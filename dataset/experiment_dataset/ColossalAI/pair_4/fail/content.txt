Requested labels: gpu-h20-10
Job defined at: hpcaitech/ColossalAI/.github/workflows/build_on_pr.yml@refs/pull/6254/merge
Waiting for a runner to pick up this job...
Job is about to start running on the runner: gpu-h20-10 (repository)
Current runner version: '2.323.0'
Runner name: 'gpu-h20-10'
Runner group name: 'Default'
Machine name: 'gpu-h20-10'
##[group]GITHUB_TOKEN Permissions
Actions: read
read
read
read
read
read
read


read
read
read
read
read
read
##[endgroup]
None
Runner is running behind proxy server 'http://vpn.luchentech.com:32171' for all HTTP requests.
Runner is running behind proxy server 'http://vpn.luchentech.com:32171' for all HTTPS requests.



'actions/checkout@v2' ee0669bd1cc54295c223e0bb666b733df41de1c5
'actions/upload-artifact@v4' ea165f8d65b6e75b540449e92b4886f43607fa02
Complete job name: Build and Test Colossal-AI
##[group]Checking docker version
##[command]/usr/bin/docker version --format '{{.Server.APIVersion}}'
'1.41'
Docker daemon API version: '1.41'
##[command]/usr/bin/docker version --format '{{.Client.APIVersion}}'
'1.41'
Docker client API version: '1.41'
##[endgroup]
##[group]Clean up resources from previous jobs
##[command]/usr/bin/docker ps --all --quiet --no-trunc --filter "label=81704a"
##[command]/usr/bin/docker network prune --force --filter "label=81704a"
##[endgroup]
##[group]Create local container network
##[command]/usr/bin/docker network create --label 81704a github_network_f8f369a09b904755b7ddc4a6eaba4311
2350cc20b0c1839fc6a6c1bd5b915a5b7064626e70f9cc918e6cd2908e18352e
##[endgroup]
##[group]Starting job container
##[command]/usr/bin/docker pull image-cloud.luchentech.com/hpcaitech/pytorch-cuda:2.2.2-12.1.0
2.2.2-12.1.0: Pulling from hpcaitech/pytorch-cuda
c2a777c1361b156ea23925ab311db35b1b450443d25dc292205058aeffea7e64
Status: Image is up to date for image-cloud.luchentech.com/hpcaitech/pytorch-cuda:2.2.2-12.1.0
image-cloud.luchentech.com/hpcaitech/pytorch-cuda:2.2.2-12.1.0
##[command]/usr/bin/docker create --name 67095444f83c4602b399de7bdcad0cb3_imagecloudluchentechcomhpcaitechpytorchcuda2221210_5c6989 --label 81704a --workdir /__w/ColossalAI/ColossalAI --network github_network_f8f369a09b904755b7ddc4a6eaba4311 --gpus all --shm-size=2g --rm -v /dev/shm -v /data/scratch:/data/scratch -e "HTTP_PROXY=http://vpn.luchentech.com:32171" -e "http_proxy=http://vpn.luchentech.com:32171" -e "HTTPS_PROXY=http://vpn.luchentech.com:32171" -e "https_proxy=http://vpn.luchentech.com:32171" -e "HOME=/github/home" -e GITHUB_ACTIONS=true -e CI=true -v "/var/run/docker.sock":"/var/run/docker.sock" -v "/root/actions-runner/github-gpu":"/__w" -v "/root/actions-runner/externals":"/__e":ro -v "/root/actions-runner/github-gpu/_temp":"/__w/_temp" -v "/root/actions-runner/github-gpu/_actions":"/__w/_actions" -v "/root/actions-runner/github-gpu/_tool":"/__w/_tool" -v "/root/actions-runner/github-gpu/_temp/_github_home":"/github/home" -v "/root/actions-runner/github-gpu/_temp/_github_workflow":"/github/workflow" --entrypoint "tail" image-cloud.luchentech.com/hpcaitech/pytorch-cuda:2.2.2-12.1.0 "-f" "/dev/null"
f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
##[command]/usr/bin/docker start f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
##[command]/usr/bin/docker ps --all --filter id=f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 --filter status=running --no-trunc --format "{{.ID}} {{.Status}}"
f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 Up Less than a second
##[command]/usr/bin/docker inspect --format "{{range .Config.Env}}{{println .}}{{end}}" f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
HTTP_PROXY=http://vpn.luchentech.com:32171
http_proxy=http://vpn.luchentech.com:32171
HTTPS_PROXY=http://vpn.luchentech.com:32171
https_proxy=http://vpn.luchentech.com:32171
HOME=/github/home
GITHUB_ACTIONS=true
CI=true
PATH=/opt/conda/envs/pytorch/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
NVARCH=x86_64
NVIDIA_REQUIRE_CUDA=cuda>=12.1 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526
NV_CUDA_CUDART_VERSION=12.1.55-1
NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-1
CUDA_VERSION=12.1.0
LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
NV_CUDA_LIB_VERSION=12.1.0-1
NV_NVTX_VERSION=12.1.66-1
NV_LIBNPP_VERSION=12.0.2.50-1
NV_LIBNPP_PACKAGE=libnpp-12-1=12.0.2.50-1
NV_LIBCUSPARSE_VERSION=12.0.2.55-1
NV_LIBCUBLAS_PACKAGE_NAME=libcublas-12-1
NV_LIBCUBLAS_VERSION=12.1.0.26-1
NV_LIBCUBLAS_PACKAGE=libcublas-12-1=12.1.0.26-1
NV_LIBNCCL_PACKAGE_NAME=libnccl2
NV_LIBNCCL_PACKAGE_VERSION=2.17.1-1
NCCL_VERSION=2.17.1-1
NV_LIBNCCL_PACKAGE=libnccl2=2.17.1-1+cuda12.1
NVIDIA_PRODUCT_NAME=CUDA
NVIDIA_CUDA_END_OF_LIFE=1
NV_CUDA_CUDART_DEV_VERSION=12.1.55-1
NV_NVML_DEV_VERSION=12.1.55-1
NV_LIBCUSPARSE_DEV_VERSION=12.0.2.55-1
NV_LIBNPP_DEV_VERSION=12.0.2.50-1
NV_LIBNPP_DEV_PACKAGE=libnpp-dev-12-1=12.0.2.50-1
NV_LIBCUBLAS_DEV_VERSION=12.1.0.26-1
NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-12-1
NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-12-1=12.1.0.26-1
NV_CUDA_NSIGHT_COMPUTE_VERSION=12.1.0-1
NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE=cuda-nsight-compute-12-1=12.1.0-1
NV_NVPROF_VERSION=12.1.55-1
NV_NVPROF_DEV_PACKAGE=cuda-nvprof-12-1=12.1.55-1
NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
NV_LIBNCCL_DEV_PACKAGE_VERSION=2.17.1-1
NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.17.1-1+cuda12.1
LIBRARY_PATH=/usr/local/cuda/lib64/stubs
NV_CUDNN_VERSION=8.9.0.131
NV_CUDNN_PACKAGE_NAME=libcudnn8
NV_CUDNN_PACKAGE=libcudnn8=8.9.0.131-1+cuda12.1
NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.9.0.131-1+cuda12.1
CUDA_HOME=/usr/local/cuda
##[endgroup]
##[group]Waiting for all services to be ready
##[endgroup]
actions/checkout@v2

hpcaitech/TensorNVMe
TensorNVMe


true

1

false

##[endgroup]
##[command]/usr/bin/docker exec  f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 sh -c "cat /etc/*release | grep ^ID"
hpcaitech/TensorNVMe

Working directory is '/__w/ColossalAI/ColossalAI/TensorNVMe'

2 25 1
##[endgroup]
Temporarily overriding HOME='/__w/_temp/bca23be4-fb8e-49ed-b3b7-4ecc6337e614' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /__w/ColossalAI/ColossalAI/TensorNVMe

[command]/usr/bin/git init /__w/ColossalAI/ColossalAI/TensorNVMe
Initialized empty Git repository in /__w/ColossalAI/ColossalAI/TensorNVMe/.git/
https://github.com/hpcaitech/TensorNVMe
##[endgroup]

[command]/usr/bin/git config --local gc.auto 0
##[endgroup]

core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader
'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'
--local
##[endgroup]
##[group]Determining the default branch
Retrieving the default branch name
Default branch 'main'
##[endgroup]

[command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --progress --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
Enumerating 60, done.
Counting 1% (1/60)
Counting 3% (2/60)
Counting 5% (3/60)
Counting 6% (4/60)
Counting 8% (5/60)
Counting 10% (6/60)
Counting 11% (7/60)
Counting 13% (8/60)
Counting 15% (9/60)
Counting 16% (10/60)
Counting 18% (11/60)
Counting 20% (12/60)
Counting 21% (13/60)
Counting 23% (14/60)
Counting 25% (15/60)
Counting 26% (16/60)
Counting 28% (17/60)
Counting 30% (18/60)
Counting 31% (19/60)
Counting 33% (20/60)
Counting 35% (21/60)
Counting 36% (22/60)
Counting 38% (23/60)
Counting 40% (24/60)
Counting 41% (25/60)
Counting 43% (26/60)
Counting 45% (27/60)
Counting 46% (28/60)
Counting 48% (29/60)
Counting 50% (30/60)
Counting 51% (31/60)
Counting 53% (32/60)
Counting 55% (33/60)
Counting 56% (34/60)
Counting 58% (35/60)
Counting 60% (36/60)
Counting 61% (37/60)
Counting 63% (38/60)
Counting 65% (39/60)
Counting 66% (40/60)
Counting 68% (41/60)
Counting 70% (42/60)
Counting 71% (43/60)
Counting 73% (44/60)
Counting 75% (45/60)
Counting 76% (46/60)
Counting 78% (47/60)
Counting 80% (48/60)
Counting 81% (49/60)
Counting 83% (50/60)
Counting 85% (51/60)
Counting 86% (52/60)
Counting 88% (53/60)
Counting 90% (54/60)
Counting 91% (55/60)
Counting 93% (56/60)
Counting 95% (57/60)
Counting 96% (58/60)
Counting 98% (59/60)
Counting 100% (60/60)
Counting 100 60 60
Compressing 1% (1/51)
Compressing 3% (2/51)
Compressing 5% (3/51)
Compressing 7% (4/51)
Compressing 9% (5/51)
Compressing 11% (6/51)
Compressing 13% (7/51)
Compressing 15% (8/51)
Compressing 17% (9/51)
Compressing 19% (10/51)
Compressing 21% (11/51)
Compressing 23% (12/51)
Compressing 25% (13/51)
Compressing 27% (14/51)
Compressing 29% (15/51)
Compressing 31% (16/51)
Compressing 33% (17/51)
Compressing 35% (18/51)
Compressing 37% (19/51)
Compressing 39% (20/51)
Compressing 41% (21/51)
Compressing 43% (22/51)
Compressing 45% (23/51)
Compressing 47% (24/51)
Compressing 49% (25/51)
Compressing 50% (26/51)
Compressing 52% (27/51)
Compressing 54% (28/51)
Compressing 56% (29/51)
Compressing 58% (30/51)
Compressing 60% (31/51)
Compressing 62% (32/51)
Compressing 64% (33/51)
Compressing 66% (34/51)
Compressing 68% (35/51)
Compressing 70% (36/51)
Compressing 72% (37/51)
Compressing 74% (38/51)
Compressing 76% (39/51)
Compressing 78% (40/51)
Compressing 80% (41/51)
Compressing 82% (42/51)
Compressing 84% (43/51)
Compressing 86% (44/51)
Compressing 88% (45/51)
Compressing 90% (46/51)
Compressing 92% (47/51)
Compressing 94% (48/51)
Compressing 96% (49/51)
Compressing 98% (50/51)
Compressing 100% (51/51)
Compressing 100 51 51
60 6 24 1 0 0
https://github.com/hpcaitech/TensorNVMe
branch] main origin/main
##[endgroup]

##[endgroup]

main refs/remotes/origin/main

Branch 'main' set up to track remote branch 'main' from 'origin'.
##[endgroup]
-1 --format='%H'
6403388f7c8929f43e407c8f7f39c6453d78c5d4
##[group]Run if [ -d /github/home/tensornvme_cache ] && [ ! -z "$(ls -A /github/home/tensornvme_cache/)" ]; then
[36;1mif [ -d /github/home/tensornvme_cache ] && [ ! -z "$(ls -A /github/home/tensornvme_cache/)" ]; then[0m
[36;1m  cp -p -r /github/home/tensornvme_cache/* /__w/ColossalAI/ColossalAI/TensorNVMe[0m
36
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
##[group]Run cd TensorNVMe
[36;1mcd TensorNVMe[0m
[36;1mconda install cmake[0m
[36;1mpip install -r requirements.txt[0m
[36;1mDISABLE_URING=1 pip install -v --no-cache-dir .[0m
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
Channels:
- defaults
Platform: linux-64
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
2025-04-11T02:45:02.3453747Z
## Package Plan ##
2025-04-11T02:45:02.3454309Z
environment location: /opt/conda
2025-04-11T02:45:02.3454580Z
added / updated specs:
- cmake
2025-04-11T02:45:02.3455071Z
2025-04-11T02:45:02.3455075Z
The following packages will be downloaded:
2025-04-11T02:45:02.3455369Z
package                    |            build
---------------------------|-----------------
archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
ca-certificates-2025.2.25  |       h06a4308_0         129 KB
certifi-2025.1.31          |  py311h06a4308_0         163 KB
cmake-3.31.2               |       h27e300b_0        20.9 MB
conda-24.11.3              |  py311h06a4308_0         1.2 MB
expat-2.6.4                |       h6a678d5_0         180 KB
frozendict-2.4.2           |  py311h06a4308_0          37 KB
libuv-1.48.0               |       h5eee18b_0         950 KB
openssl-3.0.16             |       h5eee18b_0         5.2 MB
rhash-1.4.3                |       hdbd6064_0         220 KB
xz-5.6.4                   |       h5eee18b_1         567 KB
------------------------------------------------------------
Total:        29.5 MB
2025-04-11T02:45:02.3459904Z
The following NEW packages will be INSTALLED:
2025-04-11T02:45:02.3460199Z
cmake              pkgs/main/linux-64::cmake-3.31.2-h27e300b_0
expat              pkgs/main/linux-64::expat-2.6.4-h6a678d5_0
frozendict         pkgs/main/linux-64::frozendict-2.4.2-py311h06a4308_0
libuv              pkgs/main/linux-64::libuv-1.48.0-h5eee18b_0
rhash              pkgs/main/linux-64::rhash-1.4.3-hdbd6064_0
2025-04-11T02:45:02.3466245Z
The following packages will be UPDATED:
2025-04-11T02:45:02.3466513Z
archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0
ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0
certifi                        2023.11.17-py311h06a4308_0 --> 2025.1.31-py311h06a4308_0
conda                             23.11.0-py311h06a4308_0 --> 24.11.3-py311h06a4308_0
openssl                                 3.0.12-h7f8727e_0 --> 3.0.16-h5eee18b_0
xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1
2025-04-11T02:45:02.3468622Z
2025-04-11T02:45:02.3468632Z
Proceed ([y]/n)?
2025-04-11T02:45:05.1860116Z
Downloading and Extracting Packages: ...working... done
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (24.1)
Collecting click (from -r requirements.txt (line 2))
click-8.1.8-py3-none-any.whl.metadata (2.3
Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.2.2)
Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.13.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)
Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (1.12)
Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.2.1)
Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)
Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2024.6.1)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)
click-8.1.8-py3-none-any.whl (98
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 625.3 kB/s eta 0:00:00
Installing collected packages: click
Successfully installed click-8.1.8
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Using pip 24.0 from /opt/conda/envs/pytorch/lib/python3.10/site-packages/pip (python 3.10)
Processing /__w/ColossalAI/ColossalAI/TensorNVMe
Preparing metadata (setup.py): started
Running command python setup.py egg_info
running egg_info
creating /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info
writing /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/PKG-INFO
writing dependency_links to /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/dependency_links.txt
writing entry points to /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/entry_points.txt
writing requirements to /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/requires.txt
writing top-level names to /tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/top_level.txt
writing manifest file '/tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/SOURCES.txt'
reading manifest file '/tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
writing manifest file '/tmp/pip-pip-egg-info-j647vn1s/tensornvme.egg-info/SOURCES.txt'
Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensornvme==0.1.0) (24.1)
Requirement already satisfied: click in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensornvme==0.1.0) (8.1.8)
Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensornvme==0.1.0) (2.2.2)
Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (3.13.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (4.11.0)
Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (1.12)
Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (3.2.1)
Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (3.1.4)
Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->tensornvme==0.1.0) (2024.6.1)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch->tensornvme==0.1.0) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch->tensornvme==0.1.0) (1.3.0)
Building wheels for collected packages: tensornvme
Building wheel for tensornvme (setup.py): started
Running command python setup.py bdist_wheel
CXX 9 4 0
CXX
CXX
CXX /usr/bin/c++
CXX
CXX
liburing is not found, install in /github/home/.tensornvme
libaio is not found, install in /github/home/.tensornvme
-- Configuring done (0.2s)
-- Generating done (0.0s)
-- Build files have been written to: /__w/ColossalAI/ColossalAI/TensorNVMe/cmake-build
[ 12%] Creating directories for 'extern_aio'
[ 25%] Performing download step (git clone) for 'extern_aio'
Cloning into 'libaio'...
HEAD is now at 1b18bfa bump libaio version
[ 37%] No update step for 'extern_aio'
[ 50%] No patch step for 'extern_aio'
[ 62%] No configure step for 'extern_aio'
[ 75%] Performing build step for 'extern_aio'
ar: creating libaio.a
[ 87%] No install step for 'extern_aio'
[100%] Completed 'extern_aio'
[100%] Built target extern_aio
/github/home/.bashrc is changed, please source it.
running bdist_wheel
running build
running build_py
creating build
creating build/lib.linux-x86_64-cpython-310
creating build/lib.linux-x86_64-cpython-310/tensornvme
copying tensornvme/offload.py -> build/lib.linux-x86_64-cpython-310/tensornvme
copying tensornvme/__init__.py -> build/lib.linux-x86_64-cpython-310/tensornvme
copying tensornvme/async_file_io.py -> build/lib.linux-x86_64-cpython-310/tensornvme
creating build/lib.linux-x86_64-cpython-310/tensornvme/cli
copying tensornvme/cli/check.py -> build/lib.linux-x86_64-cpython-310/tensornvme/cli
copying tensornvme/cli/__init__.py -> build/lib.linux-x86_64-cpython-310/tensornvme/cli
copying tensornvme/cli/cli.py -> build/lib.linux-x86_64-cpython-310/tensornvme/cli
running build_ext
building 'tensornvme._C' extension
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe
creating /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc
Emitting ninja build file /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/space_mgr.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/space_mgr.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/space_mgr.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/aio.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/aio.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/aio.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[3/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/async_file_io.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/async_file_io.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/async_file_io.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[4/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/offload.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/offload.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/offload.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[5/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/backend.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/backend.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/backend.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In file included from /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/backend.cpp:15:
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h: In constructor ‘PthreadAsyncIO::PthreadAsyncIO(unsigned int, unsigned int)’:
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:38:18: warning: ‘PthreadAsyncIO::total_tasks’ will be initialized after [-Wreorder]
38 |     unsigned int total_tasks;
^~~~~~~~~~~
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:29:18: warning:   ‘unsigned int PthreadAsyncIO::total_h2d’ [-Wreorder]
29 |     unsigned int total_h2d;
^~~~~~~~~
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:41:5: warning:   when initialized here [-Wreorder]
41 |     PthreadAsyncIO(unsigned int n_entries, unsigned int n_tasks)
^~~~~~~~~~~~~~
[6/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/pthread_backend.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/pthread_backend.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/pthread_backend.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In file included from /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/pthread_backend.cpp:1:
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h: In constructor ‘PthreadAsyncIO::PthreadAsyncIO(unsigned int, unsigned int)’:
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:38:18: warning: ‘PthreadAsyncIO::total_tasks’ will be initialized after [-Wreorder]
38 |     unsigned int total_tasks;
^~~~~~~~~~~
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:29:18: warning:   ‘unsigned int PthreadAsyncIO::total_h2d’ [-Wreorder]
29 |     unsigned int total_h2d;
^~~~~~~~~
/__w/ColossalAI/ColossalAI/TensorNVMe/include/pthread_backend.h:41:5: warning:   when initialized here [-Wreorder]
41 |     PthreadAsyncIO(unsigned int n_entries, unsigned int n_tasks)
^~~~~~~~~~~~~~
[7/7] c++ -MMD -MF /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/py_api.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -DDISABLE_URING -I/__w/ColossalAI/ColossalAI/TensorNVMe/csrc -I/__w/ColossalAI/ColossalAI/TensorNVMe/include -I/github/home/.tensornvme/include -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/TensorNVMe/csrc/py_api.cpp -o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/py_api.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/aio.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/async_file_io.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/backend.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/offload.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/pthread_backend.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/py_api.o /__w/ColossalAI/ColossalAI/TensorNVMe/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/TensorNVMe/csrc/space_mgr.o -L/github/home/.tensornvme/lib -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -laio -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/tensornvme/_C.cpython-310-x86_64-linux-gnu.so
/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!
2025-04-11T02:45:35.2487306Z
********************************************************************************
Please avoid running ``setup.py`` directly.
Instead, use pypa/build, pypa/installer or other
standards-based tools.
2025-04-11T02:45:35.2492125Z
See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
********************************************************************************
2025-04-11T02:45:35.2495046Z
!!
self.initialize_options()
installing to build/bdist.linux-x86_64/wheel
running install
running install_lib
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/wheel
creating build/bdist.linux-x86_64/wheel/tensornvme
copying build/lib.linux-x86_64-cpython-310/tensornvme/offload.py -> build/bdist.linux-x86_64/wheel/tensornvme
copying build/lib.linux-x86_64-cpython-310/tensornvme/__init__.py -> build/bdist.linux-x86_64/wheel/tensornvme
copying build/lib.linux-x86_64-cpython-310/tensornvme/_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/tensornvme
creating build/bdist.linux-x86_64/wheel/tensornvme/cli
copying build/lib.linux-x86_64-cpython-310/tensornvme/cli/check.py -> build/bdist.linux-x86_64/wheel/tensornvme/cli
copying build/lib.linux-x86_64-cpython-310/tensornvme/cli/__init__.py -> build/bdist.linux-x86_64/wheel/tensornvme/cli
copying build/lib.linux-x86_64-cpython-310/tensornvme/cli/cli.py -> build/bdist.linux-x86_64/wheel/tensornvme/cli
copying build/lib.linux-x86_64-cpython-310/tensornvme/async_file_io.py -> build/bdist.linux-x86_64/wheel/tensornvme
running install_egg_info
running egg_info
creating tensornvme.egg-info
writing tensornvme.egg-info/PKG-INFO
writing dependency_links to tensornvme.egg-info/dependency_links.txt
writing entry points to tensornvme.egg-info/entry_points.txt
writing requirements to tensornvme.egg-info/requires.txt
writing top-level names to tensornvme.egg-info/top_level.txt
writing manifest file 'tensornvme.egg-info/SOURCES.txt'
reading manifest file 'tensornvme.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
writing manifest file 'tensornvme.egg-info/SOURCES.txt'
Copying tensornvme.egg-info to build/bdist.linux-x86_64/wheel/tensornvme-0.1.0-py3.10.egg-info
running install_scripts
creating build/bdist.linux-x86_64/wheel/tensornvme-0.1.0.dist-info/WHEEL
creating '/tmp/pip-wheel-38t1em_l/tensornvme-0.1.0-cp310-cp310-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
adding 'tensornvme/_C.cpython-310-x86_64-linux-gnu.so'
adding 'tensornvme/__init__.py'
adding 'tensornvme/async_file_io.py'
adding 'tensornvme/offload.py'
adding 'tensornvme/cli/__init__.py'
adding 'tensornvme/cli/check.py'
adding 'tensornvme/cli/cli.py'
adding 'tensornvme-0.1.0.dist-info/METADATA'
adding 'tensornvme-0.1.0.dist-info/WHEEL'
adding 'tensornvme-0.1.0.dist-info/entry_points.txt'
adding 'tensornvme-0.1.0.dist-info/top_level.txt'
adding 'tensornvme-0.1.0.dist-info/RECORD'
removing build/bdist.linux-x86_64/wheel
Building wheel for tensornvme (setup.py): finished with status 'done'
Created wheel for tensornvme: filename=tensornvme-0.1.0-cp310-cp310-linux_x86_64.whl size=147126 sha256=137489d9a69cdbde8b1fb290a1ae8725d8c1090e9cd2cd064b5fdc6effe0392c
Stored in directory: /tmp/pip-ephem-wheel-cache-3vrde08c/wheels/cb/3c/a4/391c1ae2f1a321082a466078f0646d215673629d6cbb874a65
Successfully built tensornvme
Installing collected packages: tensornvme
changing mode of /opt/conda/envs/pytorch/bin/tensornvme to 755
Successfully installed tensornvme-0.1.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
##[group]Run cd TensorNVMe
[36;1mcd TensorNVMe[0m
[36;1mcp -p -r ./build /github/home/tensornvme_cache/[0m
[36;1mcp -p -r ./cmake-build /github/home/tensornvme_cache/[0m
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
actions/checkout@v2

hpcaitech/ColossalAI


true

1

false

##[endgroup]
##[command]/usr/bin/docker exec  f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 sh -c "cat /etc/*release | grep ^ID"
hpcaitech/ColossalAI

Working directory is '/__w/ColossalAI/ColossalAI'

2 25 1
##[endgroup]
Temporarily overriding HOME='/__w/_temp/fc2f98dc-f753-4690-9811-06b021eca682' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /__w/ColossalAI/ColossalAI
[command]/usr/bin/git config --local --get remote.origin.url
https://github.com/hpcaitech/ColossalAI
##[group]Removing previously created refs, to avoid conflicts
[command]/usr/bin/git rev-parse --symbolic-full-name --verify --quiet HEAD
HEAD
[command]/usr/bin/git rev-parse --symbolic-full-name --branches
##[endgroup]
##[group]Cleaning the repository
[command]/usr/bin/git clean -ffdx
Removing TensorNVMe/
[command]/usr/bin/git reset --hard HEAD
HEAD is now at 0950b07a [pre-commit.ci] auto fixes from pre-commit.com hooks
##[endgroup]

[command]/usr/bin/git config --local gc.auto 0
##[endgroup]

core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader
'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'
--local
##[endgroup]

2 1 6f94bf4ca860b2a64be2bb167fbcd4cdaf3efe45 6254
Enumerating 7, done.
Counting 14% (1/7)
Counting 28% (2/7)
Counting 42% (3/7)
Counting 57% (4/7)
Counting 71% (5/7)
Counting 85% (6/7)
Counting 100% (7/7)
Counting 100 7 7
Compressing 100% (1/1)
Compressing 100 1 1
3 2 2 2 0 0
https://github.com/hpcaitech/ColossalAI
+ 40c00c29...6f94bf4c 6f94bf4ca860b2a64be2bb167fbcd4cdaf3efe45 -> pull/6254/merge  (forced update)
##[endgroup]

##[endgroup]

6254
Warning: you are leaving 41 commits behind, not connected to
any of your branches:
2025-04-11T02:45:37.9142134Z
0950b07a [pre-commit.ci] auto fixes from pre-commit.com hooks
910433f0 fix
21707a77 fix
c37107ce Merge branch 'upgrade-transformers' of github.com:flybird11111/ColossalAI into upgrade-transformers
... and 37 more.
2025-04-11T02:45:37.9143719Z
If you want to keep them by creating a new branch, this may be a good time
to do so with:
2025-04-11T02:45:37.9144299Z
git branch <new-branch-name> 0950b07a
2025-04-11T02:45:37.9144572Z
6f94bf4c 0950b07a328809335470812959341c585f1a9e2a 44d4053fec005fe0b06b6bc755fdc962463145df
##[endgroup]
-1 --format='%H'
6f94bf4ca860b2a64be2bb167fbcd4cdaf3efe45
##[group]Run # -p flag is required to preserve the file timestamp to avoid ninja rebuild
[36;1m# -p flag is required to preserve the file timestamp to avoid ninja rebuild[0m
[36;1mif [ -d /github/home/cuda_ext_cache ] && [ ! -z "$(ls -A /github/home/cuda_ext_cache/)" ]; then[0m
[36;1m  cp -p -r /github/home/cuda_ext_cache/* /__w/ColossalAI/ColossalAI/[0m
36
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
##[group]Run BUILD_EXT=1 pip install -v -e .
[36;1mBUILD_EXT=1 pip install -v -e .[0m
[36;1mpip install --no-cache-dir -r requirements/requirements-test.txt[0m
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
Using pip 24.0 from /opt/conda/envs/pytorch/lib/python3.10/site-packages/pip (python 3.10)
Obtaining file:///__w/ColossalAI/ColossalAI
Preparing metadata (setup.py): started
Running command python setup.py egg_info
[extension] Building extensionscpu_adam_x86, layernorm_cuda, moe_cuda, fused_optim_cuda, inference_ops_cuda, scaled_masked_softmax_cuda, scaled_upper_triangle_masked_softmax_cuda
running egg_info
creating /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info
writing /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/PKG-INFO
writing dependency_links to /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/dependency_links.txt
writing entry points to /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/entry_points.txt
writing requirements to /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/requires.txt
writing top-level names to /tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/top_level.txt
writing manifest file '/tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/SOURCES.txt'
reading manifest file '/tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
warning: no files found matching '*.tr' under directory 'colossalai'
warning: no files found matching '*.cc' under directory 'colossalai'
warning: no files found matching '*.pyi' under directory 'colossalai'
warning: no files found matching '*.tr' under directory 'extensions'
warning: no files found matching '*.cc' under directory 'extensions'
warning: no files found matching '*.pyi' under directory 'extensions'
adding license file 'LICENSE'
writing manifest file '/tmp/pip-pip-egg-info-aox9erle/colossalai.egg-info/SOURCES.txt'
Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai==0.4.9) (1.26.4)
tqdm colossalai==0.4.9)
Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata
tqdm-4.67.1-py3-none-any.whl.metadata (57
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 331.7 kB/s eta 0:00:00
psutil colossalai==0.4.9)
Obtaining dependency information for psutil from https://files.pythonhosted.org/packages/bf/b9/b0eb3f3cbcb734d930fdf839431606844a825b23eaf9a6ab371edac8162c/psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)
Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai==0.4.9) (24.1)
pre-commit colossalai==0.4.9)
Obtaining dependency information for pre-commit from https://files.pythonhosted.org/packages/88/74/a88bf1b1efeae488a0c0b7bdf71429c313722d1fc0f377537fbe554e6180/pre_commit-4.2.0-py2.py3-none-any.whl.metadata
pre commit-4.2.0-py2.py3-none-any.whl.metadata (1.3
rich colossalai==0.4.9)
Obtaining dependency information for rich from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata
rich-14.0.0-py3-none-any.whl.metadata (18
Requirement already satisfied: click in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai==0.4.9) (8.1.8)
fabric colossalai==0.4.9)
Obtaining dependency information for fabric from https://files.pythonhosted.org/packages/d6/1f/e99e23ee01847147fa194e8d41cfcf2535a2dbfcb51414c541cadb15c5d7/fabric-3.2.2-py3-none-any.whl.metadata
fabric-3.2.2-py3-none-any.whl.metadata (3.5
contexttimer colossalai==0.4.9)
contexttimer-0.3.3.tar.gz (4.9
Preparing metadata (setup.py): started
Running command python setup.py egg_info
running egg_info
creating /tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info
writing /tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/PKG-INFO
writing dependency_links to /tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/dependency_links.txt
writing top-level names to /tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/top_level.txt
writing manifest file '/tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/SOURCES.txt'
reading manifest file '/tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/SOURCES.txt'
writing manifest file '/tmp/pip-pip-egg-info-5ls9tqd8/contexttimer.egg-info/SOURCES.txt'
Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: ninja in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai==0.4.9) (1.11.1.1)
Requirement already satisfied: torch<=2.5.1,>=2.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai==0.4.9) (2.2.2)
safetensors colossalai==0.4.9)
Obtaining dependency information for safetensors from https://files.pythonhosted.org/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
einops colossalai==0.4.9)
Obtaining dependency information for einops from https://files.pythonhosted.org/packages/87/62/9773de14fe6c45c23649e98b83231fffd7b9892b6cf863251dc2afa73643/einops-0.8.1-py3-none-any.whl.metadata
einops-0.8.1-py3-none-any.whl.metadata (13
pydantic colossalai==0.4.9)
Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/b0/1d/407b29780a289868ed696d1616f4aad49d6388e5a77f567dcd2629dcd7b8/pydantic-2.11.3-py3-none-any.whl.metadata
pydantic-2.11.3-py3-none-any.whl.metadata (65
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.2/65.2 kB 981.0 kB/s eta 0:00:00
ray colossalai==0.4.9)
Obtaining dependency information for ray from https://files.pythonhosted.org/packages/93/f1/9108c4f878e3cacb767b7dfbbc3a26537c79ab516d2530b9f63b558ba4bb/ray-2.44.1-cp310-cp310-manylinux2014_x86_64.whl.metadata
Downloading ray-2.44.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (19 kB)
sentencepiece colossalai==0.4.9)
Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a6/27/33019685023221ca8ed98e8ceb7ae5e166032686fa3662c68f1f1edf334e/sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
google colossalai==0.4.9)
Obtaining dependency information for google from https://files.pythonhosted.org/packages/ac/35/17c9141c4ae21e9a29a43acdfd848e3e468a810517f862cad07977bf8fe9/google-3.0.0-py2.py3-none-any.whl.metadata
Downloading google-3.0.0-py2.py3-none-any.whl.metadata (627 bytes)
protobuf colossalai==0.4.9)
Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/28/50/1925de813499546bc8ab3ae857e3ec84efe7d2f19b34529d0c7c3d02d11d/protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata
Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
transformers==4.39.3 colossalai==0.4.9)
Obtaining dependency information for transformers==4.39.3 from https://files.pythonhosted.org/packages/15/fc/7b6dd7e1adc0a6407b845ed4be1999e98b6917d0694e57316d140cc85484/transformers-4.39.3-py3-none-any.whl.metadata
transformers-4.39.3-py3-none-any.whl.metadata (134
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 2.2 MB/s eta 0:00:00
peft<=0.13.2,>=0.7.1 colossalai==0.4.9)
Obtaining dependency information for peft<=0.13.2,>=0.7.1 from https://files.pythonhosted.org/packages/78/9d/5f95bfb298c8d3b4e3a107701f9a4e7774a0d4d1f8eb0c9d5420b80f7c9d/peft-0.13.2-py3-none-any.whl.metadata
peft-0.13.2-py3-none-any.whl.metadata (13
bitsandbytes>=0.39.0 colossalai==0.4.9)
Obtaining dependency information for bitsandbytes>=0.39.0 from https://files.pythonhosted.org/packages/07/b7/cb5ce4d1a382cf53c19ef06c5fc29e85f5e129b4da6527dd207d90a5b8ad/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata
Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)
rpyc==6.0.0 colossalai==0.4.9)
Obtaining dependency information for rpyc==6.0.0 from https://files.pythonhosted.org/packages/f6/e7/38cd5f2d8ab0d259648f6672fd19de30688a22ae769f87616c6a2fe92581/rpyc-6.0.0-py3-none-any.whl.metadata
rpyc-6.0.0-py3-none-any.whl.metadata (3.5
fastapi colossalai==0.4.9)
Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/50/b3/b51f09c2ba432a576fe63758bddc81f78f0c6309d9e5c10d194313bf021e/fastapi-0.115.12-py3-none-any.whl.metadata
fastapi-0.115.12-py3-none-any.whl.metadata (27
uvicorn==0.29.0 colossalai==0.4.9)
Obtaining dependency information for uvicorn==0.29.0 from https://files.pythonhosted.org/packages/73/f5/cbb16fcbe277c1e0b8b3ddd188f2df0e0947f545c49119b589643632d156/uvicorn-0.29.0-py3-none-any.whl.metadata
uvicorn-0.29.0-py3-none-any.whl.metadata (6.3
Collecting galore_torch (from colossalai==0.4.9)
Obtaining dependency information for galore_torch from https://files.pythonhosted.org/packages/2b/b9/e9e88f989c62edefaa45df07198ce280ac0d373f5e2842686c6ece2ddb1e/galore_torch-1.0-py3-none-any.whl.metadata
Downloading galore_torch-1.0-py3-none-any.whl.metadata (355 bytes)
diffusers==0.29.0 colossalai==0.4.9)
Obtaining dependency information for diffusers==0.29.0 from https://files.pythonhosted.org/packages/d5/68/a84d929518c9fbd65febcedd7810203bcac393f9cddd0603ec58df7f93f7/diffusers-0.29.0-py3-none-any.whl.metadata
diffusers-0.29.0-py3-none-any.whl.metadata (19
importlib-metadata diffusers==0.29.0->colossalai==0.4.9)
Obtaining dependency information for importlib-metadata from https://files.pythonhosted.org/packages/79/9d/0fb148dc4d6fa4a7dd1d8378168d9b4cd8d4560a6fbf6f0121c5fc34eb68/importlib_metadata-8.6.1-py3-none-any.whl.metadata
importlib metadata-8.6.1-py3-none-any.whl.metadata (4.7
Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from diffusers==0.29.0->colossalai==0.4.9) (3.13.1)
huggingface-hub>=0.23.2 diffusers==0.29.0->colossalai==0.4.9)
Obtaining dependency information for huggingface-hub>=0.23.2 from https://files.pythonhosted.org/packages/93/27/1fb384a841e9661faad1c31cbfa62864f59632e876df5d795234da51c395/huggingface_hub-0.30.2-py3-none-any.whl.metadata
huggingface hub-0.30.2-py3-none-any.whl.metadata (13
regex!=2019.12.17 diffusers==0.29.0->colossalai==0.4.9)
Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 542.6 kB/s eta 0:00:00
Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from diffusers==0.29.0->colossalai==0.4.9) (2.32.2)
Requirement already satisfied: Pillow in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from diffusers==0.29.0->colossalai==0.4.9) (10.3.0)
plumbum rpyc==6.0.0->colossalai==0.4.9)
Obtaining dependency information for plumbum from https://files.pythonhosted.org/packages/4f/9d/d03542c93bb3d448406731b80f39c3d5601282f778328c22c77d270f4ed4/plumbum-1.9.0-py3-none-any.whl.metadata
plumbum-1.9.0-py3-none-any.whl.metadata (10
Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers==4.39.3->colossalai==0.4.9) (6.0.1)
tokenizers<0.19,>=0.14 transformers==4.39.3->colossalai==0.4.9)
Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/1c/5d/cf5e122ce4f1a29f165b2a69dc33d1ff30bce303343d58a54775ddba5d51/tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
h11>=0.8 uvicorn==0.29.0->colossalai==0.4.9)
Obtaining dependency information for h11>=0.8 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata
h11-0.14.0-py3-none-any.whl.metadata (8.2
Requirement already satisfied: typing-extensions>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn==0.29.0->colossalai==0.4.9) (4.11.0)
accelerate>=0.21.0 peft<=0.13.2,>=0.7.1->colossalai==0.4.9)
Obtaining dependency information for accelerate>=0.21.0 from https://files.pythonhosted.org/packages/63/b1/8198e3cdd11a426b1df2912e3381018c4a4a55368f6d0857ba3ca418ef93/accelerate-1.6.0-py3-none-any.whl.metadata
accelerate-1.6.0-py3-none-any.whl.metadata (19
Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (1.12)
Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (3.2.1)
Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (3.1.4)
Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (2024.6.1)
invoke>=2.0 fabric->colossalai==0.4.9)
Obtaining dependency information for invoke>=2.0 from https://files.pythonhosted.org/packages/0a/66/7f8c48009c72d73bc6bbe6eb87ac838d6a526146f7dab14af671121eb379/invoke-2.2.0-py3-none-any.whl.metadata
invoke-2.2.0-py3-none-any.whl.metadata (3.3
paramiko>=2.4 fabric->colossalai==0.4.9)
Obtaining dependency information for paramiko>=2.4 from https://files.pythonhosted.org/packages/15/f8/c7bd0ef12954a81a1d3cea60a13946bd9a49a0036a5927770c461eade7ae/paramiko-3.5.1-py3-none-any.whl.metadata
paramiko-3.5.1-py3-none-any.whl.metadata (4.6
decorator>=5 fabric->colossalai==0.4.9)
Obtaining dependency information for decorator>=5 from https://files.pythonhosted.org/packages/4e/8c/f3147f5c4b73e7550fe5f9352eaa956ae838d5c51eb58e7a25b9f3e2643b/decorator-5.2.1-py3-none-any.whl.metadata
decorator-5.2.1-py3-none-any.whl.metadata (3.9
deprecated>=1.2 fabric->colossalai==0.4.9)
Obtaining dependency information for deprecated>=1.2 from https://files.pythonhosted.org/packages/6e/c6/ac0b6c1e2d138f1002bcf799d330bd6d85084fece321e662a14223794041/Deprecated-1.2.18-py2.py3-none-any.whl.metadata
Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7
starlette<0.47.0,>=0.40.0 fastapi->colossalai==0.4.9)
Obtaining dependency information for starlette<0.47.0,>=0.40.0 from https://files.pythonhosted.org/packages/a0/4b/528ccf7a982216885a1ff4908e886b8fb5f19862d1962f56a3fce2435a70/starlette-0.46.1-py3-none-any.whl.metadata
starlette-0.46.1-py3-none-any.whl.metadata (6.2
annotated-types>=0.6.0 pydantic->colossalai==0.4.9)
Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata
annotated types-0.7.0-py3-none-any.whl.metadata (15
pydantic-core==2.33.1 pydantic->colossalai==0.4.9)
Obtaining dependency information for pydantic-core==2.33.1 from https://files.pythonhosted.org/packages/f2/68/866ce83a51dd37e7c604ce0050ff6ad26de65a7799df89f4db87dd93d1d6/pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
typing-extensions>=4.0 uvicorn==0.29.0->colossalai==0.4.9)
Obtaining dependency information for typing-extensions>=4.0 from https://files.pythonhosted.org/packages/8b/54/b1ae86c0973cc6f0210b53d508ca3641fb6d0c56823f288d108bc7ab3cc8/typing_extensions-4.13.2-py3-none-any.whl.metadata
typing extensions-4.13.2-py3-none-any.whl.metadata (3.0
typing-inspection>=0.4.0 pydantic->colossalai==0.4.9)
Obtaining dependency information for typing-inspection>=0.4.0 from https://files.pythonhosted.org/packages/31/08/aa4fdfb71f7de5176385bd9e90852eaf6b5d622735020ad600f2bab54385/typing_inspection-0.4.0-py3-none-any.whl.metadata
typing inspection-0.4.0-py3-none-any.whl.metadata (2.6
beautifulsoup4 google->colossalai==0.4.9)
Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/f9/49/6abb616eb3cbab6a7cca303dc02fdf3836de2e0b834bf966a7f5271a34d8/beautifulsoup4-4.13.3-py3-none-any.whl.metadata
beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8
cfgv>=2.0.0 pre-commit->colossalai==0.4.9)
Obtaining dependency information for cfgv>=2.0.0 from https://files.pythonhosted.org/packages/c5/55/51844dd50c4fc7a33b653bfaba4c2456f06955289ca770a5dbd5fd267374/cfgv-3.4.0-py2.py3-none-any.whl.metadata
cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5
identify>=1.0.0 pre-commit->colossalai==0.4.9)
Obtaining dependency information for identify>=1.0.0 from https://files.pythonhosted.org/packages/07/ce/0845144ed1f0e25db5e7a79c2354c1da4b5ce392b8966449d5db8dca18f1/identify-2.6.9-py2.py3-none-any.whl.metadata
identify-2.6.9-py2.py3-none-any.whl.metadata (4.4
nodeenv>=0.11.1 pre-commit->colossalai==0.4.9)
Obtaining dependency information for nodeenv>=0.11.1 from https://files.pythonhosted.org/packages/d2/1d/1b658dbd2b9fa9c4c9f32accbfc0205d532c8c6194dc0f2a4c0428e7128a/nodeenv-1.9.1-py2.py3-none-any.whl.metadata
nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21
virtualenv>=20.10.0 pre-commit->colossalai==0.4.9)
Obtaining dependency information for virtualenv>=20.10.0 from https://files.pythonhosted.org/packages/4c/ed/3cfeb48175f0671ec430ede81f628f9fb2b1084c9064ca67ebe8c0ed6a05/virtualenv-20.30.0-py3-none-any.whl.metadata
virtualenv-20.30.0-py3-none-any.whl.metadata (4.5
jsonschema ray->colossalai==0.4.9)
Obtaining dependency information for jsonschema from https://files.pythonhosted.org/packages/69/4a/4f9dbeb84e8850557c02365a0eee0649abe5eb1d84af92a25731c6c0f922/jsonschema-4.23.0-py3-none-any.whl.metadata
jsonschema-4.23.0-py3-none-any.whl.metadata (7.9
msgpack<2.0.0,>=1.0.0 ray->colossalai==0.4.9)
Obtaining dependency information for msgpack<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/ff/75/09081792db60470bef19d9c2be89f024d366b1e1973c197bb59e6aabc647/msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)
aiosignal ray->colossalai==0.4.9)
Obtaining dependency information for aiosignal from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata
aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8
frozenlist ray->colossalai==0.4.9)
Obtaining dependency information for frozenlist from https://files.pythonhosted.org/packages/ee/59/928322800306f6529d1852323014ee9008551e9bb027cc38d276cbc0b0e7/frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
markdown-it-py>=2.2.0 rich->colossalai==0.4.9)
Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata
Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)
pygments<3.0.0,>=2.13.0 rich->colossalai==0.4.9)
Obtaining dependency information for pygments<3.0.0,>=2.13.0 from https://files.pythonhosted.org/packages/8a/0b/9fcc47d19c48b59121088dd6da2488a49d5f72dacf8262e2790a1d2c7d15/pygments-2.19.1-py3-none-any.whl.metadata
pygments-2.19.1-py3-none-any.whl.metadata (2.5
wrapt<2,>=1.10 deprecated>=1.2->fabric->colossalai==0.4.9)
Obtaining dependency information for wrapt<2,>=1.10 from https://files.pythonhosted.org/packages/90/ec/00759565518f268ed707dcc40f7eeec38637d46b098a1f5143bff488fe97/wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)
mdurl~=0.1 markdown-it-py>=2.2.0->rich->colossalai==0.4.9)
Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata
mdurl-0.1.2-py3-none-any.whl.metadata (1.6
bcrypt>=3.2 paramiko>=2.4->fabric->colossalai==0.4.9)
Obtaining dependency information for bcrypt>=3.2 from https://files.pythonhosted.org/packages/cb/c6/8fedca4c2ada1b6e889c52d2943b2f968d3427e5d65f595620ec4c06fa2f/bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata
Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)
cryptography>=3.3 paramiko>=2.4->fabric->colossalai==0.4.9)
Obtaining dependency information for cryptography>=3.3 from https://files.pythonhosted.org/packages/78/2b/999b2a1e1ba2206f2d3bca267d68f350beb2b048a41ea827e08ce7260098/cryptography-44.0.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata
Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)
pynacl>=1.5 paramiko>=2.4->fabric->colossalai==0.4.9)
Obtaining dependency information for pynacl>=1.5 from https://files.pythonhosted.org/packages/ee/87/f1bb6a595f14a327e8285b9eb54d41fef76c585a0edef0a45f6fc95de125/PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata
Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)
anyio<5,>=3.6.2 starlette<0.47.0,>=0.40.0->fastapi->colossalai==0.4.9)
Obtaining dependency information for anyio<5,>=3.6.2 from https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl.metadata
anyio-4.9.0-py3-none-any.whl.metadata (4.7
distlib<1,>=0.3.7 virtualenv>=20.10.0->pre-commit->colossalai==0.4.9)
Obtaining dependency information for distlib<1,>=0.3.7 from https://files.pythonhosted.org/packages/91/a1/cf2472db20f7ce4a6be1253a81cfdf85ad9c7885ffbed7047fb72c24cf87/distlib-0.3.9-py2.py3-none-any.whl.metadata
distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2
platformdirs<5,>=3.9.1 virtualenv>=20.10.0->pre-commit->colossalai==0.4.9)
Obtaining dependency information for platformdirs<5,>=3.9.1 from https://files.pythonhosted.org/packages/6d/45/59578566b3275b8fd9157885918fcd0c4d74162928a5310926887b856a51/platformdirs-4.3.7-py3-none-any.whl.metadata
platformdirs-4.3.7-py3-none-any.whl.metadata (11
soupsieve>1.2 beautifulsoup4->google->colossalai==0.4.9)
Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl.metadata
soupsieve-2.6-py3-none-any.whl.metadata (4.6
zipp>=3.20 importlib-metadata->diffusers==0.29.0->colossalai==0.4.9)
Obtaining dependency information for zipp>=3.20 from https://files.pythonhosted.org/packages/b7/1a/7e4798e9339adc931158c9d69ecc34f5e6791489d469f5e50ec15e35f458/zipp-3.21.0-py3-none-any.whl.metadata
zipp-3.21.0-py3-none-any.whl.metadata (3.7
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (2.1.3)
attrs>=22.2.0 jsonschema->ray->colossalai==0.4.9)
Obtaining dependency information for attrs>=22.2.0 from https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl.metadata
attrs-25.3.0-py3-none-any.whl.metadata (10
jsonschema-specifications>=2023.03.6 jsonschema->ray->colossalai==0.4.9)
Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/d1/0f/8910b19ac0670a0f80ce1008e5e751c4a57e14d2c4c13a482aa6079fa9d6/jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata
jsonschema specifications-2024.10.1-py3-none-any.whl.metadata (3.0
referencing>=0.28.4 jsonschema->ray->colossalai==0.4.9)
Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl.metadata
referencing-0.36.2-py3-none-any.whl.metadata (2.8
rpds-py>=0.7.1 jsonschema->ray->colossalai==0.4.9)
Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/a7/a7/6d04d438f53d8bb2356bb000bea9cf5c96a9315e405b577117e344cc7404/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading rpds_py-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->diffusers==0.29.0->colossalai==0.4.9) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->diffusers==0.29.0->colossalai==0.4.9) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->diffusers==0.29.0->colossalai==0.4.9) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->diffusers==0.29.0->colossalai==0.4.9) (2024.6.2)
Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch<=2.5.1,>=2.2.0->colossalai==0.4.9) (1.3.0)
exceptiongroup>=1.0.2 anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->colossalai==0.4.9)
Obtaining dependency information for exceptiongroup>=1.0.2 from https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl.metadata
exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6
sniffio>=1.1 anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->colossalai==0.4.9)
Obtaining dependency information for sniffio>=1.1 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata
sniffio-1.3.1-py3-none-any.whl.metadata (3.9
cffi>=1.12 cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.4.9)
Obtaining dependency information for cffi>=1.12 from https://files.pythonhosted.org/packages/8d/fb/4da72871d177d63649ac449aec2e8a29efe0274035880c7af59101ca2232/cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)
pycparser cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.4.9)
Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata
Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)
Downloading diffusers-0.29.0-py3-none-any.whl (2.2 MB)
2 2 2 2 MB 6 2 0 00 00
rpyc-6.0.0-py3-none-any.whl (74
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.5/74.5 kB 897.0 kB/s eta 0:00:00
Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)
8 8 8 8 MB 27 0 0 00 00
uvicorn-0.29.0-py3-none-any.whl (60
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 705.8 kB/s eta 0:00:00
Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)
76 1 76 1 MB 17 1 0 00 00
peft-0.13.2-py3-none-any.whl (320
320 7 320 7 kB 4 3 0 00 00
Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)
471 6 471 6 kB 6 3 0 00 00
tqdm-4.67.1-py3-none-any.whl (78
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 953.3 kB/s eta 0:00:00
einops-0.8.1-py3-none-any.whl (64
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.4/64.4 kB 752.1 kB/s eta 0:00:00
fabric-3.2.2-py3-none-any.whl (59
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.4/59.4 kB 687.7 kB/s eta 0:00:00
fastapi-0.115.12-py3-none-any.whl (95
95 2 95 2 kB 1 2 0 00 00
pydantic-2.11.3-py3-none-any.whl (443
443 6 443 6 kB 6 0 0 00 00
Downloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
2 0 2 0 MB 24 7 0 00 00
galore torch-1.0-py3-none-any.whl (13
google-3.0.0-py2.py3-none-any.whl (45
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.3/45.3 kB 488.9 kB/s eta 0:00:00
pre commit-4.2.0-py2.py3-none-any.whl (220
220 7 220 7 kB 2 9 0 00 00
Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)
316 2 316 2 kB 4 2 0 00 00
Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)
278 0 278 0 kB 3 7 0 00 00
Downloading ray-2.44.1-cp310-cp310-manylinux2014_x86_64.whl (67.9 MB)
67 9 67 9 MB 21 2 0 00 00
rich-14.0.0-py3-none-any.whl (243
243 2 243 2 kB 3 2 0 00 00
Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
1 3 1 3 MB 17 2 0 00 00
accelerate-1.6.0-py3-none-any.whl (354
354 7 354 7 kB 4 8 0 00 00
annotated types-0.7.0-py3-none-any.whl (13
cfgv-3.4.0-py2.py3-none-any.whl (7.2
decorator-5.2.1-py3-none-any.whl (9.2
Deprecated-1.2.18-py2.py3-none-any.whl (10.0
h11-0.14.0-py3-none-any.whl (58
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 668.4 kB/s eta 0:00:00
huggingface hub-0.30.2-py3-none-any.whl (481
481 4 481 4 kB 6 4 0 00 00
identify-2.6.9-py2.py3-none-any.whl (99
99 1 99 1 kB 1 2 0 00 00
invoke-2.2.0-py3-none-any.whl (160
160 3 160 3 kB 2 1 0 00 00
Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)
87 5 87 5 kB 1 1 0 00 00
Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)
378 0 378 0 kB 5 0 0 00 00
nodeenv-1.9.1-py2.py3-none-any.whl (22
paramiko-3.5.1-py3-none-any.whl (227
227 3 227 3 kB 3 0 0 00 00
Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)
1 2 1 2 MB 16 2 0 00 00
Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)
781 7 781 7 kB 10 4 0 00 00
starlette-0.46.1-py3-none-any.whl (71
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.0/72.0 kB 859.8 kB/s eta 0:00:00
Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
3 6 3 6 MB 29 2 0 00 00
typing extensions-4.13.2-py3-none-any.whl (45
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.8/45.8 kB 495.9 kB/s eta 0:00:00
typing inspection-0.4.0-py3-none-any.whl (14
20 30 0 4 3
4 3 4 3 MB 31 0 0 00 00
aiosignal-1.3.2-py2.py3-none-any.whl (7.6
Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)
241 9 241 9 kB 3 2 0 00 00
beautifulsoup4-4.13.3-py3-none-any.whl (186
186 0 186 0 kB 2 4 0 00 00
importlib metadata-8.6.1-py3-none-any.whl (26
jsonschema-4.23.0-py3-none-any.whl (88
88 5 88 5 kB 1 1 0 00 00
plumbum-1.9.0-py3-none-any.whl (127
128 0 128 0 kB 1 6 0 00 00
anyio-4.9.0-py3-none-any.whl (100
100 9 100 9 kB 1 3 0 00 00
attrs-25.3.0-py3-none-any.whl (63
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 746.0 kB/s eta 0:00:00
Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl (284 kB)
284 5 284 5 kB 3 8 0 00 00
Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)
4 2 4 2 MB 27 2 0 00 00
distlib-0.3.9-py2.py3-none-any.whl (468
469 0 469 0 kB 6 3 0 00 00
jsonschema specifications-2024.10.1-py3-none-any.whl (18
mdurl-0.1.2-py3-none-any.whl (10.0
platformdirs-4.3.7-py3-none-any.whl (18
Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)
856 7 856 7 kB 11 5 0 00 00
referencing-0.36.2-py3-none-any.whl (26
Downloading rpds_py-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)
389 5 389 5 kB 5 2 0 00 00
soupsieve-2.6-py3-none-any.whl (36
Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)
82 8 82 8 kB 1 0 0 00 00
zipp-3.21.0-py3-none-any.whl (9.6
Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)
446 2 446 2 kB 6 0 0 00 00
exceptiongroup-1.2.2-py3-none-any.whl (16
sniffio-1.3.1-py3-none-any.whl (10
pycparser-2.22-py3-none-any.whl (117
117 6 117 6 kB 1 5 0 00 00
Building wheels for collected packages: contexttimer
Building wheel for contexttimer (setup.py): started
Running command python setup.py bdist_wheel
running bdist_wheel
running build
running build_py
creating build
creating build/lib
creating build/lib/contexttimer
copying contexttimer/__init__.py -> build/lib/contexttimer
copying contexttimer/timeout.py -> build/lib/contexttimer
/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!
2025-04-11T02:46:24.7192037Z
********************************************************************************
Please avoid running ``setup.py`` directly.
Instead, use pypa/build, pypa/installer or other
standards-based tools.
2025-04-11T02:46:24.7196327Z
See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
********************************************************************************
2025-04-11T02:46:24.7199475Z
!!
self.initialize_options()
installing to build/bdist.linux-x86_64/wheel
running install
running install_lib
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/wheel
creating build/bdist.linux-x86_64/wheel/contexttimer
copying build/lib/contexttimer/__init__.py -> build/bdist.linux-x86_64/wheel/contexttimer
copying build/lib/contexttimer/timeout.py -> build/bdist.linux-x86_64/wheel/contexttimer
running install_egg_info
running egg_info
writing contexttimer.egg-info/PKG-INFO
writing dependency_links to contexttimer.egg-info/dependency_links.txt
writing top-level names to contexttimer.egg-info/top_level.txt
reading manifest file 'contexttimer.egg-info/SOURCES.txt'
writing manifest file 'contexttimer.egg-info/SOURCES.txt'
Copying contexttimer.egg-info to build/bdist.linux-x86_64/wheel/contexttimer-0.3.3-py3.10.egg-info
running install_scripts
creating build/bdist.linux-x86_64/wheel/contexttimer-0.3.3.dist-info/WHEEL
creating '/tmp/pip-wheel-dlyt23z3/contexttimer-0.3.3-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
adding 'contexttimer/__init__.py'
adding 'contexttimer/timeout.py'
adding 'contexttimer-0.3.3.dist-info/METADATA'
adding 'contexttimer-0.3.3.dist-info/WHEEL'
adding 'contexttimer-0.3.3.dist-info/top_level.txt'
adding 'contexttimer-0.3.3.dist-info/RECORD'
removing build/bdist.linux-x86_64/wheel
Building wheel for contexttimer (setup.py): finished with status 'done'
Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5804 sha256=3dadc26ce04a09cd9d346ae66ada40ebfefd8d029bee337d1260172b935fa0d6
Stored in directory: /github/home/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4
Successfully built contexttimer
Installing collected packages: sentencepiece, distlib, contexttimer, zipp, wrapt, typing-extensions, tqdm, soupsieve, sniffio, safetensors, rpds-py, regex, pygments, pycparser, psutil, protobuf, plumbum, platformdirs, nodeenv, msgpack, mdurl, invoke, identify, h11, frozenlist, exceptiongroup, einops, decorator, cfgv, bcrypt, attrs, annotated-types, virtualenv, uvicorn, typing-inspection, rpyc, referencing, pydantic-core, markdown-it-py, importlib-metadata, huggingface-hub, deprecated, cffi, beautifulsoup4, anyio, aiosignal, tokenizers, starlette, rich, pynacl, pydantic, pre-commit, jsonschema-specifications, google, diffusers, cryptography, bitsandbytes, accelerate, transformers, paramiko, jsonschema, fastapi, ray, peft, galore_torch, fabric, colossalai
Attempting uninstall: typing-extensions
Found existing installation: typing_extensions 4.11.0
Uninstalling typing_extensions-4.11.0:
Removing file or directory /opt/conda/envs/pytorch/lib/python3.10/site-packages/__pycache__/typing_extensions.cpython-310.pyc
Removing file or directory /opt/conda/envs/pytorch/lib/python3.10/site-packages/typing_extensions-4.11.0.dist-info/
Removing file or directory /opt/conda/envs/pytorch/lib/python3.10/site-packages/typing_extensions.py
Successfully uninstalled typing_extensions-4.11.0
changing mode of /opt/conda/envs/pytorch/bin/tqdm to 755
changing mode of /opt/conda/envs/pytorch/bin/pygmentize to 755
changing mode of /opt/conda/envs/pytorch/bin/nodeenv to 755
changing mode of /opt/conda/envs/pytorch/bin/inv to 755
changing mode of /opt/conda/envs/pytorch/bin/invoke to 755
changing mode of /opt/conda/envs/pytorch/bin/identify-cli to 755
changing mode of /opt/conda/envs/pytorch/bin/virtualenv to 755
changing mode of /opt/conda/envs/pytorch/bin/uvicorn to 755
changing mode of /opt/conda/envs/pytorch/bin/rpyc_classic to 755
changing mode of /opt/conda/envs/pytorch/bin/rpyc_classic.py to 755
changing mode of /opt/conda/envs/pytorch/bin/rpyc_registry to 755
changing mode of /opt/conda/envs/pytorch/bin/rpyc_registry.py to 755
changing mode of /opt/conda/envs/pytorch/bin/markdown-it to 755
changing mode of /opt/conda/envs/pytorch/bin/huggingface-cli to 755
changing mode of /opt/conda/envs/pytorch/bin/pre-commit to 755
changing mode of /opt/conda/envs/pytorch/bin/diffusers-cli to 755
changing mode of /opt/conda/envs/pytorch/bin/accelerate to 755
changing mode of /opt/conda/envs/pytorch/bin/accelerate-config to 755
changing mode of /opt/conda/envs/pytorch/bin/accelerate-estimate-memory to 755
changing mode of /opt/conda/envs/pytorch/bin/accelerate-launch to 755
changing mode of /opt/conda/envs/pytorch/bin/accelerate-merge-weights to 755
changing mode of /opt/conda/envs/pytorch/bin/transformers-cli to 755
changing mode of /opt/conda/envs/pytorch/bin/jsonschema to 755
changing mode of /opt/conda/envs/pytorch/bin/fastapi to 755
changing mode of /opt/conda/envs/pytorch/bin/ray to 755
changing mode of /opt/conda/envs/pytorch/bin/serve to 755
changing mode of /opt/conda/envs/pytorch/bin/tune to 755
changing mode of /opt/conda/envs/pytorch/bin/fab to 755
Running setup.py develop for colossalai
Running command python setup.py develop
[extension] Building extensionscpu_adam_x86, layernorm_cuda, moe_cuda, fused_optim_cuda, inference_ops_cuda, scaled_masked_softmax_cuda, scaled_upper_triangle_masked_softmax_cuda
running develop
/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.
!!
2025-04-11T02:46:41.2544482Z
********************************************************************************
Please avoid running ``setup.py`` and ``easy_install``.
Instead, use pypa/build, pypa/installer or other
standards-based tools.
2025-04-11T02:46:41.2549382Z
See https://github.com/pypa/setuptools/issues/917 for details.
********************************************************************************
2025-04-11T02:46:41.2552168Z
!!
easy_install.initialize_options(self)
/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!
2025-04-11T02:46:41.2608478Z
********************************************************************************
Please avoid running ``setup.py`` directly.
Instead, use pypa/build, pypa/installer or other
standards-based tools.
2025-04-11T02:46:41.2613247Z
See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
********************************************************************************
2025-04-11T02:46:41.2616089Z
!!
self.initialize_options()
running egg_info
creating colossalai.egg-info
writing colossalai.egg-info/PKG-INFO
writing dependency_links to colossalai.egg-info/dependency_links.txt
writing entry points to colossalai.egg-info/entry_points.txt
writing requirements to colossalai.egg-info/requires.txt
writing top-level names to colossalai.egg-info/top_level.txt
writing manifest file 'colossalai.egg-info/SOURCES.txt'
reading manifest file 'colossalai.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
warning: no files found matching '*.tr' under directory 'colossalai'
warning: no files found matching '*.cc' under directory 'colossalai'
warning: no files found matching '*.pyi' under directory 'colossalai'
warning: no files found matching '*.tr' under directory 'extensions'
warning: no files found matching '*.cc' under directory 'extensions'
warning: no files found matching '*.pyi' under directory 'extensions'
adding license file 'LICENSE'
writing manifest file 'colossalai.egg-info/SOURCES.txt'
running build_ext
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no g++ version bounds defined for CUDA version 12.1
warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
building 'colossalai._C.cpu_adam_x86' extension
creating /__w/ColossalAI/ColossalAI/build
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -std=c++14 -std=c++17 -lcudart -lcublas -g -Wno-reorder -fopenmp -march=native -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=cpu_adam_x86 -D_GLIBCXX_USE_CXX11_ABI=0
/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.cpp:237: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
237 #pragma unroll 4
|
/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.cpp:352: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
352 #pragma unroll 8
|
In file included from /opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/Exceptions.h:14,
from /opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11,
from /opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/extension.h:9,
from /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.h:29,
from /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.cpp:22:
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<Adam_Optimizer>’:
/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.cpp:443:51:   required from here
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/pybind11/pybind11.h:1496:7: warning: ‘pybind11::class_<Adam_Optimizer>’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]
1496 | class class_ : public detail::generic_type {
^~~~~~
creating build/lib.linux-x86_64-cpython-310
creating build/lib.linux-x86_64-cpython-310/colossalai
creating build/lib.linux-x86_64-cpython-310/colossalai/_C
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/x86/cpu_adam.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/cpu_adam_x86.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.layernorm_cuda' extension
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/layernorm
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/layernorm/layer_norm.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/usr/local/cuda/include -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/layernorm/layer_norm.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/layernorm/layer_norm.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=layernorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/layer_norm_kernel.o.d -I/usr/local/cuda/include -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/layer_norm_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/layer_norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -maxrregcount=50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=layernorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/layer_norm_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/layernorm/layer_norm.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/layernorm_cuda.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.moe_cuda' extension
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/moe
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/moe/moe.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/moe/moe.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/moe/moe.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=moe_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/moe_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/moe_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/moe_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=moe_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/moe_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/moe/moe.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/moe_cuda.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.fused_optim_cuda' extension
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/optimizer
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/6] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/optimizer/optimizer.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/optimizer/optimizer.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/optimizer/optimizer.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/6] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_scale_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_scale_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[3/6] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_l2norm_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_l2norm_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[4/6] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_lamb_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_lamb_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_lamb_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[5/6] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_sgd_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_sgd_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[6/6] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_adam_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_adam_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_adam_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_optim_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_adam_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_l2norm_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_lamb_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_scale_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/multi_tensor_sgd_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/optimizer/optimizer.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/fused_optim_cuda.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.inference_ops_cuda' extension
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/inference
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/9] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/inference/inference.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/inference/inference.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/inference/inference.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/get_cos_and_sin_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/get_cos_and_sin_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/get_cos_and_sin_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[3/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/convert_fp8_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/convert_fp8_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/convert_fp8_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[4/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/activation_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/activation_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/activation_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[5/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/rms_layernorm_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/rms_layernorm_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/rms_layernorm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[6/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/context_kv_cache_memcpy_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/context_kv_cache_memcpy_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/context_kv_cache_memcpy_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[7/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/decode_kv_cache_memcpy_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/decode_kv_cache_memcpy_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/decode_kv_cache_memcpy_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[8/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/fused_rotary_emb_and_cache_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/fused_rotary_emb_and_cache_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/fused_rotary_emb_and_cache_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[9/9] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/flash_decoding_attention_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/flash_decoding_attention_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/flash_decoding_attention_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=inference_ops_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/activation_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/context_kv_cache_memcpy_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/convert_fp8_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/decode_kv_cache_memcpy_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/flash_decoding_attention_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/fused_rotary_emb_and_cache_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/get_cos_and_sin_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/rms_layernorm_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/inference/inference.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/inference_ops_cuda.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.scaled_masked_softmax_cuda' extension
creating /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_masked_softmax.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_masked_softmax.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_masked_softmax_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_masked_softmax_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_masked_softmax_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -std=c++14 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90
nvcc warning : incompatible redefinition for option 'std', the last value of this option was used
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_masked_softmax_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_masked_softmax.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so
building 'colossalai._C.scaled_upper_triangle_masked_softmax_cuda' extension
Emitting ninja build file /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_upper_triang_masked_softmax.o.d -pthread -B /opt/conda/envs/pytorch/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -O2 -isystem /opt/conda/envs/pytorch/include -fPIC -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_upper_triang_masked_softmax.cpp -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_upper_triangle_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_upper_triang_masked_softmax_kernel.o.d -I/__w/ColossalAI/ColossalAI/extensions/csrc/ -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/envs/pytorch/include/python3.10 -c -c /__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_upper_triang_masked_softmax_kernel.cu -o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_upper_triang_masked_softmax_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DCOLOSSAL_WITH_CUDA -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_upper_triangle_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
g++ -pthread -B /opt/conda/envs/pytorch/compiler_compat -shared -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib -Wl,-rpath,/opt/conda/envs/pytorch/lib -Wl,-rpath-link,/opt/conda/envs/pytorch/lib -L/opt/conda/envs/pytorch/lib /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/csrc/kernel/cuda/scaled_upper_triang_masked_softmax_kernel.o /__w/ColossalAI/ColossalAI/build/temp.linux-x86_64-cpython-310/__w/ColossalAI/ColossalAI/extensions/pybind/softmax/scaled_upper_triang_masked_softmax.o -L/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/colossalai/_C/scaled_upper_triangle_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/cpu_adam_x86.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/layernorm_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/moe_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/fused_optim_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/inference_ops_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
copying build/lib.linux-x86_64-cpython-310/colossalai/_C/scaled_upper_triangle_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> colossalai/_C
Creating /opt/conda/envs/pytorch/lib/python3.10/site-packages/colossalai.egg-link (link to .)
Adding colossalai 0.4.9 to easy-install.pth file
Installing colossalai script to /opt/conda/envs/pytorch/bin
2025-04-11T03:01:50.3016748Z
Installed /__w/ColossalAI/ColossalAI
Successfully installed accelerate-1.6.0 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 bcrypt-4.3.0 beautifulsoup4-4.13.3 bitsandbytes-0.45.5 cffi-1.17.1 cfgv-3.4.0 colossalai-0.4.9 contexttimer-0.3.3 cryptography-44.0.2 decorator-5.2.1 deprecated-1.2.18 diffusers-0.29.0 distlib-0.3.9 einops-0.8.1 exceptiongroup-1.2.2 fabric-3.2.2 fastapi-0.115.12 frozenlist-1.5.0 galore_torch-1.0 google-3.0.0 h11-0.14.0 huggingface-hub-0.30.2 identify-2.6.9 importlib-metadata-8.6.1 invoke-2.2.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 nodeenv-1.9.1 paramiko-3.5.1 peft-0.13.2 platformdirs-4.3.7 plumbum-1.9.0 pre-commit-4.2.0 protobuf-6.30.2 psutil-7.0.0 pycparser-2.22 pydantic-2.11.3 pydantic-core-2.33.1 pygments-2.19.1 pynacl-1.5.0 ray-2.44.1 referencing-0.36.2 regex-2024.11.6 rich-14.0.0 rpds-py-0.24.0 rpyc-6.0.0 safetensors-0.5.3 sentencepiece-0.2.0 sniffio-1.3.1 soupsieve-2.6 starlette-0.46.1 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.39.3 typing-extensions-4.13.2 typing-inspection-0.4.0 uvicorn-0.29.0 virtualenv-20.30.0 wrapt-1.17.2 zipp-3.21.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Collecting git+https://github.com/hpcaitech/pytest-testmon (from -r requirements/requirements-test.txt (line 3))
Cloning https://github.com/hpcaitech/pytest-testmon to /tmp/pip-req-build-bt6w8jkb
Running command git clone --filter=blob:none --quiet https://github.com/hpcaitech/pytest-testmon /tmp/pip-req-build-bt6w8jkb
Resolved https://github.com/hpcaitech/pytest-testmon to commit be30f4ac384656daae1a9157e6de97825caaf0ba
Installing build dependencies: started
Installing build dependencies: finished with status 'done'
Getting requirements to build wheel: started
Getting requirements to build wheel: finished with status 'done'
Preparing metadata (pyproject.toml): started
Preparing metadata (pyproject.toml): finished with status 'done'
Collecting pytest (from -r requirements/requirements-test.txt (line 1))
pytest-8.3.5-py3-none-any.whl.metadata (7.6
Collecting coverage==7.2.3 (from -r requirements/requirements-test.txt (line 2))
Downloading coverage-7.2.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)
Requirement already satisfied: torchvision in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 4)) (0.17.2)
Collecting timm (from -r requirements/requirements-test.txt (line 5))
timm-1.0.15-py3-none-any.whl.metadata (52
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.0/52.0 kB 377.5 kB/s eta 0:00:00
Collecting titans (from -r requirements/requirements-test.txt (line 6))
titans-0.0.7.tar.gz (38
Preparing metadata (setup.py): started
Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: torchaudio>=0.13.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 7)) (2.2.2)
Collecting torchx-nightly==2022.6.29 (from -r requirements/requirements-test.txt (line 8))
torchx nightly-2022.6.29-py3-none-any.whl.metadata (4.9
Collecting torchrec==0.2.0 (from -r requirements/requirements-test.txt (line 9))
torchrec-0.2.0-py39-none-any.whl.metadata (6.7
Requirement already satisfied: contexttimer in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 10)) (0.3.3)
Requirement already satisfied: einops in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 11)) (0.8.1)
Requirement already satisfied: triton in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 12)) (2.2.0)
Collecting requests==2.27.1 (from -r requirements/requirements-test.txt (line 13))
requests-2.27.1-py2.py3-none-any.whl.metadata (5.0
Requirement already satisfied: SentencePiece in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 14)) (0.2.0)
Requirement already satisfied: ninja in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 15)) (1.11.1.1)
Collecting flash_attn (from -r requirements/requirements-test.txt (line 16))
Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)
6 0 6 0 MB 12 1 0 00 00
Preparing metadata (setup.py): started
Preparing metadata (setup.py): finished with status 'done'
Collecting datasets (from -r requirements/requirements-test.txt (line 17))
datasets-3.5.0-py3-none-any.whl.metadata (19
Requirement already satisfied: pydantic in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 18)) (2.11.3)
Requirement already satisfied: ray in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 19)) (2.44.1)
Requirement already satisfied: peft>=0.7.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r requirements/requirements-test.txt (line 20)) (0.13.2)
Collecting pyre-extensions (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8))
pyre extensions-0.0.32-py3-none-any.whl.metadata (4.0
Collecting docstring-parser==0.8.1 (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8))
docstring parser-0.8.1.tar.gz (14
Installing build dependencies: started
Installing build dependencies: finished with status 'done'
Getting requirements to build wheel: started
Getting requirements to build wheel: finished with status 'done'
Preparing metadata (pyproject.toml): started
Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: pyyaml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8)) (6.0.1)
Collecting docker (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8))
docker-7.1.0-py3-none-any.whl.metadata (3.8
Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8)) (3.13.1)
Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8)) (2024.6.1)
Collecting arrow (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
arrow-1.3.0-py3-none-any.whl.metadata (7.5
Requirement already satisfied: attrs in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (25.3.0)
Requirement already satisfied: certifi in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (2024.6.2)
Requirement already satisfied: charset-normalizer in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (2.0.4)
Collecting cmake (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
Collecting Cython (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)
Collecting distro (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
distro-1.9.0-py3-none-any.whl.metadata (6.8
Collecting hypothesis (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
hypothesis-6.131.0-py3-none-any.whl.metadata (5.6
Requirement already satisfied: idna in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (3.7)
Collecting iopath (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
iopath-0.1.10.tar.gz (42
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.2/42.2 kB 556.6 kB/s eta 0:00:00
Preparing metadata (setup.py): started
Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: Jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (3.1.4)
Requirement already satisfied: MarkupSafe in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (2.1.3)
Collecting mypy-extensions (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
mypy extensions-1.0.0-py3-none-any.whl.metadata (1.1
Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (1.26.4)
Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (24.1)
Collecting pandas (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
89 9 89 9 kB 1 4 0 00 00
Collecting portalocker (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
portalocker-3.1.1-py3-none-any.whl.metadata (8.6
Collecting pyarrow (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting pyDeprecate (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
pyDeprecate-0.3.2-py3-none-any.whl.metadata (10
Collecting pyparsing (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
pyparsing-3.2.3-py3-none-any.whl.metadata (5.0
Collecting pyre-extensions (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8))
pyre extensions-0.0.27-py3-none-any.whl.metadata (4.0
Collecting python-dateutil (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
python dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4
Collecting pytz (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
pytz-2025.2-py2.py3-none-any.whl.metadata (22
Collecting scikit-build (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
scikit build-0.18.1-py3-none-any.whl.metadata (18
Collecting six (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
six-1.17.0-py2.py3-none-any.whl.metadata (1.7
Collecting sortedcontainers (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10
Collecting tabulate (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
tabulate-0.9.0-py3-none-any.whl.metadata (34
Collecting torchmetrics (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
torchmetrics-1.7.1-py3-none-any.whl.metadata (21
Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (4.67.1)
Collecting typing-inspect (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
typing inspect-0.9.0-py3-none-any.whl.metadata (1.5
Requirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (4.13.2)
Requirement already satisfied: urllib3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (2.2.2)
Collecting usort (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
usort-1.0.8.post1-py3-none-any.whl.metadata (3.5
Collecting websocket-client (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
websocket client-1.8.0-py3-none-any.whl.metadata (8.0
Collecting fbgemm-gpu (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading fbgemm_gpu-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (2.8 kB)
Collecting urllib3 (from torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
urllib3-1.26.20-py2.py3-none-any.whl.metadata (50
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 692.3 kB/s eta 0:00:00
Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pytest->-r requirements/requirements-test.txt (line 1)) (1.2.2)
Collecting iniconfig (from pytest->-r requirements/requirements-test.txt (line 1))
iniconfig-2.1.0-py3-none-any.whl.metadata (2.7
Collecting pluggy<2,>=1.5 (from pytest->-r requirements/requirements-test.txt (line 1))
pluggy-1.5.0-py3-none-any.whl.metadata (4.8
Collecting tomli>=1 (from pytest->-r requirements/requirements-test.txt (line 1))
tomli-2.2.1-py3-none-any.whl.metadata (10
Collecting pytest (from -r requirements/requirements-test.txt (line 1))
pytest-7.4.4-py3-none-any.whl.metadata (7.9
Collecting requirements-parser (from pytest-testmon==2.0.7b1->-r requirements/requirements-test.txt (line 3))
requirements parser-0.11.0-py3-none-any.whl.metadata (4.7
Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision->-r requirements/requirements-test.txt (line 4)) (2.2.2)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision->-r requirements/requirements-test.txt (line 4)) (10.3.0)
Requirement already satisfied: huggingface_hub in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from timm->-r requirements/requirements-test.txt (line 5)) (0.30.2)
Requirement already satisfied: safetensors in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from timm->-r requirements/requirements-test.txt (line 5)) (0.5.3)
Requirement already satisfied: colossalai in /__w/ColossalAI/ColossalAI (from titans->-r requirements/requirements-test.txt (line 6)) (0.4.9)
Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements/requirements-test.txt (line 17))
dill-0.3.8-py3-none-any.whl.metadata (10
INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.
Collecting datasets (from -r requirements/requirements-test.txt (line 17))
datasets-3.4.1-py3-none-any.whl.metadata (19
datasets-3.4.0-py3-none-any.whl.metadata (19
datasets-3.3.2-py3-none-any.whl.metadata (19
datasets-3.3.1-py3-none-any.whl.metadata (19
datasets-3.3.0-py3-none-any.whl.metadata (19
datasets-3.2.0-py3-none-any.whl.metadata (20
datasets-3.1.0-py3-none-any.whl.metadata (20
INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.
datasets-3.0.2-py3-none-any.whl.metadata (20
datasets-3.0.1-py3-none-any.whl.metadata (20
datasets-3.0.0-py3-none-any.whl.metadata (19
datasets-2.21.0-py3-none-any.whl.metadata (21
datasets-2.20.0-py3-none-any.whl.metadata (19
Collecting pyarrow-hotfix (from datasets->-r requirements/requirements-test.txt (line 17))
pyarrow hotfix-0.6-py3-none-any.whl.metadata (3.6
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
Collecting datasets (from -r requirements/requirements-test.txt (line 17))
datasets-2.19.2-py3-none-any.whl.metadata (19
datasets-2.19.1-py3-none-any.whl.metadata (19
Collecting xxhash (from datasets->-r requirements/requirements-test.txt (line 17))
Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess (from datasets->-r requirements/requirements-test.txt (line 17))
multiprocess-0.70.17-py310-none-any.whl.metadata (7.2
Collecting fsspec (from torchx-nightly==2022.6.29->-r requirements/requirements-test.txt (line 8))
fsspec-2024.3.1-py3-none-any.whl.metadata (6.8
Collecting aiohttp (from datasets->-r requirements/requirements-test.txt (line 17))
Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pydantic->-r requirements/requirements-test.txt (line 18)) (0.7.0)
Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pydantic->-r requirements/requirements-test.txt (line 18)) (2.33.1)
Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pydantic->-r requirements/requirements-test.txt (line 18)) (0.4.0)
Requirement already satisfied: click>=7.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (8.1.8)
Requirement already satisfied: jsonschema in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (4.23.0)
Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (1.1.0)
Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (6.30.2)
Requirement already satisfied: aiosignal in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (1.3.2)
Requirement already satisfied: frozenlist in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ray->-r requirements/requirements-test.txt (line 19)) (1.5.0)
Requirement already satisfied: psutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft>=0.7.1->-r requirements/requirements-test.txt (line 20)) (7.0.0)
Requirement already satisfied: transformers in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft>=0.7.1->-r requirements/requirements-test.txt (line 20)) (4.39.3)
Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft>=0.7.1->-r requirements/requirements-test.txt (line 20)) (1.6.0)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r requirements/requirements-test.txt (line 17))
aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9
Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets->-r requirements/requirements-test.txt (line 17))
async timeout-5.0.1-py3-none-any.whl.metadata (5.1
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements/requirements-test.txt (line 17))
Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp->datasets->-r requirements/requirements-test.txt (line 17))
Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets->-r requirements/requirements-test.txt (line 17))
Downloading yarl-1.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)
71 8 71 8 kB 1 1 0 00 00
Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->torchvision->-r requirements/requirements-test.txt (line 4)) (1.12)
Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->torchvision->-r requirements/requirements-test.txt (line 4)) (3.2.1)
Collecting types-python-dateutil>=2.8.10 (from arrow->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)
Requirement already satisfied: pre-commit in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (4.2.0)
Requirement already satisfied: rich in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (14.0.0)
Requirement already satisfied: fabric in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.2.2)
Requirement already satisfied: google in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.0.0)
Requirement already satisfied: bitsandbytes>=0.39.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.45.5)
Requirement already satisfied: rpyc==6.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (6.0.0)
Requirement already satisfied: fastapi in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.115.12)
Requirement already satisfied: uvicorn==0.29.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.29.0)
Requirement already satisfied: galore_torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.0)
Requirement already satisfied: diffusers==0.29.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.29.0)
Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->peft>=0.7.1->-r requirements/requirements-test.txt (line 20)) (2024.11.6)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->peft>=0.7.1->-r requirements/requirements-test.txt (line 20)) (0.15.2)
Requirement already satisfied: importlib-metadata in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from diffusers==0.29.0->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (8.6.1)
Requirement already satisfied: plumbum in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rpyc==6.0.0->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.9.0)
Requirement already satisfied: h11>=0.8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from uvicorn==0.29.0->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.14.0)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema->ray->-r requirements/requirements-test.txt (line 19)) (2024.10.1)
Requirement already satisfied: referencing>=0.28.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema->ray->-r requirements/requirements-test.txt (line 19)) (0.36.2)
Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema->ray->-r requirements/requirements-test.txt (line 19)) (0.24.0)
INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.
Collecting multiprocess (from datasets->-r requirements/requirements-test.txt (line 17))
multiprocess-0.70.16-py310-none-any.whl.metadata (7.2
Collecting tzdata>=2022.7 (from pandas->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4
Collecting types-setuptools>=69.1.0 (from requirements-parser->pytest-testmon==2.0.7b1->-r requirements/requirements-test.txt (line 3))
types setuptools-78.1.0.20250329-py3-none-any.whl.metadata (2.2
Requirement already satisfied: setuptools>=42.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from scikit-build->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (69.5.1)
Requirement already satisfied: wheel>=0.32.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from scikit-build->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9)) (0.43.0)
Collecting lightning-utilities>=0.8.0 (from torchmetrics->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
lightning utilities-0.14.3-py3-none-any.whl.metadata (5.6
Collecting LibCST>=0.3.7 (from usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
Downloading libcst-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)
Collecting moreorless>=0.3.0 (from usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
moreorless-0.4.0-py2.py3-none-any.whl.metadata (1.5
Collecting stdlibs>=2021.4.1 (from usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
stdlibs-2025.4.4-py3-none-any.whl.metadata (5.0
Collecting toml>=0.10.0 (from usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
toml-0.10.2-py2.py3-none-any.whl.metadata (7.1
Collecting trailrunner>=1.0 (from usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
trailrunner-1.4.0-py3-none-any.whl.metadata (4.2
Collecting pathspec>=0.8.1 (from trailrunner>=1.0->usort->torchrec==0.2.0->-r requirements/requirements-test.txt (line 9))
pathspec-0.12.1-py3-none-any.whl.metadata (21
Requirement already satisfied: invoke>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (2.2.0)
Requirement already satisfied: paramiko>=2.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.5.1)
Requirement already satisfied: decorator>=5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (5.2.1)
Requirement already satisfied: deprecated>=1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.2.18)
Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fastapi->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.46.1)
Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from google->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (4.13.3)
Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.4.0)
Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (2.6.9)
Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.9.1)
Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (20.30.0)
Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (2.19.1)
Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch->torchvision->-r requirements/requirements-test.txt (line 4)) (1.3.0)
Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from deprecated>=1.2->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.17.2)
Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.1.2)
Requirement already satisfied: bcrypt>=3.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from paramiko>=2.4->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (4.3.0)
Requirement already satisfied: cryptography>=3.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from paramiko>=2.4->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (44.0.2)
Requirement already satisfied: pynacl>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from paramiko>=2.4->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.5.0)
Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (4.9.0)
Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (0.3.9)
Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (4.3.7)
Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from beautifulsoup4->google->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (2.6)
Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.29.0->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (3.21.0)
Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.3.1)
Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (1.17.1)
Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai->titans->-r requirements/requirements-test.txt (line 6)) (2.22)
Downloading coverage-7.2.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)
228 0 228 0 kB 3 0 0 00 00
torchx nightly-2022.6.29-py3-none-any.whl (177
177 8 177 8 kB 2 4 0 00 00
torchrec-0.2.0-py39-none-any.whl (293
293 4 293 4 kB 4 0 0 00 00
requests-2.27.1-py2.py3-none-any.whl (63
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 756.1 kB/s eta 0:00:00
pyre extensions-0.0.27-py3-none-any.whl (12
pytest-7.4.4-py3-none-any.whl (325
325 3 325 3 kB 4 4 0 00 00
Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)
2 4 2 4 MB 15 1 0 00 00
datasets-2.19.1-py3-none-any.whl (542
542 0 542 0 kB 7 5 0 00 00
dill-0.3.8-py3-none-any.whl (116
116 3 116 3 kB 1 5 0 00 00
fsspec-2024.3.1-py3-none-any.whl (171
172 0 172 0 kB 2 3 0 00 00
Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
1 6 1 6 MB 22 6 0 00 00
pluggy-1.5.0-py3-none-any.whl (20
Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)
42 1 42 1 MB 28 1 0 00 00
tomli-2.2.1-py3-none-any.whl (14
urllib3-1.26.20-py2.py3-none-any.whl (144
144 2 144 2 kB 1 9 0 00 00
arrow-1.3.0-py3-none-any.whl (66
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 809.2 kB/s eta 0:00:00
python dateutil-2.9.0.post0-py2.py3-none-any.whl (229
229 9 229 9 kB 3 1 0 00 00
six-1.17.0-py2.py3-none-any.whl (11
Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)
27 9 27 9 MB 31 9 0 00 00
Downloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
3 6 3 6 MB 34 9 0 00 00
distro-1.9.0-py3-none-any.whl (20
docker-7.1.0-py3-none-any.whl (147
147 8 147 8 kB 1 9 0 00 00
Downloading fbgemm_gpu-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (417.2 MB)
417 2 417 2 MB 26 3 0 00 00
hypothesis-6.131.0-py3-none-any.whl (495
495 7 495 7 kB 7 0 0 00 00
sortedcontainers-2.4.0-py2.py3-none-any.whl (29
iniconfig-2.1.0-py3-none-any.whl (6.0
multiprocess-0.70.16-py310-none-any.whl (134
134 8 134 8 kB 1 8 0 00 00
mypy extensions-1.0.0-py3-none-any.whl (4.7
Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
13 1 13 1 MB 31 6 0 00 00
pytz-2025.2-py2.py3-none-any.whl (509
509 2 509 2 kB 7 1 0 00 00
portalocker-3.1.1-py3-none-any.whl (19
pyarrow hotfix-0.6-py3-none-any.whl (7.9
pyDeprecate-0.3.2-py3-none-any.whl (10
pyparsing-3.2.3-py3-none-any.whl (111
111 1 111 1 kB 1 4 0 00 00
requirements parser-0.11.0-py3-none-any.whl (14
scikit build-0.18.1-py3-none-any.whl (85
85 6 85 6 kB 1 1 0 00 00
tabulate-0.9.0-py3-none-any.whl (35
torchmetrics-1.7.1-py3-none-any.whl (961
961 5 961 5 kB 13 5 0 00 00
typing inspect-0.9.0-py3-none-any.whl (8.8
usort-1.0.8.post1-py3-none-any.whl (37
websocket client-1.8.0-py3-none-any.whl (58
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 687.9 kB/s eta 0:00:00
Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
194 1 194 1 kB 2 6 0 00 00
aiohappyeyeballs-2.6.1-py3-none-any.whl (15
async timeout-5.0.1-py3-none-any.whl (6.2
Downloading libcst-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2 3 2 3 MB 32 9 0 00 00
lightning utilities-0.14.3-py3-none-any.whl (28
moreorless-0.4.0-py2.py3-none-any.whl (9.3
Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)
219 8 219 8 kB 3 0 0 00 00
Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)
206 6 206 6 kB 2 8 0 00 00
stdlibs-2025.4.4-py3-none-any.whl (57
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.2/57.2 kB 668.4 kB/s eta 0:00:00
toml-0.10.2-py2.py3-none-any.whl (16
trailrunner-1.4.0-py3-none-any.whl (11
Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)
types setuptools-78.1.0.20250329-py3-none-any.whl (66
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 804.9 kB/s eta 0:00:00
tzdata-2025.2-py2.py3-none-any.whl (347
347 8 347 8 kB 4 8 0 00 00
Downloading yarl-1.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (334 kB)
334 0 334 0 kB 4 6 0 00 00
pathspec-0.12.1-py3-none-any.whl (31
Building wheels for collected packages: docstring-parser, pytest-testmon, titans, flash_attn, iopath
Building wheel for docstring-parser (pyproject.toml): started
Building wheel for docstring-parser (pyproject.toml): finished with status 'done'
Created wheel for docstring-parser: filename=docstring_parser-0.8.1-py3-none-any.whl size=19697 sha256=775e80388768cdc758ea2ef1a0e81769d7db301de7a831e2666a9f13bd7f9ee7
Stored in directory: /tmp/pip-ephem-wheel-cache-tdhc_r7k/wheels/26/e4/54/64439f1d0c5d3721041ddc0f001e4b57756a394880a2af8981
Building wheel for pytest-testmon (pyproject.toml): started
Building wheel for pytest-testmon (pyproject.toml): finished with status 'done'
Created wheel for pytest-testmon: filename=pytest_testmon-2.0.7b1-py3-none-any.whl size=35044 sha256=11019945d24c9bcd6e5e00b552e052d01c094acdd206db61f39706451b2380a5
Stored in directory: /tmp/pip-ephem-wheel-cache-tdhc_r7k/wheels/cb/f6/db/609602674f7b7c7ecbfd91b3d67b1ea34fe598f7e344495c44
Building wheel for titans (setup.py): started
Building wheel for titans (setup.py): finished with status 'done'
Created wheel for titans: filename=titans-0.0.7-py3-none-any.whl size=63319 sha256=797aaaf0091a5bd0638f7130c2450194ffce491e0b6f983d66b8c641ac1af022
Stored in directory: /tmp/pip-ephem-wheel-cache-tdhc_r7k/wheels/65/21/1b/3dfb7cdd10cdc650f08fbb72b6f28dd75e1e9b7b42f6695a16
Building wheel for flash_attn (setup.py): started
Building wheel for flash_attn (setup.py): finished with status 'done'
Created wheel for flash_attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187696268 sha256=1776769f7ae3a8be3b31ec3a4c875ad1764da74be2d9b1751e5c01162ad0096f
Stored in directory: /tmp/pip-ephem-wheel-cache-tdhc_r7k/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca
Building wheel for iopath (setup.py): started
Building wheel for iopath (setup.py): finished with status 'done'
Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=10c7319faeecfecf51f8c3a59fb4a914d15a20ef8b8a726e0357ef2b5bb3fb14
Stored in directory: /tmp/pip-ephem-wheel-cache-tdhc_r7k/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d
Successfully built docstring-parser pytest-testmon titans flash_attn iopath
Installing collected packages: sortedcontainers, pytz, xxhash, websocket-client, urllib3, tzdata, types-setuptools, types-python-dateutil, tomli, toml, tabulate, stdlibs, six, pyparsing, pyDeprecate, pyarrow-hotfix, pyarrow, propcache, portalocker, pluggy, pathspec, mypy-extensions, multidict, moreorless, lightning-utilities, LibCST, iniconfig, hypothesis, fsspec, fbgemm-gpu, docstring-parser, distro, dill, Cython, coverage, cmake, async-timeout, aiohappyeyeballs, yarl, typing-inspect, trailrunner, scikit-build, requirements-parser, requests, python-dateutil, pytest, multiprocess, iopath, usort, torchmetrics, pytest-testmon, pyre-extensions, pandas, flash_attn, docker, arrow, aiohttp, torchx-nightly, timm, torchrec, datasets, titans
Attempting uninstall: urllib3
Found existing installation: urllib3 2.2.2
Uninstalling urllib3-2.2.2:
Successfully uninstalled urllib3-2.2.2
Attempting uninstall: fsspec
Found existing installation: fsspec 2024.6.1
Uninstalling fsspec-2024.6.1:
Successfully uninstalled fsspec-2024.6.1
Attempting uninstall: requests
Found existing installation: requests 2.32.2
Uninstalling requests-2.32.2:
Successfully uninstalled requests-2.32.2
Successfully installed Cython-3.0.12 LibCST-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 arrow-1.3.0 async-timeout-5.0.1 cmake-4.0.0 coverage-7.2.3 datasets-2.19.1 dill-0.3.8 distro-1.9.0 docker-7.1.0 docstring-parser-0.8.1 fbgemm-gpu-1.1.0 flash_attn-2.7.4.post1 fsspec-2024.3.1 hypothesis-6.131.0 iniconfig-2.1.0 iopath-0.1.10 lightning-utilities-0.14.3 moreorless-0.4.0 multidict-6.4.3 multiprocess-0.70.16 mypy-extensions-1.0.0 pandas-2.2.3 pathspec-0.12.1 pluggy-1.5.0 portalocker-3.1.1 propcache-0.3.1 pyDeprecate-0.3.2 pyarrow-19.0.1 pyarrow-hotfix-0.6 pyparsing-3.2.3 pyre-extensions-0.0.27 pytest-7.4.4 pytest-testmon-2.0.7b1 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.27.1 requirements-parser-0.11.0 scikit-build-0.18.1 six-1.17.0 sortedcontainers-2.4.0 stdlibs-2025.4.4 tabulate-0.9.0 timm-1.0.15 titans-0.0.7 toml-0.10.2 tomli-2.2.1 torchmetrics-1.7.1 torchrec-0.2.0 torchx-nightly-2022.6.29 trailrunner-1.4.0 types-python-dateutil-2.9.0.20241206 types-setuptools-78.1.0.20250329 typing-inspect-0.9.0 tzdata-2025.2 urllib3-1.26.20 usort-1.0.8.post1 websocket-client-1.8.0 xxhash-3.5.0 yarl-1.19.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
##[group]Run # -p flag is required to preserve the file timestamp to avoid ninja rebuild
[36;1m# -p flag is required to preserve the file timestamp to avoid ninja rebuild[0m
[36;1mcp -p -r /__w/ColossalAI/ColossalAI/build /github/home/cuda_ext_cache/[0m
shell: bash --noprofile --norc -e -o pipefail {0}
##[endgroup]
##[group]Run CURL_CA_BUNDLE="" PYTHONPATH=$PWD FAST_TEST=1 pytest \
[36;1mCURL_CA_BUNDLE="" PYTHONPATH=$PWD FAST_TEST=1 pytest \[0m
[36;1m-m "not largedist" \[0m
[36;1m--durations=0 \[0m
[36;1m--ignore tests/test_analyzer \[0m
[36;1m--ignore tests/test_auto_parallel \[0m
[36;1m--ignore tests/test_fx \[0m
[36;1m--ignore tests/test_autochunk \[0m
[36;1m--ignore tests/test_gptq \[0m
[36;1m--ignore tests/test_infer_ops \[0m
[36;1m--ignore tests/test_legacy \[0m
[36;1m--ignore tests/test_smoothquant \[0m
[36;1mtests/test_booster/test_mixed_precision/test_fp16_torch.py[0m
shell: bash --noprofile --norc -e -o pipefail {0}

LD_LIBRARY_PATH: /github/home/.tensornvme/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
LLAMA_PATH: /data/scratch/llama-tiny
MOE_TENSOR_PATH: /data/scratch/moe_tensors
HF_ENDPOINT: https://hf-mirror.com
##[endgroup]
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.4, pluggy-1.5.0
rootdir: /__w/ColossalAI/ColossalAI
configfile: pytest.ini
plugins: hypothesis-6.131.0, anyio-4.9.0, testmon-2.0.7b1
collected 1 item
2025-04-11T03:03:49.0705053Z
tests/test_booster/test_mixed_precision/test_fp16_torch.py F             [100%]
2025-04-11T03:03:55.1255993Z
=================================== FAILURES ===================================
____________________________ test_torch_ddp_plugin _____________________________
2025-04-11T03:03:55.1256632Z
args = (), kwargs = {}, try_count = 1
error_lines = ['', '', '-- Process 0 terminated with the following error:', 'Traceback (most recent call last):', '  File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap', '    fn(i, *args)', ...]
2025-04-11T03:03:55.1258203Z
def _run_until_success(*args, **kwargs):
try_count = 0
assert max_try is None or isinstance(
max_try, int
), f"Expected max_try to be None or int, but got {type(max_try)}"
2025-04-11T03:03:55.1259619Z
while max_try is None or try_count < max_try:
try:
try_count += 1
ret = func(*args, **kwargs)
return ret
except exception_type as e:
error_lines = str(e).split("\n")
if try_count < max_try and (pattern is None or _match_lines(error_lines, pattern)):
print("Exception is caught, retrying...")
# when pattern is not specified, we always skip the exception
# when pattern is specified, we only skip when pattern is matched
continue
else:
print("Maximum number of attempts is reached or pattern is not matched, no more retrying...")
>                   raise e
2025-04-11T03:03:55.1264375Z
colossalai/testing/utils.py:144:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
colossalai/testing/utils.py:133: in _run_until_success
ret = func(*args, **kwargs)
tests/test_booster/test_mixed_precision/test_fp16_torch.py:40: in test_torch_ddp_plugin
spawn(run_torch_amp, 1)
colossalai/testing/utils.py:252: in spawn
mp.spawn(wrapped_func, nprocs=nprocs)
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:241: in spawn
return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197: in start_processes
while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
2025-04-11T03:03:55.1268967Z
self = <torch.multiprocessing.spawn.ProcessContext object at 0x7f1c7ce77f70>
timeout = None
2025-04-11T03:03:55.1269653Z
def join(self, timeout=None):
r"""Join one or more processes within spawn context.
2025-04-11T03:03:55.1270271Z
Attempt to join one or more processes in this spawn context.
If one of them exited with a non-zero exit status, this function
kills the remaining processes and raises an exception with the cause
of the first process exiting.
2025-04-11T03:03:55.1271921Z
Returns ``True`` if all processes have been joined successfully,
``False`` if there are more processes that need to be joined.
2025-04-11T03:03:55.1272768Z
Args:
timeout (float): Wait this long before giving up on waiting.
"""
# Ensure this function can be called even when we're done.
if len(self.sentinels) == 0:
return True
2025-04-11T03:03:55.1274400Z
# Wait for any process to fail or all of them to succeed.
ready = multiprocessing.connection.wait(
self.sentinels.keys(),
timeout=timeout,
)
2025-04-11T03:03:55.1275794Z
error_index = None
for sentinel in ready:
index = self.sentinels.pop(sentinel)
process = self.processes[index]
process.join()
if process.exitcode != 0:
error_index = index
break
2025-04-11T03:03:55.1277791Z
# Return if there was no error.
if error_index is None:
# Return whether or not all processes have been joined.
return len(self.sentinels) == 0
2025-04-11T03:03:55.1279099Z
# Assume failure. Terminate processes that are still alive.
for process in self.processes:
if process.is_alive():
process.terminate()
process.join()
2025-04-11T03:03:55.1280546Z
# There won't be an error on the queue if the process crashed.
failed_process = self.processes[error_index]
if self.error_queues[error_index].empty():
exitcode = self.processes[error_index].exitcode
if exitcode < 0:
name = signal.Signals(-exitcode).name
raise ProcessExitedException(
"process %d terminated with signal %s" % (error_index, name),
error_index=error_index,
error_pid=failed_process.pid,
exit_code=exitcode,
signal_name=name,
)
else:
raise ProcessExitedException(
"process %d terminated with exit code %d" % (error_index, exitcode),
error_index=error_index,
error_pid=failed_process.pid,
exit_code=exitcode,
)
2025-04-11T03:03:55.1286009Z
original_trace = self.error_queues[error_index].get()
msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
msg += original_trace
>       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException:
E
E       -- Process 0 terminated with the following error:
E       Traceback (most recent call last):
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
E           fn(i, *args)
E         File "/__w/ColossalAI/ColossalAI/tests/test_booster/test_mixed_precision/test_fp16_torch.py", line 19, in run_torch_amp
E           model = model_fn().cuda()
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in cuda
E           return self._apply(lambda t: t.cuda(device))
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
E           module._apply(fn)
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
E           module._apply(fn)
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 825, in _apply
E           param_applied = fn(param)
E         File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in <lambda>
E           return self._apply(lambda t: t.cuda(device))
E       RuntimeError: CUDA error: out of memory
E       CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
E       For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
E       Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-04-11T03:03:55.1296367Z
/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:158: ProcessRaisedException
----------------------------- Captured stdout call -----------------------------
[04/11/25 03:03:54] INFO     colossalai - colossalai - INFO:
/__w/ColossalAI/ColossalAI/colossalai/initialize.py
:75 launch
INFO     colossalai - colossalai - INFO: Distributed
environment is initialized, world size: 1
Maximum number of attempts is reached or pattern is not matched, no more retrying...
----------------------------- Captured stderr call -----------------------------
/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.
deprecate("Transformer2DModelOutput", "1.0.0", deprecation_message)
/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
warnings.warn(
/opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'vpn.luchentech.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
warnings.warn(
/opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'vpn.luchentech.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
warnings.warn(
/opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'vpn.luchentech.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
warnings.warn(
=============================== warnings summary ===============================
colossalai/interface/model.py:45
/__w/ColossalAI/ColossalAI/colossalai/interface/model.py:45: DeprecationWarning: invalid escape sequence '\S'
to_return = {re.sub(f"lora_\S\.{adapter_name}\.(weight|bias)", "base_layer", k) for k in to_return}
2025-04-11T03:03:55.6266638Z
colossalai/interface/model.py:45
/__w/ColossalAI/ColossalAI/colossalai/interface/model.py:45: DeprecationWarning: invalid escape sequence '\.'
to_return = {re.sub(f"lora_\S\.{adapter_name}\.(weight|bias)", "base_layer", k) for k in to_return}
2025-04-11T03:03:55.6267980Z
colossalai/checkpoint_io/utils.py:862
/__w/ColossalAI/ColossalAI/colossalai/checkpoint_io/utils.py:862: DeprecationWarning: invalid escape sequence '\.'
reg = re.compile("(.*?).index((\..*)?).json")
2025-04-11T03:03:55.6269226Z
colossalai/nn/optimizer/cpu_adam.py:12
/__w/ColossalAI/ColossalAI/colossalai/nn/optimizer/cpu_adam.py:12: DeprecationWarning: invalid escape sequence '\:'
"""
2025-04-11T03:03:55.6270319Z
colossalai/nn/optimizer/fused_adam.py:15
/__w/ColossalAI/ColossalAI/colossalai/nn/optimizer/fused_adam.py:15: DeprecationWarning: invalid escape sequence '\:'
"""Implements Adam algorithm.
2025-04-11T03:03:55.6271493Z
colossalai/nn/optimizer/hybrid_adam.py:12
/__w/ColossalAI/ColossalAI/colossalai/nn/optimizer/hybrid_adam.py:12: DeprecationWarning: invalid escape sequence '\:'
"""Implements Adam algorithm.
2025-04-11T03:03:55.6272679Z
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34
/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.
deprecate("Transformer2DModelOutput", "1.0.0", deprecation_message)
2025-04-11T03:03:55.6276123Z
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:896
/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
warnings.warn(
2025-04-11T03:03:55.6278315Z
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064
../../../opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064
/opt/conda/envs/pytorch/lib/python3.10/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'vpn.luchentech.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
warnings.warn(
2025-04-11T03:03:55.6282744Z
<frozen importlib._bootstrap>:283
<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead
2025-04-11T03:03:55.6283901Z
-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
============================== slowest durations ===============================
5.95s call     tests/test_booster/test_mixed_precision/test_fp16_torch.py::test_torch_ddp_plugin
0.09s setup    tests/test_booster/test_mixed_precision/test_fp16_torch.py::test_torch_ddp_plugin
2025-04-11T03:03:55.6285652Z
(1 durations < 0.005s hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/test_booster/test_mixed_precision/test_fp16_torch.py::test_torch_ddp_plugin - torch.multiprocessing.spawn.ProcessRaisedException:
2025-04-11T03:03:55.6287120Z
-- Process 0 terminated with the following error:
Traceback (most recent call last):
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
fn(i, *args)
File "/__w/ColossalAI/ColossalAI/tests/test_booster/test_mixed_precision/test_fp16_torch.py", line 19, in run_torch_amp
model = model_fn().cuda()
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in cuda
return self._apply(lambda t: t.cuda(device))
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
module._apply(fn)
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 802, in _apply
module._apply(fn)
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 825, in _apply
param_applied = fn(param)
File "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 911, in <lambda>
return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
======================= 1 failed, 14 warnings in 13.81s ========================
##[error]Process completed with exit code 1.

##[command]/usr/bin/docker exec  f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 sh -c "cat /etc/*release | grep ^ID"

2 25 1
Temporarily overriding HOME='/__w/_temp/59eab5b6-9783-4f9a-a478-64eb97ece6a2' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /__w/ColossalAI/ColossalAI
core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader


'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'

##[command]/usr/bin/docker exec  f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480 sh -c "cat /etc/*release | grep ^ID"
Stop and remove container: 67095444f83c4602b399de7bdcad0cb3_imagecloudluchentechcomhpcaitechpytorchcuda2221210_5c6989
##[command]/usr/bin/docker rm --force f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
f5e9724142d2602874b72fe2c9e714ee4cf78e54fd0110da3a216c97ae205480
Remove container network: github_network_f8f369a09b904755b7ddc4a6eaba4311
##[command]/usr/bin/docker network rm github_network_f8f369a09b904755b7ddc4a6eaba4311
github_network_f8f369a09b904755b7ddc4a6eaba4311


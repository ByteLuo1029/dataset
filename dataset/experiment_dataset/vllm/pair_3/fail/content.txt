'2.323.0'
##[group]Operating System
Ubuntu
24.04.2
LTS
##[endgroup]
##[group]Runner Image
Image: ubuntu-24.04
Version: 20250406.1.0
Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20250406.1/images/ubuntu/Ubuntu2404-Readme.md
Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20250406.1
##[endgroup]
##[group]Runner Image Provisioner
2.0.422.1
##[endgroup]
##[group]GITHUB_TOKEN Permissions
Actions: read
read
read
read
read
read
read


read
read
read
read
read
read
##[endgroup]
None



'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' 11bd71901bbe5b1630ceea73d27597364c9af683
'actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38' 42375524e23c412d93fb67b49958b491fce71c38
'pre-commit/action@2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd' 2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd

'actions/cache@v4'
Version: 4.2.3
c8a3bb963e1f1826d8fcc8d1354f0dd29d8ac1db1d4f6f20247055ae11b81ed9
5a3ec84eff668545956fd18022155c47e93e2684
##[endgroup]
pre-commit
actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

vllm-project/vllm



true


1



false

##[endgroup]
vllm-project/vllm

'/home/runner/work/vllm/vllm'

2 49 0
##[endgroup]
Temporarily overriding HOME='/home/runner/work/_temp/5bc54caf-36af-4be1-aed0-6139e2470567' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /home/runner/work/vllm/vllm
'/home/runner/work/vllm/vllm'

/home/runner/work/vllm/vllm










/home/runner/work/vllm/vllm/.git/
https://github.com/vllm-project/vllm
##[endgroup]

[command]/usr/bin/git config --local gc.auto 0
##[endgroup]

core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader
'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'
--local
##[endgroup]

2 --no-tags --prune --no-recurse-submodules --depth=1 origin +6e6c80bad3fc3331fe7f6f291008850fea794c4d:refs/remotes/pull/6036/merge
https://github.com/vllm-project/vllm
6e6c80bad3fc3331fe7f6f291008850fea794c4d  pull/6036/merge
##[endgroup]

##[endgroup]

[command]/usr/bin/git config --local --unset-all extensions.worktreeConfig

6036
6036
2025-04-15T09:26:56.9362739Z



2025-04-15T09:26:56.9365356Z


2025-04-15T09:26:56.9367227Z

2025-04-15T09:26:56.9367718Z

2025-04-15T09:26:56.9368175Z

2025-04-15T09:26:56.9368602Z

2025-04-15T09:26:56.9369507Z
6e6c80b 92c961b3ad2f503bd9de33fbe19f1f7769910312 1575c1701a80befec8efe274b338cb26bc199275
##[endgroup]
-1 --format=%H
6e6c80bad3fc3331fe7f6f291008850fea794c4d
actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

3.12


update-environment:
allow-prereleases:
##[endgroup]

3 12 9
##[endgroup]
##[group]Run echo "::add-matcher::.github/workflows/matchers/actionlint.json"
36 "::add-matcher::.github/workflows/matchers/actionlint.json"[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
##[group]Run echo "::add-matcher::.github/workflows/matchers/mypy.json"
36 "::add-matcher::.github/workflows/matchers/mypy.json"[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
pre-commit/action@2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd

extra_args: --all-files --hook-stage manual

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
install pre-commit
36 install pre-commit[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
pre-commit
pre commit-4.2.0-py2.py3-none-any.whl.metadata (1.3
cfgv>=2.0.0 pre-commit)
cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5
identify>=1.0.0 pre-commit)
identify-2.6.9-py2.py3-none-any.whl.metadata (4.4
nodeenv>=0.11.1 pre-commit)
nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21
pyyaml>=5.1 pre-commit)
Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
virtualenv>=20.10.0 pre-commit)
virtualenv-20.30.0-py3-none-any.whl.metadata (4.5
distlib<1,>=0.3.7 virtualenv>=20.10.0->pre-commit)
distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2
filelock<4,>=3.12.2 virtualenv>=20.10.0->pre-commit)
filelock-3.18.0-py3-none-any.whl.metadata (2.9
platformdirs<5,>=3.9.1 virtualenv>=20.10.0->pre-commit)
platformdirs-4.3.7-py3-none-any.whl.metadata (11
pre commit-4.2.0-py2.py3-none-any.whl (220
cfgv-3.4.0-py2.py3-none-any.whl (7.2
identify-2.6.9-py2.py3-none-any.whl (99
nodeenv-1.9.1-py2.py3-none-any.whl (22
Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)
767 5 767 5 kB 64 1 0 00 00
20 30 0 4 3
4 3 4 3 MB 139 4 0 00 00
distlib-0.3.9-py2.py3-none-any.whl (468
filelock-3.18.0-py3-none-any.whl (16
platformdirs-4.3.7-py3-none-any.whl (18

3 4 0 0 3 9 3 18 0 2 6 9 1 9 1 4 3 7 4 2 0 6 0 2 20 30 0
freeze --local
36 freeze --local[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
3 4 0
0 3 9
3 18 0
2 6 9
1 9 1
4 3 7
4 2 0
6 0 2
20 30 0
actions/cache@v4

~/.cache/pre-commit
3 3 12 9 b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18



save-always:

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
Cache hit for: pre-commit-3|/opt/hostedtoolcache/Python/3.12.9/x64|b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18
Received 29360128 of 113357780 (25.9%), 27.9 MBs/sec
Received 113357780 of 113357780 (100.0%), 71.1 MBs/sec
Cache Size: ~108 MB (113357780 B)
[command]/usr/bin/tar -xf /home/runner/work/_temp/fa41c9bb-6684-478f-be57-b958a26aeba1/cache.tzst -P -C /home/runner/work/vllm/vllm --use-compress-program unzstd
Cache restored successfully
Cache restored from key: pre-commit-3|/opt/hostedtoolcache/Python/3.12.9/x64|b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18
##[group]Run pre-commit run --show-diff-on-failure --color=always --all-files --hook-stage manual
[36;1mpre-commit run --show-diff-on-failure --color=always --all-files --hook-stage manual[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
yapf.....................................................................[42mPassed[m

codespell................................................................[42mPassed[m
isort....................................................................[42mPassed[m
clang-format.............................................................[42mPassed[m
PyMarkdown...............................................................[42mPassed[m
Lint GitHub Actions workflow files.......................................[42mPassed[m
pip-compile..............................................................[41mFailed[m
[2m- hook id: pip-compile[m
[2m- files were modified by this hook[m
2025-04-15T09:28:26.3657802Z
â ‹ Resolving dependencies...
[2Kâ ™ Resolving dependencies...
[2Kâ ‹ Resolving dependencies...
[2Kâ ™ Resolving dependencies...
[2Kâ ™ torch==2.6.0
[2Kâ ™ torchaudio==2.6.0
[2Kâ ™ torchvision==0.21.0
[2Kâ ™ lm-eval==0.4.8
[2Kâ ™ lm-eval==0.4.8
[2Kâ ™ transformers==4.51.1
[2Kâ ™ buildkite-test-collector==0.1.9
[2Kâ ™ genai-perf==0.0.8
[2Kâ ™ tritonclient==2.51.0
[2Kâ ™ numba==0.61.2
[2Kâ ¹ numba==0.61.2
[2Kâ ¹ numba==0.61.2
[2Kâ ¹ runai-model-streamer==0.11.0
[2Kâ ¹ runai-model-streamer-s3==0.11.0
[2Kâ ¹ nvidia-cuda-nvrtc-cu12==12.4.127
[2Kâ ¹ nvidia-cuda-nvrtc-cu12==12.4.127
[2Kâ ¹ nvidia-cuda-runtime-cu12==12.4.127
[2Kâ ¹ nvidia-cuda-runtime-cu12==12.4.127
[2Kâ ¹ nvidia-cuda-cupti-cu12==12.4.127
[2Kâ ¹ nvidia-cuda-cupti-cu12==12.4.127
[2Kâ ¹ nvidia-cudnn-cu12==9.1.0.70
[2Kâ ¹ nvidia-cudnn-cu12==9.1.0.70
[2Kâ ¹ nvidia-cublas-cu12==12.4.5.8
[2Kâ ¹ nvidia-cublas-cu12==12.4.5.8
[2Kâ ¹ nvidia-cufft-cu12==11.2.1.3
[2Kâ ¸ nvidia-curand-cu12==10.3.5.147
[2Kâ ¸ nvidia-cusparselt-cu12==0.6.2
[2Kâ ¸ triton==3.2.0
[2Kâ ¼ awscli==1.35.23
[2Kâ ¼ botocore==1.35.57
[2Kâ ¼ backoff==2.2.1
[2Kâ ¼ blobfile==3.0.0
[2Kâ ¼ encodec==0.1.1
[2Kâ ´ encodec==0.1.1
[2Kâ ¦ encodec==0.1.1
[2Kâ § encodec==0.1.1
[2Kâ ‡ encodec==0.1.1
[2Kâ ‹ encodec==0.1.1
[2Kâ ‹ peft==0.13.2
[2Kâ ‹ pqdm==0.2.0
[2Kâ ‹ ray==2.43.0
[2Kâ ‹ ray==2.43.0
[2Kâ ‹ sentence-transformers==3.2.1
[2Kâ ‹ soundfile==0.12.1
[2Kâ ‹ jiwer==3.0.5
[2Kâ ‹ timm==1.0.11
[2Kâ ‹ transformers-stream-generator==0.0.5
[2Kâ ‹ matplotlib==3.9.2
[2Kâ ‹ mistral-common==1.5.4
[2Kâ ‹ mistral-common==1.5.4
[2Kâ ‹ num2words==0.5.14
[2Kâ ‹ opencv-python-headless==4.11.0.86
[2Kâ ‹ setuptools==75.8.0
[2Kâ ‹ pillow==10.4.0
[2Kâ ™ pydantic-core==2.23.4
[2Kâ ™ typing-extensions==4.12.2
[2Kâ ™ pydantic==2.9.2
[2Kâ ¹ docopt==0.6.2
[2Kâ ¸ docopt==0.6.2
[2Kâ ¼ docopt==0.6.2
[2Kâ ¼ argcomplete==3.5.1
[2Kâ ¼ black==24.10.0
[2Kâ ¼ genson==1.3.0
[2Kâ ¼ inflect==5.6.2
[2Kâ ¼ isort==5.13.2
[2Kâ ¼ hf-xet==0.1.4
[2Kâ ¼ typer==0.15.2
[2Kâ ¼ chardet==5.2.0
[2K[2mResolved [1m206 packages[0m [2min 2.51s[0m[0m
[32m# This file was autogenerated by uv via the following command:[39m
[32m#    uv pip compile requirements/test.in -o requirements/test.txt[39m
absl-py==2.1.0
[32m    # via rouge-score[39m
accelerate==1.0.1
[32m    # via
#   lm-eval
#   peft[39m
aiohappyeyeballs==2.4.3
[32m    # via aiohttp[39m
aiohttp==3.10.11
[32m    # via
#   datasets
#   fsspec
#   lm-eval[39m
aiosignal==1.3.1
[32m    # via
#   aiohttp
#   ray[39m
annotated-types==0.7.0
[32m    # via pydantic[39m
anyio==4.6.2.post1
[32m    # via httpx[39m
argcomplete==3.5.1
[32m    # via datamodel-code-generator[39m
attrs==24.2.0
[32m    # via
#   aiohttp
#   jsonlines
#   jsonschema
#   referencing[39m
audioread==3.0.1
[32m    # via librosa[39m
awscli==1.35.23
[32m    # via -r requirements/test.in[39m
backoff==2.2.1
[32m    # via -r requirements/test.in[39m
bitsandbytes==0.45.3
[32m    # via -r requirements/test.in[39m
black==24.10.0
[32m    # via datamodel-code-generator[39m
blobfile==3.0.0
[32m    # via -r requirements/test.in[39m
boto3==1.35.57
[32m    # via tensorizer[39m
botocore==1.35.57
[32m    # via
#   awscli
#   boto3
#   s3transfer[39m
bounded-pool-executor==0.0.3
[32m    # via pqdm[39m
buildkite-test-collector==0.1.9
[32m    # via -r requirements/test.in[39m
certifi==2024.8.30
[32m    # via
#   httpcore
#   httpx
#   requests[39m
cffi==1.17.1
[32m    # via soundfile[39m
chardet==5.2.0
[32m    # via mbstrdecoder[39m
charset-normalizer==3.4.0
[32m    # via requests[39m
click==8.1.7
[32m    # via
#   black
#   jiwer
#   nltk
#   ray
#   typer[39m
colorama==0.4.6
[32m    # via
#   awscli
#   sacrebleu
#   tqdm-multiprocess[39m
contourpy==1.3.0
[32m    # via matplotlib[39m
cramjam==2.9.0
[32m    # via fastparquet[39m
cupy-cuda12x==13.3.0
[32m    # via ray[39m
cycler==0.12.1
[32m    # via matplotlib[39m
datamodel-code-generator==0.26.3
[32m    # via -r requirements/test.in[39m
dataproperty==1.0.1
[32m    # via
#   pytablewriter
#   tabledata[39m
datasets==3.0.2
[32m    # via
#   evaluate
#   lm-eval[39m
decorator==5.1.1
[32m    # via librosa[39m
dill==0.3.8
[32m    # via
#   datasets
#   evaluate
#   lm-eval
#   multiprocess[39m
dnspython==2.7.0
[32m    # via email-validator[39m
docopt==0.6.2
[32m    # via num2words[39m
docutils==0.16
[32m    # via awscli[39m
einops==0.8.0
[32m    # via
#   -r requirements/test.in
#   encodec
#   vector-quantize-pytorch
#   vocos[39m
einx==0.3.0
[32m    # via vector-quantize-pytorch[39m
email-validator==2.2.0
[32m    # via pydantic[39m
encodec==0.1.1
[32m    # via vocos[39m
evaluate==0.4.3
[32m    # via lm-eval[39m
fastparquet==2024.11.0
[32m    # via genai-perf[39m
fastrlock==0.8.2
[32m    # via cupy-cuda12x[39m
fastsafetensors==0.1.10
[32m    # via -r requirements/test.in[39m
3 16 1
[32m    # via
#   blobfile
#   datasets
#   huggingface-hub
#   ray
#   torch
#   transformers[39m
fonttools==4.54.1
[32m    # via matplotlib[39m
frozendict==2.4.6
[32m    # via einx[39m
frozenlist==1.5.0
[32m    # via
#   aiohttp
#   aiosignal
#   ray[39m
fsspec==2024.9.0
[32m    # via
#   datasets
#   evaluate
#   fastparquet
#   huggingface-hub
#   torch[39m
genai-perf==0.0.8
[32m    # via -r requirements/test.in[39m
genson==1.3.0
[32m    # via datamodel-code-generator[39m
h11==0.14.0
[32m    # via httpcore[39m
hf-xet==0.1.4
[32m    # via huggingface-hub[39m
hiredis==3.0.0
[32m    # via tensorizer[39m
httpcore==1.0.6
[32m    # via httpx[39m
httpx==0.27.2
[32m    # via -r requirements/test.in[39m
huggingface-hub==0.30.1
[32m    # via
#   -r requirements/test.in
#   accelerate
#   datasets
#   evaluate
#   peft
#   sentence-transformers
#   timm
#   tokenizers
#   transformers
#   vocos[39m
humanize==4.11.0
[32m    # via runai-model-streamer[39m
idna==3.10
[32m    # via
#   anyio
#   email-validator
#   httpx
#   requests
#   yarl[39m
inflect==5.6.2
[32m    # via datamodel-code-generator[39m
iniconfig==2.0.0
[32m    # via pytest[39m
isort==5.13.2
[32m    # via datamodel-code-generator[39m
jinja2==3.1.6
[32m    # via
#   datamodel-code-generator
#   torch[39m
jiwer==3.0.5
[32m    # via -r requirements/test.in[39m
jmespath==1.0.1
[32m    # via
#   boto3
#   botocore[39m
joblib==1.4.2
[32m    # via
#   librosa
#   nltk
#   scikit-learn[39m
jsonlines==4.0.0
[32m    # via lm-eval[39m
jsonschema==4.23.0
[32m    # via
#   mistral-common
#   ray[39m
jsonschema-specifications==2024.10.1
[32m    # via jsonschema[39m
kaleido==0.2.1
[32m    # via genai-perf[39m
kiwisolver==1.4.7
[32m    # via matplotlib[39m
lazy-loader==0.4
[32m    # via librosa[39m
libnacl==2.1.0
[32m    # via tensorizer[39m
librosa==0.10.2.post1
[32m    # via -r requirements/test.in[39m
llvmlite==0.44.0
[32m    # via numba[39m
lm-eval==0.4.8
[32m    # via -r requirements/test.in[39m
lxml==5.3.0
[32m    # via
#   blobfile
#   sacrebleu[39m
markdown-it-py==3.0.0
[32m    # via rich[39m
markupsafe==3.0.2
[32m    # via jinja2[39m
matplotlib==3.9.2
[32m    # via -r requirements/test.in[39m
mbstrdecoder==1.1.3
[32m    # via
#   dataproperty
#   pytablewriter
#   typepy[39m
mdurl==0.1.2
[32m    # via markdown-it-py[39m
mistral-common==1.5.4
[32m    # via -r requirements/test.in[39m
more-itertools==10.5.0
[32m    # via lm-eval[39m
mpmath==1.3.0
[32m    # via sympy[39m
msgpack==1.1.0
[32m    # via
#   librosa
#   ray[39m
multidict==6.1.0
[32m    # via
#   aiohttp
#   yarl[39m
multiprocess==0.70.16
[32m    # via
#   datasets
#   evaluate[39m
mypy-extensions==1.0.0
[32m    # via black[39m
networkx==3.2.1
[32m    # via torch[39m
nltk==3.9.1
[32m    # via rouge-score[39m
num2words==0.5.14
[32m    # via -r requirements/test.in[39m
numba==0.61.2
[32m    # via
#   -r requirements/test.in
#   librosa[39m
numexpr==2.10.1
[32m    # via lm-eval[39m
numpy==1.26.4
[32m    # via
#   -r requirements/test.in
#   accelerate
#   bitsandbytes
#   contourpy
#   cupy-cuda12x
#   datasets
#   einx
#   encodec
#   evaluate
#   fastparquet
#   genai-perf
#   librosa
#   matplotlib
#   mistral-common
#   numba
#   numexpr
#   opencv-python-headless
#   pandas
#   patsy
#   peft
#   rouge-score
#   runai-model-streamer
#   sacrebleu
#   scikit-learn
#   scipy
#   soxr
#   statsmodels
#   tensorizer
#   torchvision
#   transformers
#   tritonclient
#   vocos[39m
nvidia-cublas-cu12==12.4.5.8
[32m    # via
#   nvidia-cudnn-cu12
#   nvidia-cusolver-cu12
#   torch[39m
nvidia-cuda-cupti-cu12==12.4.127
[32m    # via torch[39m
nvidia-cuda-nvrtc-cu12==12.4.127
[32m    # via torch[39m
nvidia-cuda-runtime-cu12==12.4.127
[32m    # via torch[39m
nvidia-cudnn-cu12==9.1.0.70
[32m    # via torch[39m
nvidia-cufft-cu12==11.2.1.3
[32m    # via torch[39m
nvidia-curand-cu12==10.3.5.147
[32m    # via torch[39m
nvidia-cusolver-cu12==11.6.1.9
[32m    # via torch[39m
nvidia-cusparse-cu12==12.3.1.170
[32m    # via
#   nvidia-cusolver-cu12
#   torch[39m
nvidia-cusparselt-cu12==0.6.2
[32m    # via torch[39m
nvidia-nccl-cu12==2.21.5
[32m    # via torch[39m
nvidia-nvjitlink-cu12==12.4.127
[32m    # via
#   nvidia-cusolver-cu12
#   nvidia-cusparse-cu12
#   torch[39m
nvidia-nvtx-cu12==12.4.127
[32m    # via torch[39m
opencv-python-headless==4.11.0.86
[32m    # via
#   -r requirements/test.in
#   mistral-common[39m
packaging==24.1
[32m    # via
#   accelerate
#   black
#   datamodel-code-generator
#   datasets
#   evaluate
#   fastparquet
#   huggingface-hub
#   lazy-loader
#   matplotlib
#   peft
#   plotly
#   pooch
#   pytest
#   pytest-rerunfailures
#   ray
#   statsmodels
#   transformers
#   typepy[39m
pandas==2.2.3
[32m    # via
#   datasets
#   evaluate
#   fastparquet
#   genai-perf
#   statsmodels[39m
pathspec==0.12.1
[32m    # via black[39m
pathvalidate==3.2.1
[32m    # via pytablewriter[39m
patsy==1.0.1
[32m    # via statsmodels[39m
peft==0.13.2
[32m    # via
#   -r requirements/test.in
#   lm-eval[39m
pillow==10.4.0
[32m    # via
#   genai-perf
#   matplotlib
#   mistral-common
#   sentence-transformers
#   torchvision[39m
4 3 6
[32m    # via
#   black
#   pooch[39m
plotly==5.24.1
[32m    # via genai-perf[39m
pluggy==1.5.0
[32m    # via pytest[39m
pooch==1.8.2
[32m    # via librosa[39m
portalocker==2.10.1
[32m    # via sacrebleu[39m
pqdm==0.2.0
[32m    # via -r requirements/test.in[39m
propcache==0.2.0
[32m    # via yarl[39m
protobuf==5.28.3
[32m    # via
#   ray
#   tensorizer[39m
psutil==6.1.0
[32m    # via
#   accelerate
#   peft
#   tensorizer[39m
py==1.11.0
[32m    # via pytest-forked[39m
pyarrow==18.0.0
[32m    # via
#   datasets
#   genai-perf[39m
pyasn1==0.6.1
[32m    # via rsa[39m
pybind11==2.13.6
[32m    # via lm-eval[39m
pycparser==2.22
[32m    # via cffi[39m
pycryptodomex==3.22.0
[32m    # via blobfile[39m
pydantic==2.9.2
[32m    # via
#   datamodel-code-generator
#   mistral-common[39m
pydantic-core==2.23.4
[32m    # via pydantic[39m
pygments==2.18.0
[32m    # via rich[39m
pyparsing==3.2.0
[32m    # via matplotlib[39m
pytablewriter==1.2.0
[32m    # via lm-eval[39m
pytest==8.3.3
[32m    # via
#   -r requirements/test.in
#   buildkite-test-collector
#   genai-perf
#   pytest-asyncio
#   pytest-forked
#   pytest-mock
#   pytest-rerunfailures
#   pytest-shard
#   pytest-timeout[39m
pytest-asyncio==0.24.0
[32m    # via -r requirements/test.in[39m
pytest-forked==1.6.0
[32m    # via -r requirements/test.in[39m
pytest-mock==3.14.0
[32m    # via genai-perf[39m
pytest-rerunfailures==14.0
[32m    # via -r requirements/test.in[39m
pytest-shard==0.1.2
[32m    # via -r requirements/test.in[39m
pytest-timeout==2.3.1
[32m    # via -r requirements/test.in[39m
python-dateutil==2.9.0.post0
[32m    # via
#   botocore
#   matplotlib
#   pandas
#   typepy[39m
python-rapidjson==1.20
[32m    # via tritonclient[39m
pytz==2024.2
[32m    # via
#   pandas
#   typepy[39m
pyyaml==6.0.2
[32m    # via
#   accelerate
#   awscli
#   datamodel-code-generator
#   datasets
#   genai-perf
#   huggingface-hub
#   peft
#   ray
#   responses
#   timm
#   transformers
#   vocos[39m
rapidfuzz==3.12.1
[32m    # via jiwer[39m
ray==2.43.0
[32m    # via -r requirements/test.in[39m
redis==5.2.0
[32m    # via tensorizer[39m
referencing==0.35.1
[32m    # via
#   jsonschema
#   jsonschema-specifications[39m
regex==2024.9.11
[32m    # via
#   nltk
#   sacrebleu
#   tiktoken
#   transformers[39m
requests==2.32.3
[32m    # via
#   buildkite-test-collector
#   datasets
#   evaluate
#   huggingface-hub
#   lm-eval
#   mistral-common
#   pooch
#   ray
#   responses
#   tiktoken
#   transformers[39m
responses==0.25.3
[32m    # via genai-perf[39m
rich==13.9.4
[32m    # via
#   genai-perf
#   typer[39m
rouge-score==0.1.2
[32m    # via lm-eval[39m
rpds-py==0.20.1
[32m    # via
#   jsonschema
#   referencing[39m
rsa==4.7.2
[32m    # via awscli[39m
runai-model-streamer==0.11.0
[32m    # via -r requirements/test.in[39m
runai-model-streamer-s3==0.11.0
[32m    # via -r requirements/test.in[39m
s3transfer==0.10.3
[32m    # via
#   awscli
#   boto3[39m
sacrebleu==2.4.3
[32m    # via lm-eval[39m
safetensors==0.4.5
[32m    # via
#   accelerate
#   peft
#   timm
#   transformers[39m
scikit-learn==1.5.2
[32m    # via
#   librosa
#   lm-eval
#   sentence-transformers[39m
scipy==1.13.1
[32m    # via
#   librosa
#   scikit-learn
#   sentence-transformers
#   statsmodels
#   vocos[39m
sentence-transformers==3.2.1
[32m    # via -r requirements/test.in[39m
sentencepiece==0.2.0
[32m    # via mistral-common[39m
setuptools==75.8.0
[32m    # via
#   pytablewriter
#   torch[39m
shellingham==1.5.4
[32m    # via typer[39m
six==1.16.0
[32m    # via
#   python-dateutil
#   rouge-score[39m
sniffio==1.3.1
[32m    # via
#   anyio
#   httpx[39m
soundfile==0.12.1
[32m    # via
#   -r requirements/test.in
#   librosa[39m
soxr==0.5.0.post1
[32m    # via librosa[39m
sqlitedict==2.1.0
[32m    # via lm-eval[39m
statsmodels==0.14.4
[32m    # via genai-perf[39m
sympy==1.13.1
[32m    # via
#   einx
#   torch[39m
tabledata==1.3.3
[32m    # via pytablewriter[39m
tabulate==0.9.0
[32m    # via sacrebleu[39m
tcolorpy==0.1.6
[32m    # via pytablewriter[39m
tenacity==9.0.0
[32m    # via
#   lm-eval
#   plotly[39m
tensorizer==2.9.0
[32m    # via -r requirements/test.in[39m
threadpoolctl==3.5.0
[32m    # via scikit-learn[39m
tiktoken==0.7.0
[32m    # via
#   lm-eval
#   mistral-common[39m
timm==1.0.11
[32m    # via -r requirements/test.in[39m
tokenizers==0.21.0
[32m    # via transformers[39m
torch==2.6.0
[32m    # via
#   -r requirements/test.in
#   accelerate
#   bitsandbytes
#   encodec
#   fastsafetensors
#   lm-eval
#   peft
#   runai-model-streamer
#   sentence-transformers
#   tensorizer
#   timm
#   torchaudio
#   torchvision
#   vector-quantize-pytorch
#   vocos[39m
torchaudio==2.6.0
[32m    # via
#   -r requirements/test.in
#   encodec
#   vocos[39m
torchvision==0.21.0
[32m    # via
#   -r requirements/test.in
#   timm[39m
tqdm==4.66.6
[32m    # via
#   datasets
#   evaluate
#   huggingface-hub
#   lm-eval
#   nltk
#   peft
#   pqdm
#   sentence-transformers
#   tqdm-multiprocess
#   transformers[39m
tqdm-multiprocess==0.0.11
[32m    # via lm-eval[39m
transformers==4.51.1
[32m    # via
#   -r requirements/test.in
#   genai-perf
#   lm-eval
#   peft
#   sentence-transformers
#   transformers-stream-generator[39m
transformers-stream-generator==0.0.5
[32m    # via -r requirements/test.in[39m
triton==3.2.0
[32m    # via torch[39m
tritonclient==2.51.0
[32m    # via
#   -r requirements/test.in
#   genai-perf[39m
typepy==1.3.2
[32m    # via
#   dataproperty
#   pytablewriter
#   tabledata[39m
typer==0.15.2
[32m    # via fastsafetensors[39m
typing-extensions==4.12.2
[32m    # via
#   huggingface-hub
#   librosa
#   mistral-common
#   pqdm
#   pydantic
#   pydantic-core
#   torch
#   typer[39m
tzdata==2024.2
[32m    # via pandas[39m
urllib3==2.2.3
[32m    # via
#   blobfile
#   botocore
#   requests
#   responses
#   tritonclient[39m
vector-quantize-pytorch==1.21.2
[32m    # via -r requirements/test.in[39m
vocos==0.1.0
[32m    # via -r requirements/test.in[39m
word2number==1.1
[32m    # via lm-eval[39m
xxhash==3.5.0
[32m    # via
#   datasets
#   evaluate[39m
yarl==1.17.1
[32m    # via aiohttp[39m
zstandard==0.23.0
[32m    # via lm-eval[39m
2025-04-15T09:28:26.4367820Z
Run mypy for Python 3.9..................................................[42mPassed[m
Run mypy for Python 3.10.................................................[42mPassed[m
Run mypy for Python 3.11.................................................[42mPassed[m
Run mypy for Python 3.12.................................................[42mPassed[m
Lint shell scripts.......................................................[42mPassed[m
Lint PNG exports from excalidraw.........................................[42mPassed[m
Check SPDX headers.......................................................[42mPassed[m
Check for spaces in all filenames........................................[42mPassed[m
Update Dockerfile dependency graph.......................................[42mPassed[m
Suggestion...............................................................[42mPassed[m
[2m- hook id: suggestion[m
[2m- duration: 0s[m
2025-04-15T09:32:01.3341317Z
To bypass pre-commit hooks, add --no-verify to git commit.
2025-04-15T09:32:01.3341809Z
pre-commit hook(s) made changes.
If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
To run `pre-commit` as part of git workflow, use `pre-commit install`.
All changes made by hooks:
[1mdiff --git a/requirements/test.txt b/requirements/test.txt[m
[1mindex 28db236..a5c062b 100644[m
[1m--- a/requirements/test.txt[m
[1m+++ b/requirements/test.txt[m
[36m@@ -23,10 +23,6 @@[m [manyio==4.6.2.post1[m
# via httpx[m
argcomplete==3.5.1[m
# via datamodel-code-generator[m
[31m-async-timeout==5.0.1[m
[31m-    # via[m
[31m-    #   aiohttp[m
[31m-    #   redis[m
attrs==24.2.0[m
# via[m
#   aiohttp[m
[36m@@ -125,10 +121,6 @@[m [mencodec==0.1.1[m
# via vocos[m
evaluate==0.4.3[m
# via lm-eval[m
[31m-exceptiongroup==1.2.2[m
[31m-    # via[m
[31m-    #   anyio[m
[31m-    #   pytest[m
fastparquet==2024.11.0[m
# via genai-perf[m
fastrlock==0.8.2[m
[36m@@ -578,7 +570,9 @@[m [msentence-transformers==3.2.1[m
sentencepiece==0.2.0[m
# via mistral-common[m
setuptools==75.8.0[m
[31m-    # via pytablewriter[m
[32m+[m[32m    # via[m
[32m+[m[32m    #   pytablewriter[m
[32m+[m[32m    #   torch[m
shellingham==1.5.4[m
# via typer[m
six==1.16.0[m
[36m@@ -625,12 +619,6 @@[m [mtimm==1.0.11[m
# via -r requirements/test.in[m
tokenizers==0.21.0[m
# via transformers[m
[31m-toml==0.10.2[m
[31m-    # via datamodel-code-generator[m
[31m-tomli==2.2.1[m
[31m-    # via[m
[31m-    #   black[m
[31m-    #   pytest[m
torch==2.6.0[m
# via[m
#   -r requirements/test.in[m
[36m@@ -696,16 +684,12 @@[m [mtyper==0.15.2[m
# via fastsafetensors[m
typing-extensions==4.12.2[m
# via[m
[31m-    #   anyio[m
[31m-    #   black[m
#   huggingface-hub[m
#   librosa[m
#   mistral-common[m
[31m-    #   multidict[m
#   pqdm[m
#   pydantic[m
#   pydantic-core[m
[31m-    #   rich[m
#   torch[m
#   typer[m
tzdata==2024.2[m
##[error]Process completed with exit code 1.



2 49 0
Temporarily overriding HOME='/home/runner/work/_temp/9e587808-7c65-47bf-9015-538b874445e2' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /home/runner/work/vllm/vllm
core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader


'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'


'2.323.0'
##[group]Operating System
Ubuntu
24.04.2
LTS
##[endgroup]
##[group]Runner Image
Image: ubuntu-24.04
Version: 20250406.1.0
Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20250406.1/images/ubuntu/Ubuntu2404-Readme.md
Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20250406.1
##[endgroup]
##[group]Runner Image Provisioner
2.0.422.1
##[endgroup]
##[group]GITHUB_TOKEN Permissions
Actions: read
read
read
read
read
read
read


read
read
read
read
read
read
##[endgroup]
None



'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' 11bd71901bbe5b1630ceea73d27597364c9af683
'actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38' 42375524e23c412d93fb67b49958b491fce71c38
'pre-commit/action@2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd' 2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd

'actions/cache@v4'
Version: 4.2.3
c8a3bb963e1f1826d8fcc8d1354f0dd29d8ac1db1d4f6f20247055ae11b81ed9
5a3ec84eff668545956fd18022155c47e93e2684
##[endgroup]
pre-commit
actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

vllm-project/vllm



true


1



false

##[endgroup]
vllm-project/vllm

'/home/runner/work/vllm/vllm'

2 49 0
##[endgroup]
Temporarily overriding HOME='/home/runner/work/_temp/429b1164-9767-49c5-80f9-b5bf85b0235a' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /home/runner/work/vllm/vllm
'/home/runner/work/vllm/vllm'

/home/runner/work/vllm/vllm










/home/runner/work/vllm/vllm/.git/
https://github.com/vllm-project/vllm
##[endgroup]

[command]/usr/bin/git config --local gc.auto 0
##[endgroup]

core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader
'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'
--local
##[endgroup]

2 --no-tags --prune --no-recurse-submodules --depth=1 origin +2e47fef1e2c1a14d6bb277d7b190b11d237a3ea8:refs/remotes/pull/15826/merge
https://github.com/vllm-project/vllm
2e47fef1e2c1a14d6bb277d7b190b11d237a3ea8  pull/15826/merge
##[endgroup]

##[endgroup]

[command]/usr/bin/git config --local --unset-all extensions.worktreeConfig

15826
15826
2025-04-15T09:13:01.5356527Z



2025-04-15T09:13:01.5359321Z


2025-04-15T09:13:01.5361777Z

2025-04-15T09:13:01.5362484Z

2025-04-15T09:13:01.5363162Z

2025-04-15T09:13:01.5363780Z

2025-04-15T09:13:01.5364723Z
2e47fef c51665e2e968c068c31d549e8bc6fba2b682bfd4 1575c1701a80befec8efe274b338cb26bc199275
##[endgroup]
-1 --format=%H
2e47fef1e2c1a14d6bb277d7b190b11d237a3ea8
actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

3.12


update-environment:
allow-prereleases:
##[endgroup]

3 12 9
##[endgroup]
##[group]Run echo "::add-matcher::.github/workflows/matchers/actionlint.json"
36 "::add-matcher::.github/workflows/matchers/actionlint.json"[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
##[group]Run echo "::add-matcher::.github/workflows/matchers/mypy.json"
36 "::add-matcher::.github/workflows/matchers/mypy.json"[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
pre-commit/action@2c7b3805fd2a0fd8c1884dcaebf91fc102a13ecd

extra_args: --all-files --hook-stage manual

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
install pre-commit
36 install pre-commit[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
pre-commit
pre commit-4.2.0-py2.py3-none-any.whl.metadata (1.3
cfgv>=2.0.0 pre-commit)
cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5
identify>=1.0.0 pre-commit)
identify-2.6.9-py2.py3-none-any.whl.metadata (4.4
nodeenv>=0.11.1 pre-commit)
nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21
pyyaml>=5.1 pre-commit)
Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
virtualenv>=20.10.0 pre-commit)
virtualenv-20.30.0-py3-none-any.whl.metadata (4.5
distlib<1,>=0.3.7 virtualenv>=20.10.0->pre-commit)
distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2
filelock<4,>=3.12.2 virtualenv>=20.10.0->pre-commit)
filelock-3.18.0-py3-none-any.whl.metadata (2.9
platformdirs<5,>=3.9.1 virtualenv>=20.10.0->pre-commit)
platformdirs-4.3.7-py3-none-any.whl.metadata (11
pre commit-4.2.0-py2.py3-none-any.whl (220
cfgv-3.4.0-py2.py3-none-any.whl (7.2
identify-2.6.9-py2.py3-none-any.whl (99
nodeenv-1.9.1-py2.py3-none-any.whl (22
Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)
767 5 767 5 kB 48 1 0 00 00
20 30 0 4 3
4 3 4 3 MB 87 6 0 00 00
distlib-0.3.9-py2.py3-none-any.whl (468
filelock-3.18.0-py3-none-any.whl (16
platformdirs-4.3.7-py3-none-any.whl (18

3 4 0 0 3 9 3 18 0 2 6 9 1 9 1 4 3 7 4 2 0 6 0 2 20 30 0
freeze --local
36 freeze --local[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
3 4 0
0 3 9
3 18 0
2 6 9
1 9 1
4 3 7
4 2 0
6 0 2
20 30 0
actions/cache@v4

~/.cache/pre-commit
3 3 12 9 b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18



save-always:

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
Cache hit for: pre-commit-3|/opt/hostedtoolcache/Python/3.12.9/x64|b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18
Received 113357780 of 113357780 (100.0%), 116.6 MBs/sec
Cache Size: ~108 MB (113357780 B)
[command]/usr/bin/tar -xf /home/runner/work/_temp/dc5d35b2-2b0b-4c25-a9eb-e662a9306ee2/cache.tzst -P -C /home/runner/work/vllm/vllm --use-compress-program unzstd
Cache restored successfully
Cache restored from key: pre-commit-3|/opt/hostedtoolcache/Python/3.12.9/x64|b561be449282ed0f3eb12e41c885cf98903b2d58b7a569f3e4b5873d7aff2f18
##[group]Run pre-commit run --show-diff-on-failure --color=always --all-files --hook-stage manual
[36;1mpre-commit run --show-diff-on-failure --color=always --all-files --hook-stage manual[0m
0

3 12 9
3 12 9
3 12 9
Python2 3 12 9
Python3 3 12 9
3 12 9
##[endgroup]
yapf.....................................................................[41mFailed[m
[2m- hook id: yapf[m
[2m- files were modified by this hook[m
2025-04-15T09:14:18.3372357Z
Reformatting tests/models/multimodal/processing/test_mllama.py
Reformatting vllm/lora/punica_wrapper/__init__.py
Reformatting vllm/model_executor/models/teleflm.py
Reformatting vllm/transformers_utils/configs/ovis2.py
Reformatting vllm/model_executor/models/llava_next.py
Reformatting vllm/attention/backends/flashinfer.py
Reformatting vllm/v1/worker/utils.py
Reformatting vllm/model_executor/models/paligemma.py
Reformatting tests/distributed/test_expert_parallel.py
Reformatting tests/prompt_adapter/test_pa_lora.py
Reformatting vllm/lora/ops/triton_ops/lora_kernel_metadata.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py
Reformatting vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py
Reformatting tests/entrypoints/llm/test_accuracy.py
Reformatting vllm/model_executor/models/granitemoe.py
Reformatting tests/kernels/test_mamba_ssm_ssd.py
Reformatting vllm/attention/backends/pallas.py
Reformatting vllm/v1/__init__.py
Reformatting vllm/entrypoints/openai/api_server.py
Reformatting vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py
Reformatting vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py
Reformatting examples/offline_inference/cpu_offload_lmcache.py
Reformatting tests/models/multimodal/processing/test_llava_onevision.py
Reformatting tests/tpu/test_compilation.py
Reformatting vllm/model_executor/models/mamba_cache.py
Reformatting tests/models/embedding/language/test_jina.py
Reformatting vllm/lora/ops/torch_ops/__init__.py
Reformatting tests/kernels/test_nvfp4_quant.py
Reformatting tests/entrypoints/openai/test_score.py
Reformatting vllm/distributed/device_communicators/custom_all_reduce_utils.py
Reformatting tests/basic_correctness/test_chunked_prefill.py
Reformatting vllm/v1/executor/__init__.py
Reformatting tests/spec_decode/e2e/test_mtp_correctness.py
Reformatting vllm/env_override.py
Reformatting tests/entrypoints/offline_mode/__init__.py
Reformatting vllm/scalar_type.py
Reformatting vllm/plugins/__init__.py
Reformatting vllm/v1/worker/gpu_worker.py
Reformatting tests/v1/tpu/worker/test_tpu_model_runner.py
Reformatting vllm/model_executor/layers/resampler.py
Reformatting benchmarks/benchmark_throughput.py
Reformatting tests/mq_llm_engine/test_abort.py
Reformatting tests/v1/sample/test_sampler.py
Reformatting vllm/model_executor/layers/quantization/deepspeedfp.py
Reformatting tests/kernels/conftest.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py
Reformatting tests/v1/test_stats.py
Reformatting vllm/model_executor/model_loader/utils.py
Reformatting vllm/model_executor/custom_op.py
Reformatting vllm/model_executor/models/ovis2.py
Reformatting cmake/hipify.py
Reformatting examples/online_serving/openai_chat_completion_structured_outputs_with_reasoning.py
Reformatting tests/tokenization/test_cached_tokenizer.py
Reformatting vllm/attention/backends/mla/__init__.py
Reformatting tests/models/decoder_only/audio_language/test_ultravox.py
Reformatting vllm/model_executor/models/mllama.py
Reformatting vllm/model_executor/layers/fused_moe/__init__.py
Reformatting tests/core/block/test_block_table.py
Reformatting vllm/engine/output_processor/interfaces.py
Reformatting tests/kernels/test_encoder_decoder_attn.py
Reformatting vllm/model_executor/models/qwen3_moe.py
Reformatting tests/core/block/e2e/conftest.py
Reformatting tests/entrypoints/llm/test_encode.py
Reformatting tests/v1/worker/test_gpu_model_runner.py
Reformatting vllm/model_executor/model_loader/tensorizer.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/__init__.py
Reformatting vllm/engine/multiprocessing/engine.py
Reformatting vllm/compilation/monitor.py
Reformatting vllm/model_executor/models/aria.py
Reformatting tests/models/embedding/vision_language/test_dse_qwen2_vl.py
Reformatting tests/engine/conftest.py
Reformatting vllm/v1/outputs.py
Reformatting vllm/model_executor/layers/logits_processor.py
Reformatting tests/compile/test_functionalization.py
Reformatting vllm/engine/async_timeout.py
Reformatting vllm/worker/multi_step_worker.py
Reformatting vllm/v1/spec_decode/utils.py
Reformatting vllm/model_executor/layers/quantization/ptpc_fp8.py
Reformatting vllm/model_executor/layers/sampler.py
Reformatting tests/entrypoints/openai/test_sleep.py
Reformatting vllm/model_executor/models/aimv2.py
Reformatting vllm/v1/sample/tpu/metadata.py
Reformatting vllm/compilation/pass_manager.py
Reformatting tests/detokenizer/test_stop_reason.py
Reformatting tests/entrypoints/openai/test_basic.py
Reformatting vllm/config.py
Reformatting vllm/model_executor/guided_decoding/guidance_decoding.py
Reformatting csrc/quantization/machete/generate.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py
Reformatting tests/mq_llm_engine/conftest.py
Reformatting vllm/core/block/naive_block.py
Reformatting tests/models/test_vision.py
Reformatting vllm/inputs/parse.py
Reformatting tests/basic_correctness/__init__.py
Reformatting tests/entrypoints/openai/test_transcription_validation.py
Reformatting vllm/core/block/block_table.py
Reformatting examples/online_serving/gradio_openai_chatbot_webserver.py
Reformatting tests/compile/test_fusion.py
Reformatting tests/v1/structured_output/__init__.py
Reformatting vllm/model_executor/layers/quantization/quark/utils.py
Reformatting tests/test_logits_processor.py
Reformatting vllm/logits_process.py
Reformatting tests/kernels/test_int8_kernel.py
Reformatting vllm/model_executor/models/deepseek_vl2.py
Reformatting .buildkite/check-wheel-size.py
Reformatting vllm/entrypoints/launcher.py
Reformatting tests/mistral_tool_use/conftest.py
Reformatting tests/lora/test_qwen2vl.py
Reformatting tests/v1/engine/test_async_llm.py
Reformatting vllm/model_executor/models/llava_next_video.py
Reformatting examples/online_serving/openai_completion_client.py
Reformatting tests/spec_decode/test_scorer.py
Reformatting vllm/core/block/cpu_gpu_block_allocator.py
Reformatting vllm/core/block/__init__.py
Reformatting vllm/model_executor/layers/__init__.py
Reformatting vllm/lora/peft_helper.py
Reformatting tests/lora/test_chatglm3_tp.py
Reformatting vllm/prompt_adapter/models.py
Reformatting vllm/compilation/wrapper.py
Reformatting benchmarks/cutlass_benchmarks/w8a8_benchmarks.py
Reformatting tests/entrypoints/llm/test_lazy_outlines.py
Reformatting examples/online_serving/openai_chat_completion_structured_outputs.py
Reformatting vllm/entrypoints/openai/cli_args.py
Reformatting tests/kernels/test_allspark_gemm.py
Reformatting tests/entrypoints/openai/test_models.py
Reformatting tests/models/decoder_only/language/test_aqlm.py
Reformatting vllm/worker/model_runner_base.py
Reformatting vllm/compilation/multi_output_match.py
Reformatting vllm/model_executor/models/ultravox.py
Reformatting tests/quantization/test_ptpc_fp8.py
Reformatting vllm/model_executor/layers/fused_moe/utils.py
Reformatting tests/worker/conftest.py
Reformatting tests/quantization/test_register_quantization_config.py
Reformatting vllm/model_executor/layers/quantization/fp8.py
Reformatting vllm/model_executor/guided_decoding/utils.py
Reformatting vllm/model_executor/layers/mamba/ops/ssd_bmm.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/model_utils.py
Reformatting vllm/model_executor/models/whisper.py
Reformatting tests/neuron/1_core/test_rotary_embedding.py
Reformatting benchmarks/kernels/graph_machete_bench.py
Reformatting vllm/model_executor/layers/rotary_embedding.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py
Reformatting tests/v1/entrypoints/conftest.py
Reformatting vllm/entrypoints/cli/benchmark/base.py
Reformatting vllm/model_executor/layers/quantization/awq_marlin.py
Reformatting vllm/attention/ops/chunked_prefill_paged_decode.py
Reformatting tests/entrypoints/openai/tool_parsers/test_pythonic_tool_parser.py
Reformatting tests/models/embedding/language/__init__.py
Reformatting vllm/spec_decode/__init__.py
Reformatting vllm/model_executor/layers/quantization/gptq_marlin_24.py
Reformatting vllm/model_executor/models/jamba.py
Reformatting tests/lora/test_llama_tp.py
Reformatting vllm/v1/kv_cache_interface.py
Reformatting tests/engine/test_multi_step_output_processor.py
Reformatting vllm/distributed/device_communicators/shm_broadcast.py
Reformatting vllm/model_executor/model_loader/weight_utils.py
Reformatting vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py
Reformatting vllm/model_executor/models/blip.py
Reformatting vllm/v1/core/sched/output.py
Reformatting vllm/model_executor/models/orion.py
Reformatting tests/lora/test_tokenizer_group.py
Reformatting vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py
Reformatting tests/mistral_tool_use/test_mistral_tool_calls.py
Reformatting examples/online_serving/openai_chat_embedding_client_for_multimodal.py
Reformatting vllm/distributed/device_communicators/custom_all_reduce.py
Reformatting tests/quantization/test_cpu_offload.py
Reformatting vllm/model_executor/models/transformers.py
Reformatting vllm/model_executor/layers/quantization/quark/quark.py
Reformatting tests/samplers/test_beam_search.py
Reformatting tests/distributed/test_multi_node_assignment.py
Reformatting vllm/model_executor/models/phi4mm.py
Reformatting tests/entrypoints/openai/test_chat.py
Reformatting tests/lora/test_punica_ops.py
Reformatting vllm/distributed/kv_transfer/kv_pipe/__init__.py
Reformatting vllm/model_executor/models/llava.py
Reformatting vllm/model_executor/models/module_mapping.py
Reformatting tests/v1/e2e/__init__.py
Reformatting tests/detokenizer/test_disable_detokenization.py
Reformatting examples/offline_inference/basic/basic.py
Reformatting vllm/entrypoints/openai/serving_completion.py
Reformatting vllm/core/block/utils.py
Reformatting vllm/core/scheduler.py
Reformatting tests/models/decoder_only/language/test_gptq_marlin_24.py
Reformatting vllm/model_executor/models/starcoder2.py
Reformatting tests/benchmarks/__init__.py
Reformatting tests/tool_use/conftest.py
Reformatting vllm/model_executor/layers/fused_moe/layer.py
Reformatting vllm/distributed/parallel_state.py
Reformatting tests/distributed/test_torchrun_example.py
Reformatting tests/tokenization/__init__.py
Reformatting benchmarks/kernels/benchmark_layernorm.py
Reformatting vllm/model_executor/layers/quantization/torchao.py
Reformatting tests/tpu/test_custom_dispatcher.py
Reformatting vllm/transformers_utils/configs/kimi_vl.py
Reformatting vllm/outputs.py
Reformatting vllm/entrypoints/openai/run_batch.py
Reformatting tests/kernels/test_rotary_embedding.py
Reformatting vllm/transformers_utils/processor.py
Reformatting vllm/v1/structured_output/utils.py
Reformatting vllm/engine/multiprocessing/__init__.py
Reformatting tests/kernels/test_triton_scaled_mm.py
Reformatting vllm/assets/image.py
Reformatting vllm/model_executor/layers/mamba/mamba_mixer2.py
Reformatting vllm/entrypoints/openai/serving_chat.py
Reformatting vllm/model_executor/models/eagle.py
Reformatting vllm/lora/ops/torch_ops/lora_ops.py
Reformatting vllm/v1/core/sched/scheduler.py
Reformatting vllm/model_executor/models/adapters.py
Reformatting tests/v1/engine/utils.py
Reformatting vllm/lora/worker_manager.py
Reformatting vllm/v1/metrics/stats.py
Reformatting vllm/v1/attention/backends/mla/common.py
Reformatting tests/kv_transfer/test_module.py
Reformatting vllm/attention/backends/ipex_attn.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/builders.py
Reformatting vllm/multimodal/__init__.py
Reformatting vllm/v1/structured_output/backend_xgrammar.py
Reformatting tests/engine/__init__.py
Reformatting vllm/model_executor/models/nemotron_nas.py
Reformatting vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py
Reformatting benchmarks/cutlass_benchmarks/weight_shapes.py
Reformatting tests/core/block/test_common.py
Reformatting tests/worker/test_profile.py
Reformatting vllm/v1/sample/sampler.py
Reformatting vllm/lora/ops/triton_ops/lora_expand.py
Reformatting tests/basic_correctness/test_cpu_offload.py
Reformatting vllm/transformers_utils/configs/skyworkr1v.py
Reformatting vllm/entrypoints/cli/benchmark/latency.py
Reformatting vllm/logging_utils/formatter.py
Reformatting vllm/model_executor/layers/quantization/marlin.py
Reformatting tests/entrypoints/llm/test_collective_rpc.py
Reformatting vllm/assets/audio.py
Reformatting vllm/lora/ops/triton_ops/lora_shrink.py
Reformatting tests/quantization/test_torchao.py
Reformatting tests/entrypoints/llm/test_gpu_utilization.py
Reformatting vllm/attention/ops/flashmla.py
Reformatting tests/compile/piecewise/test_simple.py
Reformatting vllm/v1/engine/mm_input_cache.py
Reformatting vllm/distributed/device_communicators/tpu_communicator.py
Reformatting tests/neuron/1_core/test_cache.py
Reformatting vllm/multimodal/parse.py
Reformatting tests/entrypoints/llm/test_guided_generate.py
Reformatting tests/distributed/test_utils.py
Reformatting tests/core/conftest.py
Reformatting tests/lora/test_worker.py
Reformatting vllm/v1/attention/backends/pallas.py
Reformatting vllm/distributed/device_communicators/hpu_communicator.py
Reformatting tests/models/multimodal/processing/test_smolvlm.py
Reformatting vllm/model_executor/models/gemma2.py
Reformatting vllm/model_executor/layers/activation.py
Reformatting vllm/distributed/kv_transfer/kv_transfer_agent.py
Reformatting vllm/model_executor/layers/mamba/ops/ssd_combined.py
Reformatting tests/neuron/1_core/test_layernorm.py
Reformatting vllm/executor/ray_utils.py
Reformatting vllm/spec_decode/mqa_scorer.py
Reformatting vllm/compilation/torch25_custom_graph_pass.py
Reformatting tests/lora/test_utils.py
Reformatting vllm/compilation/vllm_inductor_pass.py
Reformatting tests/spec_decode/test_ngram_worker.py
Reformatting vllm/lora/punica_wrapper/punica_selector.py
Reformatting tests/tensorizer_loader/test_tensorizer.py
Reformatting vllm/distributed/kv_transfer/kv_connector/base.py
Reformatting vllm/executor/mp_distributed_executor.py
Reformatting vllm/entrypoints/openai/serving_models.py
Reformatting examples/offline_inference/eagle.py
Reformatting vllm/v1/sample/ops/__init__.py
Reformatting tests/entrypoints/openai/test_chat_logit_bias_validation.py
Reformatting vllm/model_executor/models/intern_vit.py
Reformatting tests/distributed/__init__.py
Reformatting vllm/entrypoints/openai/logits_processors.py
Reformatting vllm/model_executor/guided_decoding/outlines_logits_processors.py
Reformatting vllm/entrypoints/utils.py
Reformatting examples/online_serving/gradio_webserver.py
Reformatting tests/kernels/test_marlin_gemm.py
Reformatting vllm/v1/attention/backends/__init__.py
Reformatting tests/entrypoints/openai/test_serving_models.py
Reformatting vllm/transformers_utils/configs/cohere2.py
Reformatting vllm/platforms/__init__.py
Reformatting vllm/usage/usage_lib.py
Reformatting tests/lora/test_minicpmv_tp.py
Reformatting tests/lora/conftest.py
Reformatting tests/models/multimodal/processing/test_internvl.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py
Reformatting tests/worker/test_model_runner.py
Reformatting tests/v1/sample/__init__.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py
Reformatting tests/kernels/utils_block.py
Reformatting vllm/model_executor/models/qwen_vl.py
Reformatting vllm/worker/multi_step_hpu_worker.py
Reformatting vllm/model_executor/models/phi3_small.py
Reformatting vllm/v1/attention/backends/mla/flashmla.py
Reformatting vllm/model_executor/layers/quantization/gptq_marlin.py
Reformatting examples/online_serving/jinaai_rerank_client.py
Reformatting vllm/worker/pooling_model_runner.py
Reformatting vllm/triton_utils/__init__.py
Reformatting vllm/transformers_utils/processors/deepseek_vl2.py
Reformatting vllm/model_executor/layers/fused_moe/moe_align_block_size.py
Reformatting vllm/model_executor/layers/quantization/quark/quark_moe.py
Reformatting tests/reasoning/test_deepseekr1_reasoning_parser.py
Reformatting tests/v1/structured_output/test_utils.py
Reformatting tests/kernels/test_awq_triton.py
Reformatting tests/neuron/1_core/test_block_table.py
Reformatting vllm/spec_decode/draft_model_runner.py
Reformatting tests/test_sequence.py
Reformatting vllm/worker/neuron_worker.py
Reformatting vllm/transformers_utils/configs/medusa.py
Reformatting vllm/benchmarks/endpoint_request_func.py
Reformatting vllm/model_executor/layers/vocab_parallel_embedding.py
Reformatting vllm/attention/backends/flash_attn.py
Reformatting tests/entrypoints/openai/test_run_batch.py
Reformatting tests/conftest.py
Reformatting tests/v1/e2e/test_spec_decode.py
Reformatting tests/kernels/test_layernorm.py
Reformatting vllm/inputs/registry.py
Reformatting tests/entrypoints/openai/test_chunked_prompt.py
Reformatting vllm/v1/stats/__init__.py
Reformatting tests/models/decoder_only/vision_language/__init__.py
Reformatting vllm/model_executor/layers/fused_moe/fused_marlin_moe.py
Reformatting vllm/model_executor/models/granitemoeshared.py
Reformatting tests/plugins_tests/conftest.py
Reformatting examples/online_serving/openai_chat_completion_with_reasoning.py
Reformatting vllm/attention/backends/rocm_flash_attn.py
Reformatting vllm/model_executor/models/nvlm_d.py
Reformatting vllm/v1/engine/output_processor.py
Reformatting vllm/jsontree.py
Reformatting vllm/connections.py
Reformatting examples/offline_inference/lora_with_quantization_inference.py
Reformatting vllm/engine/llm_engine.py
Reformatting tests/kv_transfer/test_disagg.py
Reformatting vllm/v1/attention/backends/mla/triton_mla.py
Reformatting tests/lora/test_lora_functions.py
Reformatting vllm/lora/ops/triton_ops/kernel_utils.py
Reformatting vllm/triton_utils/importing.py
Reformatting vllm/model_executor/models/vision.py
Reformatting vllm/multimodal/audio.py
Reformatting vllm/model_executor/models/olmo2.py
Reformatting tests/engine/test_arg_utils.py
Reformatting tests/entrypoints/openai/test_chat_with_tool_reasoning.py
Reformatting vllm/platforms/xpu.py
Reformatting vllm/prompt_adapter/request.py
Reformatting tests/core/block/test_cpu_gpu_block_allocator.py
Reformatting tests/test_cache_block_hashing.py
Reformatting vllm/transformers_utils/tokenizer_base.py
Reformatting tests/models/decoder_only/vision_language/test_phi4mm.py
Reformatting .buildkite/nightly-benchmarks/scripts/summary-nightly-results.py
Reformatting tests/prefix_caching/test_disable_sliding_window.py
Reformatting tests/kernels/test_utils.py
Reformatting tests/models/test_registry.py
Reformatting tests/entrypoints/llm/__init__.py
Reformatting vllm/model_executor/layers/quantization/hqq_marlin.py
Reformatting vllm/model_executor/layers/quantization/experts_int8.py
Reformatting benchmarks/kernels/benchmark_paged_attention.py
Reformatting vllm/assets/__init__.py
Reformatting tests/detokenizer/test_stop_strings.py
Reformatting vllm/model_executor/models/llama4.py
Reformatting tests/entrypoints/openai/correctness/__init__.py
Reformatting benchmarks/kernels/benchmark_marlin.py
Reformatting vllm/envs.py
Reformatting vllm/spec_decode/ngram_worker.py
Reformatting vllm/entrypoints/chat_utils.py
Reformatting vllm/platforms/interface.py
Reformatting tests/models/embedding/utils.py
Reformatting vllm/compilation/counter.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py
Reformatting tests/kernels/allclose_default.py
Reformatting vllm/spec_decode/mlp_speculator_worker.py
Reformatting vllm/model_executor/layers/pooler.py
Reformatting tests/test_sampling_params.py
Reformatting tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_llava.py
Reformatting tests/multimodal/test_utils.py
Reformatting vllm/v1/worker/tpu_model_runner.py
Reformatting benchmarks/benchmark_prefix_caching.py
Reformatting tests/kernels/test_ggml.py
Reformatting examples/offline_inference/encoder_decoder.py
Reformatting vllm/worker/hpu_worker.py
Reformatting examples/online_serving/api_client.py
Reformatting tests/core/block/e2e/test_correctness_sliding_window.py
Reformatting vllm/attention/__init__.py
Reformatting tests/models/decoder_only/__init__.py
Reformatting benchmarks/benchmark_long_document_qa_throughput.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py
Reformatting vllm/attention/ops/triton_flash_attention.py
Reformatting examples/offline_inference/basic/generate.py
Reformatting tests/v1/entrypoints/llm/__init__.py
Reformatting vllm/model_executor/utils.py
Reformatting vllm/platforms/cpu.py
Reformatting tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_opt.py
Reformatting docs/source/generate_examples.py
Reformatting vllm/reasoning/__init__.py
Reformatting find_cuda_init.py
Reformatting tests/kernels/test_machete_mm.py
Reformatting vllm/attention/backends/blocksparse_attn.py
Reformatting vllm/model_executor/models/chatglm.py
Reformatting vllm/multimodal/base.py
Reformatting tests/entrypoints/openai/test_root_path.py
Reformatting tests/kernels/__init__.py
Reformatting vllm/model_executor/layers/fused_moe/fused_moe.py
Reformatting vllm/entrypoints/logger.py
Reformatting vllm/model_executor/models/falcon.py
Reformatting setup.py
Reformatting tests/v1/test_serial_utils.py
Reformatting vllm/transformers_utils/tokenizer.py
Reformatting tests/entrypoints/openai/__init__.py
Reformatting tests/models/multimodal/processing/test_qwen2_vl.py
Reformatting vllm/vllm_flash_attn/fa_utils.py
Reformatting tests/model_executor/weight_utils.py
Reformatting vllm/platforms/tpu.py
Reformatting tests/kernels/utils.py
Reformatting tests/v1/engine/test_output_processor.py
Reformatting tests/samplers/test_ranks.py
Reformatting vllm/v1/sample/tpu/__init__.py
Reformatting tests/models/test_initialization.py
Reformatting vllm/model_executor/layers/fused_moe/moe_torch_iterative.py
Reformatting vllm/distributed/device_communicators/__init__.py
Reformatting vllm/engine/metrics.py
Reformatting tests/models/decoder_only/vision_language/test_pixtral.py
Reformatting vllm/attention/ops/prefix_prefill.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/__init__.py
Reformatting tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_platform.py
Reformatting vllm/worker/cpu_model_runner.py
Reformatting vllm/worker/enc_dec_model_runner.py
Reformatting vllm/model_executor/layers/quantization/utils/quant_utils.py
Reformatting vllm/model_executor/layers/mamba/mamba2_metadata.py
Reformatting tests/entrypoints/openai/test_pooling.py
Reformatting vllm/v1/sample/metadata.py
Reformatting vllm/model_executor/sampling_metadata.py
Reformatting vllm/model_executor/models/siglip.py
Reformatting vllm/model_executor/models/qwen3.py
Reformatting tests/detokenizer/conftest.py
Reformatting tests/v1/test_oracle.py
Reformatting examples/online_serving/openai_transcription_client.py
Reformatting vllm/transformers_utils/utils.py
Reformatting vllm/model_executor/models/deepseek_v2.py
Reformatting benchmarks/fused_kernels/layernorm_rms_benchmarks.py
Reformatting vllm/model_executor/models/fairseq2_llama.py
Reformatting vllm/v1/worker/lora_model_runner_mixin.py
Reformatting tests/tool_use/test_chat_completions.py
Reformatting tests/entrypoints/openai/test_embedding_dimensions.py
Reformatting examples/offline_inference/profiling_tpu/profiling.py
Reformatting tests/core/test_scheduler.py
Reformatting tests/kernels/test_mha_attn.py
Reformatting vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py
Reformatting tests/entrypoints/conftest.py
Reformatting benchmarks/kernels/benchmark_w8a8_block_fp8.py
Reformatting examples/offline_inference/chat_with_tools.py
Reformatting tests/v1/core/test_specialized_manager.py
Reformatting tests/lora/test_transfomers_model.py
Reformatting vllm/v1/core/sched/interface.py
Reformatting tests/prefix_caching/test_prefix_caching.py
Reformatting vllm/transformers_utils/configs/mpt.py
Reformatting vllm/v1/core/block_pool.py
Reformatting vllm/model_executor/models/qwen2_moe.py
Reformatting vllm/v1/core/specialized_manager.py
Reformatting vllm/lora/utils.py
Reformatting examples/offline_inference/torchrun_example.py
Reformatting tests/worker/test_encoder_decoder_model_runner.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py
Reformatting vllm/v1/worker/tpu_worker.py
Reformatting vllm/model_executor/layers/quantization/utils/marlin_utils.py
Reformatting tests/spec_decode/utils.py
Reformatting vllm/executor/uniproc_executor.py
Reformatting vllm/model_executor/layers/mamba/mamba_mixer.py
Reformatting vllm/inputs/preprocess.py
Reformatting benchmarks/benchmark_latency.py
Reformatting tests/entrypoints/openai/test_chat_template.py
Reformatting vllm/worker/model_runner.py
Reformatting tests/multi_step/test_correctness_async_llm.py
Reformatting vllm/attention/backends/__init__.py
Reformatting tests/kernels/test_activation.py
Reformatting tests/fastsafetensors_loader/test_weight_utils.py
Reformatting vllm/entrypoints/score_utils.py
Reformatting tests/models/decoder_only/language/__init__.py
Reformatting tests/lora/test_layers.py
Reformatting tests/kernels/test_causal_conv1d.py
Reformatting vllm/model_executor/models/granite.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py
Reformatting vllm/tracing.py
Reformatting vllm/transformers_utils/configs/__init__.py
Reformatting benchmarks/benchmark_prioritization.py
Reformatting tests/engine/test_executor.py
Reformatting vllm/v1/structured_output/__init__.py
Reformatting vllm/multimodal/inputs.py
Reformatting tests/metrics/test_metrics.py
Reformatting tests/plugins/vllm_add_dummy_model/setup.py
Reformatting vllm/benchmarks/latency.py
Reformatting vllm/model_executor/models/registry.py
Reformatting tests/kernels/test_flash_attn.py
Reformatting vllm/transformers_utils/configs/deepseek_vl2.py
Reformatting benchmarks/disagg_benchmarks/round_robin_proxy.py
Reformatting vllm/worker/cpu_pooling_model_runner.py
Reformatting tests/compile/backend.py
Reformatting tests/entrypoints/openai/test_chat_echo.py
Reformatting vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py
Reformatting tests/entrypoints/openai/test_rerank.py
Reformatting vllm/model_executor/models/minicpm3.py
Reformatting vllm/transformers_utils/configs/exaone.py
Reformatting vllm/model_executor/models/mixtral_quant.py
Reformatting tests/v1/entrypoints/openai/test_completion.py
Reformatting vllm/v1/engine/async_llm.py
Reformatting tests/tracing/test_tracing.py
Reformatting tests/mq_llm_engine/__init__.py
Reformatting tests/basic_correctness/test_cumem.py
Reformatting vllm/inputs/__init__.py
Reformatting tests/models/encoder_decoder/audio_language/test_whisper.py
Reformatting tests/kernels/test_mla_decode_cpu.py
Reformatting tests/kernels/test_mamba_mixer2.py
Reformatting vllm/model_executor/models/__init__.py
Reformatting tests/neuron/2_core/test_comm_ops.py
Reformatting tests/entrypoints/offline_mode/test_offline_mode.py
Reformatting vllm/model_executor/layers/quantization/base_config.py
Reformatting tests/entrypoints/test_ssl_cert_refresher.py
Reformatting tests/core/__init__.py
Reformatting vllm/model_executor/models/skyworkr1v.py
Reformatting vllm/transformers_utils/detokenizer.py
Reformatting vllm/model_executor/layers/quantization/utils/w8a8_utils.py
Reformatting tests/v1/sample/utils.py
Reformatting tests/compile/piecewise/__init__.py
Reformatting vllm/entrypoints/cli/benchmark/serve.py
Reformatting tests/lora/test_phi.py
Reformatting vllm/reasoning/granite_reasoning_parser.py
Reformatting tests/spec_decode/test_utils.py
Reformatting tests/kernels/test_gguf.py
Reformatting vllm/transformers_utils/configs/h2ovl.py
Reformatting vllm/entrypoints/cli/openai.py
Reformatting benchmarks/benchmark_serving.py
Reformatting vllm/model_executor/models/gpt_neox.py
Reformatting vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py
Reformatting vllm/v1/serial_utils.py
Reformatting tests/runai_model_streamer_test/test_runai_model_streamer_loader.py
Reformatting vllm/distributed/__init__.py
Reformatting vllm/v1/worker/__init__.py
Reformatting vllm/v1/attention/backends/flash_attn.py
Reformatting vllm/v1/engine/llm_engine.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py
Reformatting vllm/model_executor/models/phi4mm_utils.py
Reformatting examples/offline_inference/basic/classify.py
Reformatting tests/utils.py
Reformatting vllm/model_executor/layers/fused_moe/deep_gemm_moe.py
Reformatting tests/tpu/__init__.py
Reformatting tests/distributed/test_custom_all_reduce.py
Reformatting vllm/model_executor/guided_decoding/guided_fields.py
Reformatting .buildkite/generate_index.py
Reformatting use_existing_torch.py
Reformatting vllm/model_executor/models/bart.py
Reformatting examples/offline_inference/audio_language.py
Reformatting vllm/distributed/kv_transfer/kv_pipe/base.py
Reformatting tests/v1/__init__.py
Reformatting tests/v1/worker/test_gpu_input_batch.py
Reformatting vllm/model_executor/models/opt.py
Reformatting vllm/engine/output_processor/multi_step.py
Reformatting vllm/platforms/cuda.py
Reformatting benchmarks/kernels/benchmark_machete.py
Reformatting tests/entrypoints/openai/test_shutdown.py
Reformatting vllm/scripts.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/types.py
Reformatting vllm/model_executor/layers/utils.py
Reformatting vllm/model_executor/layers/quantization/gguf.py
Reformatting tests/v1/engine/test_engine_core_client.py
Reformatting tests/entrypoints/openai/test_tokenization.py
Reformatting tests/core/test_serialization.py
Reformatting tests/models/decoder_only/language/test_mamba.py
Reformatting tests/core/utils.py
Reformatting vllm/model_executor/layers/quantization/schema.py
Reformatting vllm/model_executor/models/stablelm.py
Reformatting vllm/model_executor/models/glm4v.py
Reformatting tests/v1/sample/test_sampling_params_e2e.py
Reformatting vllm/model_executor/models/h2ovl.py
Reformatting tests/spec_decode/e2e/conftest.py
Reformatting vllm/model_executor/models/clip.py
Reformatting tests/entrypoints/openai/test_video.py
Reformatting vllm/lora/layers.py
Reformatting vllm/compilation/fix_functionalization.py
Reformatting vllm/entrypoints/openai/serving_embedding.py
Reformatting vllm/_custom_ops.py
Reformatting tests/entrypoints/openai/test_audio.py
Reformatting vllm/model_executor/models/bert.py
Reformatting examples/offline_inference/data_parallel.py
Reformatting tests/v1/test_utils.py
Reformatting vllm/attention/backends/utils.py
Reformatting vllm/worker/multi_step_model_runner.py
Reformatting benchmarks/cutlass_benchmarks/utils.py
Reformatting tests/model_executor/test_guided_processors.py
Reformatting .buildkite/lm-eval-harness/test_lm_eval_correctness.py
Reformatting tests/models/decoder_only/vision_language/test_qwen2_vl.py
Reformatting vllm/transformers_utils/configs/jais.py
Reformatting vllm/transformers_utils/configs/falcon.py
Reformatting tests/lora/test_peft_helper.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py
Reformatting tests/models/embedding/language/test_gritlm.py
Reformatting tests/detokenizer/test_stop_checker.py
Reformatting tests/models/encoder_decoder/vision_language/test_mllama.py
Reformatting tests/mq_llm_engine/test_error_handling.py
Reformatting vllm/model_executor/layers/lightning_attn.py
Reformatting tests/tokenization/test_tokenizer.py
Reformatting tests/model_executor/__init__.py
Reformatting vllm/model_executor/models/mllama4.py
Reformatting vllm/model_executor/models/interfaces.py
Reformatting tests/models/embedding/language/test_scoring.py
Reformatting benchmarks/kernels/benchmark_shapes.py
Reformatting vllm/engine/output_processor/__init__.py
Reformatting .buildkite/nightly-benchmarks/scripts/download-tokenizer.py
Reformatting vllm/adapter_commons/models.py
Reformatting tests/prompt_adapter/test_multi_adapter_inference.py
Reformatting tests/tokenization/test_get_eos.py
Reformatting vllm/v1/attention/backends/mla/__init__.py
Reformatting tests/v1/e2e/test_cascade_attention.py
Reformatting benchmarks/kernels/benchmark_grouped_gemm_cutlass.py
Reformatting tests/entrypoints/openai/correctness/test_lmeval.py
Reformatting examples/online_serving/openai_chat_completion_with_reasoning_streaming.py
Reformatting vllm/inputs/data.py
Reformatting vllm/model_executor/layers/quantization/modelopt.py
Reformatting vllm/entrypoints/api_server.py
Reformatting tests/distributed/test_pipeline_parallel.py
Reformatting examples/online_serving/openai_embedding_client.py
Reformatting vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py
Reformatting tests/v1/tpu/test_sampler.py
Reformatting vllm/transformers_utils/configs/olmo2.py
Reformatting tests/entrypoints/openai/test_cli_args.py
Reformatting vllm/entrypoints/cli/benchmark/__init__.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/core.py
Reformatting tests/runai_model_streamer_test/__init__.py
Reformatting tests/models/embedding/vision_language/__init__.py
Reformatting vllm/model_executor/models/grok1.py
Reformatting tests/spec_decode/e2e/test_ngram_correctness.py
Reformatting examples/offline_inference/rlhf_utils.py
Reformatting tests/models/embedding/vision_language/test_llava_next.py
Reformatting examples/offline_inference/prithvi_geospatial_mae.py
Reformatting tests/models/embedding/language/test_embedding.py
Reformatting tests/models/encoder_decoder/language/__init__.py
Reformatting tests/models/__init__.py
Reformatting vllm/model_executor/layers/quantization/kernels/__init__.py
Reformatting tests/v1/tpu/test_topk_topp_sampler.py
Reformatting tests/kernels/test_rocm_attention_selector.py
Reformatting vllm/model_executor/layers/mamba/ops/ssd_state_passing.py
Reformatting vllm/compilation/fusion.py
Reformatting examples/online_serving/openai_chat_completion_client.py
Reformatting vllm/v1/executor/abstract.py
Reformatting vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py
Reformatting tests/kernels/test_mamba_ssm.py
Reformatting tests/test_embedded_commit.py
Reformatting tests/kernels/test_cascade_flash_attn.py
Reformatting vllm/distributed/device_communicators/pynccl_wrapper.py
Reformatting vllm/model_executor/models/gemma.py
Reformatting tests/vllm_test_utils/vllm_test_utils/blame.py
Reformatting examples/offline_inference/neuron.py
Reformatting vllm/model_executor/models/gpt_bigcode.py
Reformatting vllm/model_executor/layers/rejection_sampler.py
Reformatting tests/kernels/test_permute_cols.py
Reformatting tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_gemma_embedding.py
Reformatting tests/test_version.py
Reformatting tests/compile/conftest.py
Reformatting vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py
Reformatting vllm/spec_decode/batch_expansion.py
Reformatting tests/models/multimodal/processing/test_common.py
Reformatting examples/offline_inference/tpu.py
Reformatting tests/vllm_test_utils/vllm_test_utils/__init__.py
Reformatting tests/spec_decode/test_spec_decode_worker.py
Reformatting vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py
Reformatting vllm/model_executor/layers/quantization/kv_cache.py
Reformatting tests/test_utils.py
Reformatting vllm/entrypoints/openai/serving_transcription.py
Reformatting vllm/model_executor/models/telechat2.py
Reformatting vllm/model_executor/models/aya_vision.py
Reformatting tests/spec_decode/e2e/__init__.py
Reformatting tests/kernels/test_fused_quant_layernorm.py
Reformatting vllm/adapter_commons/utils.py
Reformatting vllm/transformers_utils/processors/ovis2.py
Reformatting tests/kernels/quant_utils.py
Reformatting tests/engine/test_computed_prefix_blocks.py
Reformatting vllm/compilation/fx_utils.py
Reformatting benchmarks/kernels/benchmark_quant.py
Reformatting vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py
Reformatting vllm/compilation/compiler_interface.py
Reformatting vllm/model_executor/models/phi3.py
Reformatting vllm/entrypoints/openai/serving_pooling.py
Reformatting vllm/model_executor/models/dbrx.py
Reformatting examples/offline_inference/structured_outputs.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py
Reformatting vllm/model_executor/models/internlm2.py
Reformatting vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py
Reformatting tests/tool_use/test_jamba_tool_parser.py
Reformatting vllm/transformers_utils/configs/eagle.py
Reformatting benchmarks/kernels/benchmark_lora.py
Reformatting vllm/model_executor/models/constant_size_cache.py
Reformatting tests/kernels/test_cache.py
Reformatting tests/entrypoints/openai/tool_parsers/__init__.py
Reformatting vllm/executor/msgspec_utils.py
Reformatting vllm/model_executor/models/nemotron.py
Reformatting vllm/compilation/inductor_pass.py
Reformatting vllm/model_executor/models/mamba2.py
Reformatting tests/v1/core/test_scheduler_e2e.py
Reformatting examples/offline_inference/encoder_decoder_multimodal.py
Reformatting vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py
Reformatting vllm/v1/engine/core.py
Reformatting tests/models/embedding/vision_language/test_phi3v.py
Reformatting benchmarks/cutlass_benchmarks/sparse_benchmarks.py
Reformatting docs/source/conf.py
Reformatting vllm/attention/ops/triton_decode_attention.py
Reformatting vllm/entrypoints/cli/types.py
Reformatting vllm/engine/async_llm_engine.py
Reformatting vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py
Reformatting tests/kernels/test_int8_quant.py
Reformatting vllm/model_executor/models/internlm2_ve.py
Reformatting vllm/sampling_params.py
Reformatting vllm/transformers_utils/configs/nemotron.py
Reformatting examples/offline_inference/rlhf_colocate.py
Reformatting vllm/v1/core/encoder_cache_manager.py
Reformatting tests/tensorizer_loader/__init__.py
Reformatting vllm/entrypoints/openai/__init__.py
Reformatting tests/v1/tpu/test_mha_attn.py
Reformatting vllm/worker/neuron_model_runner.py
Reformatting vllm/entrypoints/openai/serving_tokenization.py
Reformatting vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py
Reformatting vllm/transformers_utils/configs/nvlm_d.py
Reformatting vllm/distributed/device_communicators/cpu_communicator.py
Reformatting tests/async_engine/api_server_async_engine.py
Reformatting vllm/multimodal/hasher.py
Reformatting examples/offline_inference/load_sharded_state.py
Reformatting vllm/adapter_commons/__init__.py
Reformatting tests/basic_correctness/test_basic_correctness.py
Reformatting vllm/entrypoints/openai/serving_engine.py
Reformatting tests/tool_use/test_chat_completion_request_validations.py
Reformatting vllm/lora/request.py
Reformatting vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py
Reformatting tests/multimodal/__init__.py
Reformatting tests/v1/spec_decode/test_ngram.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py
Reformatting tests/spec_decode/e2e/test_integration_dist_tp4.py
Reformatting vllm/attention/ops/nki_flash_attn.py
Reformatting vllm/distributed/kv_transfer/kv_connector/__init__.py
Reformatting vllm/transformers_utils/configs/ultravox.py
Reformatting tests/distributed/test_pipeline_partition.py
Reformatting vllm/model_executor/models/gpt_j.py
Reformatting tests/v1/tpu/worker/__init__.py
Reformatting vllm/model_executor/layers/quantization/moe_wna16.py
Reformatting vllm/transformers_utils/s3_utils.py
Reformatting examples/offline_inference/mistral-small.py
Reformatting tests/entrypoints/openai/test_vision.py
Reformatting vllm/model_executor/models/deepseek.py
Reformatting tests/lora/test_lora_checkpoints.py
Reformatting vllm/attention/backends/triton_mla.py
Reformatting vllm/compilation/noop_elimination.py
Reformatting vllm/v1/sample/rejection_sampler.py
Reformatting vllm/lora/lora.py
Reformatting vllm/v1/spec_decode/__init__.py
Reformatting tests/spec_decode/e2e/test_multistep_correctness.py
Reformatting examples/offline_inference/simple_profiling.py
Reformatting examples/online_serving/opentelemetry/dummy_client.py
Reformatting tests/model_executor/test_enabled_custom_ops.py
Reformatting benchmarks/backend_request_func.py
Reformatting tests/models/encoder_decoder/language/test_bart.py
Reformatting vllm/v1/sample/ops/bad_words.py
Reformatting vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py
Reformatting tests/model_executor/test_model_load_with_params.py
Reformatting vllm/spec_decode/target_model_runner.py
Reformatting vllm/v1/engine/__init__.py
Reformatting tests/entrypoints/openai/test_oot_registration.py
Reformatting vllm/transformers_utils/tokenizer_group/__init__.py
Reformatting examples/online_serving/openai_pooling_client.py
Reformatting vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py
Reformatting tests/compile/test_full_graph.py
Reformatting tests/models/decoder_only/language/test_mistral.py
Reformatting benchmarks/kernels/benchmark_moe.py
Reformatting vllm/transformers_utils/configs/mlp_speculator.py
Reformatting vllm/model_executor/layers/spec_decode_base_sampler.py
Reformatting examples/online_serving/openai_chat_completion_client_for_multimodal.py
Reformatting vllm/model_executor/layers/layernorm.py
Reformatting tests/entrypoints/openai/test_encoder_decoder.py
Reformatting vllm/worker/worker_base.py
Reformatting vllm/multimodal/profiling.py
Reformatting vllm/distributed/utils.py
Reformatting tests/entrypoints/openai/tool_parsers/utils.py
Reformatting tests/benchmarks/test_throughput_cli.py
Reformatting vllm/attention/backends/mla/common.py
Reformatting tests/multimodal/test_inputs.py
Reformatting tests/kernels/test_lightning_attn.py
Reformatting tests/models/multimodal/processing/test_h2ovl.py
Reformatting tests/quantization/test_bitsandbytes.py
Reformatting vllm/entrypoints/cli/__init__.py
Reformatting vllm/model_executor/layers/quantization/utils/gptq_utils.py
Reformatting vllm/model_executor/guided_decoding/outlines_decoding.py
Reformatting vllm/model_executor/models/minicpmv.py
Reformatting tests/worker/test_swap.py
Reformatting tests/kernels/test_uva.py
Reformatting vllm/worker/hpu_model_runner.py
Reformatting vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py
Reformatting tests/core/test_scheduler_encoder_decoder.py
Reformatting tests/kernels/test_gptq.py
Reformatting tests/v1/tpu/test_basic.py
Reformatting csrc/moe/marlin_moe_wna16/generate_kernels.py
Reformatting vllm/device_allocator/cumem.py
Reformatting vllm/engine/multiprocessing/client.py
Reformatting vllm/platforms/hpu.py
Reformatting benchmarks/benchmark_serving_structured_output.py
Reformatting vllm/model_executor/layers/quantization/awq_triton.py
Reformatting vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py
Reformatting vllm/engine/__init__.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py
Reformatting vllm/v1/metrics/__init__.py
Reformatting tests/distributed/test_same_node.py
Reformatting vllm/transformers_utils/__init__.py
Reformatting tests/models/decoder_only/language/test_models.py
Reformatting vllm/core/evictor.py
Reformatting .buildkite/nightly-benchmarks/scripts/generate-nightly-markdown.py
Reformatting vllm/model_executor/models/exaone.py
Reformatting vllm/model_executor/layers/mamba/__init__.py
Reformatting vllm/model_executor/models/minimax_text_01.py
Reformatting vllm/lora/punica_wrapper/punica_base.py
Reformatting vllm/v1/executor/ray_distributed_executor.py
Reformatting vllm/model_executor/model_loader/loader.py
Reformatting vllm/v1/sample/ops/topk_topp_sampler.py
Reformatting vllm/entrypoints/openai/tool_parsers/utils.py
Reformatting tests/v1/sample/test_rejection_sampler.py
Reformatting benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py
Reformatting tests/mq_llm_engine/test_load.py
Reformatting benchmarks/kernels/benchmark_rope.py
Reformatting benchmarks/disagg_benchmarks/visualize_benchmark_results.py
Reformatting vllm/pooling_params.py
Reformatting tools/check_spdx_header.py
Reformatting tests/models/decoder_only/language/test_nvfp4.py
Reformatting tests/async_engine/conftest.py
Reformatting vllm/device_allocator/__init__.py
Reformatting examples/offline_inference/multilora_inference.py
Reformatting vllm/model_executor/models/llama_eagle.py
Reformatting tests/test_inputs.py
Reformatting vllm/v1/engine/parallel_sampling.py
Reformatting tests/spec_decode/test_batch_expansion.py
Reformatting vllm/v1/worker/block_table.py
Reformatting vllm/attention/selector.py
Reformatting vllm/model_executor/models/deepseek_mtp.py
Reformatting vllm/transformers_utils/configs/solar.py
Reformatting tests/models/multimodal/processing/__init__.py
Reformatting tests/worker/__init__.py
Reformatting tests/lora/__init__.py
Reformatting vllm/worker/__init__.py
Reformatting vllm/entrypoints/cli/benchmark/main.py
Reformatting vllm/engine/output_processor/single_step.py
Reformatting tests/v1/tpu/__init__.py
Reformatting vllm/entrypoints/cli/main.py
Reformatting tests/basic_correctness/test_preemption.py
Reformatting vllm/adapter_commons/worker_manager.py
Reformatting tests/lora/test_quant_model.py
Reformatting examples/offline_inference/reproduciblity.py
Reformatting vllm/distributed/device_communicators/cuda_wrapper.py
Reformatting tests/models/embedding/__init__.py
Reformatting tests/models/decoder_only/vision_language/test_models.py
Reformatting vllm/model_executor/models/solar.py
Reformatting vllm/model_executor/guided_decoding/guidance_logits_processors.py
Reformatting vllm/transformers_utils/configs/arctic.py
Reformatting vllm/beam_search.py
Reformatting tests/kernels/test_awq.py
Reformatting vllm/model_executor/models/phi3v.py
Reformatting vllm/model_executor/guided_decoding/xgrammar_decoding.py
Reformatting tests/benchmarks/test_latency_cli.py
Reformatting vllm/worker/worker.py
Reformatting tests/tool_use/test_tool_choice_required.py
Reformatting vllm/engine/output_processor/util.py
Reformatting tests/lora/test_baichuan.py
Reformatting tests/prefix_caching/__init__.py
Reformatting tests/vllm_test_utils/setup.py
Reformatting vllm/spec_decode/smaller_tp_proposer_worker.py
Reformatting vllm/v1/spec_decode/ngram_proposer.py
Reformatting tests/tracing/__init__.py
Reformatting tests/v1/core/test_prefix_caching.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py
Reformatting tools/report_build_time_ninja.py
Reformatting vllm/model_executor/layers/mamba/ops/__init__.py
Reformatting tests/core/block/__init__.py
Reformatting examples/offline_inference/basic/chat.py
Reformatting vllm/attention/ops/paged_attn.py
Reformatting vllm/model_executor/models/bamba.py
Reformatting vllm/profiler/layerwise_profile.py
Reformatting examples/offline_inference/save_sharded_state.py
Reformatting vllm/executor/__init__.py
Reformatting vllm/entrypoints/llm.py
Reformatting tests/spec_decode/e2e/test_medusa_correctness.py
Reformatting vllm/model_executor/layers/quantization/tpu_int8.py
Reformatting vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py
Reformatting vllm/v1/sample/__init__.py
Reformatting tests/v1/e2e/test_correctness_sliding_window.py
Reformatting vllm/lora/punica_wrapper/punica_gpu.py
Reformatting tests/test_scalartype.py
Reformatting tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/__init__.py
Reformatting vllm/v1/sample/ops/penalties.py
Reformatting vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py
Reformatting tests/entrypoints/llm/test_generate.py
Reformatting tests/models/utils.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/custom_inputs.py
Reformatting vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py
Reformatting vllm/attention/ops/ipex_attn.py
Reformatting examples/online_serving/cohere_rerank_client.py
Reformatting tests/entrypoints/llm/test_init.py
Reformatting vllm/benchmarks/utils.py
Reformatting vllm/multimodal/utils.py
Reformatting tests/distributed/test_pp_cudagraph.py
Reformatting vllm/v1/engine/logprobs.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py
Reformatting tests/samplers/test_seeded_generate.py
Reformatting vllm/transformers_utils/tokenizer_group/tokenizer_group.py
Reformatting tests/kernels/test_moe.py
Reformatting tests/core/block/test_prefix_caching_block.py
Reformatting vllm/model_executor/layers/quantization/fbgemm_fp8.py
Reformatting tests/async_engine/test_request_tracker.py
Reformatting vllm/v1/engine/detokenizer.py
Reformatting tests/fastsafetensors_loader/test_fastsafetensors_loader.py
Reformatting tests/quantization/test_quark.py
Reformatting vllm/model_executor/pooling_metadata.py
Reformatting tests/samplers/test_logits_processor.py
Reformatting examples/offline_inference/embed_matryoshka_fy.py
Reformatting vllm/model_executor/models/qwen2_5_vl.py
Reformatting vllm/model_executor/models/arctic.py
Reformatting tests/spec_decode/e2e/test_logprobs.py
Reformatting vllm/model_executor/model_loader/__init__.py
Reformatting tests/kernels/test_fp8_quant.py
Reformatting tests/models/decoder_only/language/test_hybrid.py
Reformatting vllm/model_executor/models/internvl.py
Reformatting tests/models/decoder_only/vision_language/test_awq.py
Reformatting tests/entrypoints/openai/test_lora_adapters.py
Reformatting vllm/model_executor/models/mlp_speculator.py
Reformatting tests/encoder_decoder/__init__.py
Reformatting vllm/model_executor/models/qwen2.py
Reformatting tests/entrypoints/openai/test_vision_embedding.py
Reformatting vllm/model_executor/layers/quantization/utils/machete_utils.py
Reformatting vllm/worker/cache_engine.py
Reformatting vllm/transformers_utils/configs/moonvit.py
Reformatting vllm/utils.py
Reformatting tests/lora/test_add_lora.py
Reformatting tests/kernels/test_awq_marlin.py
Reformatting vllm/prompt_adapter/utils.py
Reformatting examples/offline_inference/vision_language_multi_image.py
Reformatting vllm/transformers_utils/detokenizer_utils.py
Reformatting vllm/profiler/__init__.py
Reformatting tests/spec_decode/__init__.py
Reformatting tests/models/decoder_only/audio_language/__init__.py
Reformatting tests/entrypoints/llm/test_chat.py
Reformatting vllm/model_executor/models/phimoe.py
Reformatting tests/test_regression.py
Reformatting vllm/__init__.py
Reformatting vllm/version.py
Reformatting tests/v1/sample/test_logprobs.py
Reformatting vllm/model_executor/models/mistral3.py
Reformatting tests/models/multimodal/processing/test_llava_next.py
Reformatting vllm/compilation/backends.py
Reformatting vllm/core/__init__.py
Reformatting tests/models/decoder_only/vision_language/test_interleaved.py
Reformatting tests/v1/engine/__init__.py
Reformatting vllm/worker/tpu_model_runner.py
Reformatting vllm/v1/core/kv_cache_utils.py
Reformatting vllm/model_executor/layers/quantization/bitsandbytes.py
Reformatting tests/tokenization/test_mistral_tokenizer.py
Reformatting vllm/model_executor/models/utils.py
Reformatting vllm/v1/structured_output/backend_types.py
Reformatting vllm/transformers_utils/tokenizers/__init__.py
Reformatting tests/v1/engine/test_engine_core.py
Reformatting vllm/worker/utils.py
Reformatting tests/neuron/1_core/test_prefix_prefill.py
Reformatting benchmarks/benchmark_utils.py
Reformatting tests/core/block/e2e/test_correctness.py
Reformatting benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py
Reformatting vllm/lora/ops/triton_ops/utils.py
Reformatting tests/models/test_oot_registration.py
Reformatting tests/encoder_decoder/test_e2e_correctness.py
Reformatting vllm/model_executor/models/idefics2_vision_model.py
Reformatting tests/samplers/test_typical_acceptance_sampler.py
Reformatting vllm/attention/ops/blocksparse_attention/utils.py
Reformatting vllm/lora/ops/__init__.py
Reformatting tests/neuron/1_core/test_activation.py
Reformatting tests/kernels/test_prefix_prefill.py
Reformatting vllm/v1/worker/worker_base.py
Reformatting vllm/compilation/decorators.py
Reformatting tests/__init__.py
Reformatting vllm/model_executor/models/qwen2_vl.py
Reformatting vllm/v1/engine/core_client.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/utils.py
Reformatting tests/models/test_utils.py
Reformatting tests/lora/utils.py
Reformatting tests/tokenization/test_tokenizer_registry.py
Reformatting vllm/model_executor/models/kimi_vl.py
Reformatting tests/entrypoints/openai/correctness/test_transcription_api_correctness.py
Reformatting tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_attention_backend.py
Reformatting examples/offline_inference/embed_jina_embeddings_v3.py
Reformatting vllm/model_executor/layers/fused_moe/cutlass_moe.py
Reformatting vllm/model_executor/models/phi.py
Reformatting vllm/_ipex_ops.py
Reformatting vllm/model_executor/layers/quantization/neuron_quant.py
Reformatting vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py
Reformatting vllm/profiler/utils.py
Reformatting tests/spec_decode/conftest.py
Reformatting vllm/core/block/interfaces.py
Reformatting tests/compile/__init__.py
Reformatting vllm/model_executor/layers/quantization/__init__.py
Reformatting vllm/engine/protocol.py
Reformatting tests/vllm_test_utils/vllm_test_utils/monitor.py
Reformatting vllm/model_executor/layers/quantization/gptq.py
Reformatting tests/v1/test_async_llm_dp.py
Reformatting examples/offline_inference/neuron_int8_quantization.py
Reformatting tests/models/decoder_only/language/test_fp8.py
Reformatting examples/online_serving/openai_cross_encoder_score.py
Reformatting tests/models/encoder_decoder/audio_language/__init__.py
Reformatting vllm/core/block/common.py
Reformatting tests/models/encoder_decoder/vision_language/test_broadcast.py
Reformatting tests/tokenization/test_detokenize.py
Reformatting vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py
Reformatting examples/offline_inference/prefix_caching.py
Reformatting tests/tool_use/utils.py
Reformatting tests/tpu/test_quantization_accuracy.py
Reformatting benchmarks/kernels/benchmark_rmsnorm.py
Reformatting vllm/entrypoints/ssl.py
Reformatting vllm/adapter_commons/request.py
Reformatting vllm/v1/executor/multiproc_executor.py
Reformatting vllm/v1/request.py
Reformatting vllm/model_executor/models/llava_onevision.py
Reformatting vllm/v1/structured_output/request.py
Reformatting vllm/model_executor/models/qwen.py
Reformatting tests/kernels/test_merge_attn_states.py
Reformatting examples/offline_inference/mlpspeculator.py
Reformatting tests/spec_decode/e2e/test_integration.py
Reformatting benchmarks/benchmark_dataset.py
Reformatting tests/entrypoints/openai/test_embedding.py
Reformatting vllm/model_executor/layers/mamba/ops/causal_conv1d.py
Reformatting vllm/distributed/device_communicators/cuda_communicator.py
Reformatting tests/core/test_num_computed_tokens_update.py
Reformatting vllm/lora/ops/triton_ops/__init__.py
Reformatting tests/distributed/test_shm_broadcast.py
Reformatting vllm/lora/__init__.py
Reformatting tests/entrypoints/openai/test_prompt_validation.py
Reformatting vllm/sequence.py
Reformatting examples/offline_inference/vision_language.py
Reformatting vllm/entrypoints/cli/serve.py
Reformatting vllm/model_executor/models/interfaces_base.py
Reformatting vllm/attention/ops/blocksparse_attention/interface.py
Reformatting vllm/worker/xpu_model_runner.py
Reformatting tests/quantization/test_lm_head.py
Reformatting vllm/worker/tpu_worker.py
Reformatting tests/kernels/test_block_fp8.py
Reformatting tests/quantization/test_compressed_tensors.py
Reformatting tests/multimodal/utils.py
Reformatting tests/kernels/test_triton_decode_attention.py
Reformatting vllm/multimodal/processing.py
Reformatting vllm/transformers_utils/configs/dbrx.py
Reformatting vllm/assets/video.py
Reformatting tests/reasoning/test_granite_reasoning_parser.py
Reformatting tests/lora/test_mixtral.py
Reformatting vllm/distributed/communication_op.py
Reformatting tests/entrypoints/llm/test_generate_multiple_loras.py
Reformatting vllm/engine/arg_utils.py
Reformatting vllm/model_executor/layers/quantization/quark/__init__.py
Reformatting vllm/model_executor/models/gemma3.py
Reformatting vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py
Reformatting vllm/model_executor/models/bloom.py
Reformatting tests/v1/tpu/test_pallas.py
Reformatting vllm/transformers_utils/tokenizers/mistral.py
Reformatting tests/quantization/test_ipex_quant.py
Reformatting vllm/model_executor/model_loader/neuron.py
Reformatting vllm/compilation/__init__.py
Reformatting vllm/model_executor/layers/quantization/quark/schemes/__init__.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/runners.py
Reformatting vllm/assets/base.py
Reformatting tests/model_executor/conftest.py
Reformatting tests/distributed/test_ca_buffer_sharing.py
Reformatting vllm/attention/ops/merge_attn_states.py
Reformatting tests/quantization/utils.py
Reformatting tests/spec_decode/e2e/test_seed.py
Reformatting vllm/test_utils.py
Reformatting vllm/model_executor/models/gritlm.py
Reformatting tests/kv_transfer/test_send_recv.py
Reformatting tests/multi_step/test_correctness_llm.py
Reformatting vllm/model_executor/models/fuyu.py
Reformatting vllm/model_executor/models/mpt.py
Reformatting examples/online_serving/disagg_examples/disagg_proxy_demo.py
Reformatting vllm/v1/utils.py
Reformatting vllm/v1/worker/gpu_model_runner.py
Reformatting tests/models/encoder_decoder/__init__.py
Reformatting vllm/model_executor/layers/quantization/qqq.py
Reformatting vllm/attention/backends/abstract.py
Reformatting tests/samplers/test_sampler.py
Reformatting tests/models/encoder_decoder/vision_language/__init__.py
Reformatting vllm/model_executor/models/commandr.py
Reformatting tests/models/embedding/language/test_cls_models.py
Reformatting tests/worker/test_model_input.py
Reformatting tests/entrypoints/test_chat_utils.py
Reformatting vllm/spec_decode/metrics.py
Reformatting vllm/engine/metrics_types.py
Reformatting vllm/model_executor/models/qwen2_rm.py
Reformatting tests/spec_decode/e2e/test_eagle_correctness.py
Reformatting vllm/benchmarks/serve.py
Reformatting vllm/model_executor/models/medusa.py
Reformatting vllm/v1/metrics/loggers.py
Reformatting vllm/multimodal/video.py
Reformatting tests/spec_decode/e2e/test_mlp_correctness.py
Reformatting examples/offline_inference/disaggregated_prefill_lmcache.py
Reformatting vllm/model_executor/models/prithvi_geospatial_mae.py
Reformatting tests/async_engine/__init__.py
Reformatting vllm/model_executor/layers/quantization/utils/layer_utils.py
Reformatting vllm/attention/backends/flashmla.py
Reformatting vllm/model_executor/models/persimmon.py
Reformatting vllm/adapter_commons/layers.py
Reformatting tests/models/decoder_only/language/test_gptq_marlin.py
Reformatting tests/models/decoder_only/vision_language/vlm_utils/case_filtering.py
Reformatting vllm/model_executor/models/olmoe.py
Reformatting tests/core/block/e2e/__init__.py
Reformatting vllm/v1/attention/__init__.py
Reformatting tests/entrypoints/llm/test_prompt_validation.py
Reformatting tests/compile/piecewise/test_toy_llama.py
Reformatting vllm/transformers_utils/configs/mllama.py
Reformatting vllm/v1/spec_decode/eagle.py
Reformatting tests/plugins_tests/test_scheduler_plugins.py
Reformatting vllm/spec_decode/util.py
Reformatting tests/spec_decode/e2e/test_compatibility.py
Reformatting vllm/entrypoints/__init__.py
Reformatting vllm/v1/attention/backends/triton_attn.py
Reformatting tests/reasoning/utils.py
Reformatting vllm/logging_utils/__init__.py
Reformatting tests/samplers/test_no_bad_words.py
Reformatting vllm/model_executor/models/minimax_cache.py
Reformatting examples/other/tensorize_vllm_model.py
Reformatting vllm/v1/core/sched/utils.py
Reformatting tests/spec_decode/test_dynamic_spec_decode.py
Reformatting vllm/executor/multiproc_worker_utils.py
Reformatting tests/distributed/test_pynccl.py
Reformatting vllm/distributed/device_communicators/pynccl.py
Reformatting tests/engine/test_short_mm_context.py
Reformatting tests/engine/test_multiproc_workers.py
Reformatting vllm/lora/punica_wrapper/punica_cpu.py
Reformatting vllm/lora/punica_wrapper/punica_hpu.py
Reformatting vllm/reasoning/abs_reasoning_parsers.py
Reformatting tests/tokenization/test_tokenizer_group.py
Reformatting vllm/model_executor/models/mamba.py
Reformatting tests/async_engine/test_async_llm_engine.py
Reformatting tests/quantization/__init__.py
Reformatting tests/test_seed_behavior.py
Reformatting tests/quantization/test_gptq_dynamic.py
Reformatting tests/v1/entrypoints/llm/test_struct_output_generate.py
Reformatting tests/plugins_tests/test_platform_plugins.py
Reformatting vllm/attention/ops/hpu_paged_attn.py
Reformatting tests/models/decoder_only/language/test_phimoe.py
Reformatting vllm/model_executor/models/gpt2.py
Reformatting examples/online_serving/openai_chat_completion_client_with_tools_required.py
Reformatting vllm/entrypoints/openai/tool_parsers/__init__.py
Reformatting tests/v1/engine/conftest.py
Reformatting tests/kernels/test_block_int8.py
Reformatting tests/build_cython.py
Reformatting vllm/model_executor/models/idefics3.py
Reformatting tests/kernels/test_attention.py
Reformatting vllm/lora/punica_wrapper/utils.py
Reformatting vllm/model_executor/__init__.py
Reformatting tests/kernels/test_nvfp4_scaled_mm.py
Reformatting tests/reasoning/__init__.py
Reformatting benchmarks/kernels/benchmark_aqlm.py
Reformatting tests/kernels/test_flashinfer.py
Reformatting tests/fastsafetensors_loader/__init__.py
Reformatting examples/online_serving/openai_chat_completion_client_with_tools.py
Reformatting tests/compile/test_pass_manager.py
Reformatting vllm/model_executor/layers/linear.py
Reformatting vllm/attention/backends/torch_sdpa.py
Reformatting vllm/lora/models.py
Reformatting vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py
Reformatting tests/tool_use/__init__.py
Reformatting tests/entrypoints/openai/test_return_tokens_as_ids.py
Reformatting tests/quantization/test_experts_int8.py
Reformatting vllm/spec_decode/top1_proposer.py
Reformatting tests/models/decoder_only/language/test_granite.py
Reformatting tests/lora/test_lora_huggingface.py
Reformatting tests/lora/test_lora_manager.py
Reformatting benchmarks/overheads/benchmark_hashing.py
Reformatting tests/spec_decode/test_multi_step_worker.py
Reformatting tests/v1/sample/test_logprobs_e2e.py
Reformatting vllm/v1/core/kv_cache_manager.py
Reformatting tests/models/encoder_decoder/vision_language/test_florence2.py
Reformatting vllm/attention/ops/__init__.py
Reformatting vllm/model_executor/models/chameleon.py
Reformatting examples/offline_inference/llm_engine_example.py
Reformatting tests/neuron/1_core/test_logits_processor.py
Reformatting vllm/spec_decode/multi_step_worker.py
Reformatting vllm/spec_decode/interfaces.py
Reformatting vllm/model_executor/models/jais.py
Reformatting tests/entrypoints/openai/test_async_tokenization.py
Reformatting tests/test_sharded_state_loader.py
Reformatting vllm/attention/layer.py
Reformatting vllm/model_executor/models/glm.py
Reformatting vllm/prompt_adapter/__init__.py
Reformatting tests/v1/sample/test_topk_topp_sampler.py
Reformatting vllm/forward_context.py
Reformatting vllm/v1/spec_decode/metrics.py
Reformatting vllm/attention/backends/hpu_attn.py
Reformatting vllm/spec_decode/spec_decode_worker.py
Reformatting vllm/transformers_utils/configs/internvl.py
Reformatting vllm/attention/ops/triton_merge_attn_states.py
Reformatting tests/models/registry.py
Reformatting vllm/model_executor/layers/mamba/ops/mamba_ssm.py
Reformatting tests/kernels/test_cutlass_2of4_sparse.py
Reformatting vllm/transformers_utils/processors/__init__.py
Reformatting vllm/transformers_utils/configs/chatglm.py
Reformatting vllm/core/block/prefix_caching_block.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py
Reformatting vllm/transformers_utils/config.py
Reformatting tests/samplers/test_logprobs.py
Reformatting tests/samplers/__init__.py
Reformatting vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py
Reformatting tests/models/test_transformers.py
Reformatting tests/spec_decode/e2e/test_integration_dist_tp2.py
Reformatting tests/weight_loading/test_weight_loading.py
Reformatting tests/v1/core/test_kv_cache_utils.py
Reformatting vllm/model_executor/layers/quantization/ipex_quant.py
Reformatting vllm/model_executor/layers/quantization/utils/allspark_utils.py
Reformatting tests/kernels/test_cutlass.py
Reformatting vllm/v1/worker/gpu_input_batch.py
Reformatting tests/mq_llm_engine/utils.py
Reformatting tests/multi_step/__init__.py
Reformatting vllm/reasoning/deepseek_r1_reasoning_parser.py
Reformatting tests/v1/core/test_scheduler.py
Reformatting examples/offline_inference/vision_language_embedding.py
Reformatting examples/offline_inference/basic/embed.py
Reformatting tests/kernels/test_aqlm.py
Reformatting vllm/multimodal/registry.py
Reformatting tests/core/block/test_block_manager.py
Reformatting vllm/distributed/device_communicators/xpu_communicator.py
Reformatting tests/engine/test_skip_tokenizer_init.py
Reformatting vllm/platforms/neuron.py
Reformatting vllm/model_executor/models/qwen2_audio.py
Reformatting tools/profiler/visualize_layerwise_profile.py
Reformatting vllm/benchmarks/throughput.py
Reformatting tests/kernels/test_cutlass_moe.py
Reformatting vllm/distributed/device_communicators/neuron_communicator.py
Reformatting vllm/distributed/kv_transfer/kv_connector/factory.py
Reformatting vllm/lora/fully_sharded_layers.py
Reformatting vllm/model_executor/layers/quantization/awq.py
Reformatting tests/v1/engine/test_engine_args.py
Reformatting vllm/model_executor/models/moonvit.py
Reformatting tests/v1/tpu/test_perf.py
Reformatting examples/offline_inference/basic/score.py
Reformatting vllm/platforms/rocm.py
Reformatting tests/runai_model_streamer_test/test_weight_utils.py
Reformatting vllm/model_executor/layers/quantization/utils/fp8_utils.py
Reformatting vllm/engine/output_processor/stop_checker.py
Reformatting vllm/model_executor/models/llama.py
Reformatting vllm/v1/spec_decode/metadata.py
Reformatting tests/entrypoints/openai/test_metrics.py
Reformatting vllm/model_executor/models/roberta.py
Reformatting vllm/logger.py
Reformatting vllm/model_executor/models/blip2.py
Reformatting tests/prompt_adapter/test_bloom.py
Reformatting tests/samplers/test_ignore_eos.py
Reformatting tests/models/multimodal/processing/test_phi3v.py
Reformatting tests/kernels/test_pos_encoding.py
Reformatting tests/core/block/test_naive_block.py
Reformatting tests/v1/engine/test_llm_engine.py
Reformatting tests/spec_decode/test_metrics.py
Reformatting tests/metrics/__init__.py
Reformatting tests/tensorizer_loader/conftest.py
Reformatting tests/kernels/test_triton_moe_ptpc_fp8.py
Reformatting vllm/model_executor/layers/quantization/aqlm.py
Reformatting vllm/v1/core/__init__.py
Reformatting tests/mistral_tool_use/utils.py
Reformatting tests/entrypoints/__init__.py
Reformatting csrc/cutlass_extensions/vllm_cutlass_library_extension.py
Reformatting benchmarks/kernels/weight_shapes.py
Reformatting vllm/model_executor/models/mixtral.py
Reformatting vllm/model_executor/layers/quantization/utils/int8_utils.py
Reformatting tests/test_logger.py
Reformatting vllm/transformers_utils/configs/telechat2.py
Reformatting vllm/model_executor/guided_decoding/__init__.py
Reformatting tests/tool_use/test_parallel_tool_calls.py
Reformatting tests/kernels/test_attention_selector.py
Reformatting examples/offline_inference/distributed.py
Reformatting tests/kernels/test_flashmla.py
Reformatting vllm/model_executor/models/gemma3_mm.py
Reformatting vllm/worker/xpu_worker.py
Reformatting vllm/model_executor/models/molmo.py
Reformatting vllm/model_executor/models/minicpm.py
Reformatting vllm/model_executor/models/florence2.py
Reformatting vllm/worker/multi_step_tpu_worker.py
Reformatting tests/models/decoder_only/language/test_modelopt.py
Reformatting tests/quantization/test_configs.py
Reformatting vllm/model_executor/models/minicpmo.py
Reformatting vllm/attention/backends/cpu_mla.py
Reformatting vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py
Reformatting tests/compile/test_wrapper.py
Reformatting tests/entrypoints/openai/test_completion.py
Reformatting vllm/worker/cpu_enc_dec_model_runner.py
Reformatting vllm/spec_decode/proposer_worker_base.py
Reformatting vllm/core/block_manager.py
Reformatting vllm/model_executor/models/smolvlm.py
Reformatting tests/v1/worker/__init__.py
Reformatting vllm/model_executor/layers/fused_moe/moe_pallas.py
Reformatting tests/entrypoints/openai/test_serving_chat.py
Reformatting vllm/distributed/kv_transfer/kv_connector/simple_connector.py
Reformatting tests/kv_transfer/test_lookup_buffer.py
Reformatting vllm/v1/structured_output/backend_guidance.py
Reformatting vllm/v1/core/sched/__init__.py
Reformatting tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/__init__.py
Reformatting tests/models/decoder_only/vision_language/test_intern_vit.py
Reformatting vllm/v1/stats/common.py
Reformatting examples/offline_inference/profiling.py
Reformatting tests/v1/entrypoints/__init__.py
Reformatting vllm/entrypoints/openai/serving_score.py
Reformatting vllm/model_executor/models/olmo.py
Reformatting vllm/executor/ray_distributed_executor.py
Reformatting vllm/distributed/kv_transfer/kv_lookup_buffer/base.py
Reformatting tests/models/decoder_only/language/test_gguf.py
Reformatting examples/offline_inference/disaggregated_prefill.py
Reformatting vllm/model_executor/models/zamba2.py
Reformatting vllm/spec_decode/medusa_worker.py
Reformatting vllm/prompt_adapter/layers.py
Reformatting vllm/attention/ops/blocksparse_attention/__init__.py
Reformatting vllm/model_executor/models/phi4mm_audio.py
Reformatting vllm/v1/sample/tpu/sampler.py
Reformatting tests/test_config.py
Reformatting .buildkite/nightly-benchmarks/scripts/convert-results-json-to-markdown.py
Reformatting vllm/model_executor/parameter.py
Reformatting tests/benchmarks/test_serve_cli.py
Reformatting vllm/distributed/device_communicators/base_device_communicator.py
Reformatting vllm/entrypoints/cli/benchmark/throughput.py
Reformatting tests/core/block/conftest.py
Reformatting tests/plugins/vllm_add_dummy_platform/setup.py
Reformatting .buildkite/nightly-benchmarks/scripts/get-lmdeploy-modelname.py
Reformatting tests/mistral_tool_use/__init__.py
Reformatting vllm/model_executor/models/baichuan.py
Reformatting tests/models/multimodal/__init__.py
Reformatting vllm/model_executor/models/glm4.py
Reformatting tests/multimodal/test_processing.py
Reformatting tests/async_engine/test_api_server.py
Reformatting benchmarks/kernels/utils.py
Reformatting vllm/multimodal/image.py
Reformatting tests/tool_use/test_tool_calls.py
Reformatting examples/online_serving/openai_chat_completion_tool_calls_with_reasoning.py
Reformatting vllm/core/interfaces.py
Reformatting examples/offline_inference/rlhf.py
Reformatting vllm/core/placeholder_block_space_manager.py
Reformatting tests/samplers/test_rejection_sampler.py
Reformatting vllm/model_executor/layers/typical_acceptance_sampler.py
Reformatting vllm/entrypoints/openai/protocol.py
Reformatting vllm/attention/backends/placeholder_attn.py
Reformatting tests/distributed/test_comm_ops.py
Reformatting vllm/distributed/kv_transfer/__init__.py
Reformatting tests/compile/test_basic_correctness.py
Reformatting vllm/benchmarks/datasets.py
Reformatting vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py
Reformatting tests/standalone_tests/lazy_imports.py
Reformatting tests/detokenizer/__init__.py
Reformatting tests/models/multimodal/processing/test_idefics3.py
Reformatting vllm/model_executor/guided_decoding/reasoner/__init__.py
Reformatting tests/core/test_chunked_prefill_scheduler.py
Reformatting tests/distributed/test_distributed_oot.py
Reformatting vllm/executor/executor_base.py
Reformatting vllm/v1/engine/processor.py
Reformatting tests/kernels/test_blocksparse_attention.py
Reformatting vllm/model_executor/models/pixtral.py
Reformatting tests/quantization/test_fp8.py
Reformatting vllm/model_executor/layers/quantization/utils/marlin_utils_test.py
Reformatting vllm/worker/cpu_worker.py
Reformatting vllm/attention/backends/xformers.py
Reformatting tools/profiler/print_layerwise_table.py
Reformatting tests/models/multimodal/processing/test_llama4.py
Reformatting vllm/usage/__init__.py
Reformatting vllm/model_executor/layers/quantization/utils/__init__.py
Reformatting vllm/prompt_adapter/worker_manager.py
2025-04-15T09:14:18.4259256Z
ruff.....................................................................[41mFailed[m
[2m- hook id: ruff[m
[2m- exit code: 1[m
[2m- files were modified by this hook[m
2025-04-15T09:14:18.7003272Z
##[error]vllm/model_executor/models/aimv2.py:9:81: E501 Line too long (82 > 80)
##[error]vllm/model_executor/models/aimv2.py:18:81: E501 Line too long (89 > 80)
##[error]vllm/model_executor/models/aimv2.py:56:81: E501 Line too long (81 > 80)
##[error]vllm/model_executor/models/aimv2.py:96:81: E501 Line too long (126 > 80)
##[error]vllm/model_executor/models/aimv2.py:105:81: E501 Line too long (112 > 80)
##[error]vllm/model_executor/models/aimv2.py:106:81: E501 Line too long (98 > 80)
##[error]vllm/model_executor/models/aimv2.py:108:16: E741 Ambiguous variable name: `l`
##[error]vllm/model_executor/models/aimv2.py:108:81: E501 Line too long (82 > 80)
##[error]vllm/model_executor/models/aimv2.py:110:81: E501 Line too long (90 > 80)
##[error]vllm/model_executor/models/aimv2.py:133:81: E501 Line too long (83 > 80)
##[error]vllm/model_executor/models/aimv2.py:139:81: E501 Line too long (106 > 80)
##[error]vllm/model_executor/models/aimv2.py:328:81: E501 Line too long (93 > 80)
##[error]vllm/model_executor/models/ovis2.py:32:81: E501 Line too long (116 > 80)
##[error]vllm/model_executor/models/ovis2.py:373:81: E501 Line too long (109 > 80)
##[error]vllm/model_executor/models/ovis2.py:379:81: E501 Line too long (126 > 80)
##[error]vllm/transformers_utils/config.py:39:81: E501 Line too long (84 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:11:81: E501 Line too long (87 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:13:81: E501 Line too long (86 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:27:81: E501 Line too long (87 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:29:81: E501 Line too long (82 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:102:81: E501 Line too long (124 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:146:81: E501 Line too long (114 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:155:81: E501 Line too long (83 > 80)
##[error]vllm/transformers_utils/configs/ovis2.py:156:81: E501 Line too long (140 > 80)
2025-04-15T09:14:18.7043398Z
codespell................................................................[42mPassed[m
isort....................................................................[41mFailed[m
[2m- hook id: isort[m
[2m- files were modified by this hook[m
2025-04-15T09:14:23.2342632Z
Fixing /home/runner/work/vllm/vllm/vllm/model_executor/models/aimv2.py
Fixing /home/runner/work/vllm/vllm/vllm/model_executor/models/ovis2.py
Fixing /home/runner/work/vllm/vllm/vllm/transformers_utils/config.py
Fixing /home/runner/work/vllm/vllm/vllm/transformers_utils/configs/ovis2.py
Fixing /home/runner/work/vllm/vllm/vllm/transformers_utils/processors/ovis2.py
2025-04-15T09:14:23.2348540Z
clang-format.............................................................[42mPassed[m
PyMarkdown...............................................................[42mPassed[m
Lint GitHub Actions workflow files.......................................[42mPassed[m
pip-compile..............................................................[42mPassed[m
Run mypy for Python 3.9..................................................[41mFailed[m
[2m- hook id: mypy-3.9[m
[2m- exit code: 1[m
2025-04-15T09:14:50.4829165Z
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
2025-04-15T09:14:50.4913983Z
Run mypy for Python 3.10.................................................[41mFailed[m
[2m- hook id: mypy-3.10[m
[2m- exit code: 1[m
2025-04-15T09:15:08.5114773Z
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
2025-04-15T09:15:08.5175543Z
Run mypy for Python 3.11.................................................[41mFailed[m
[2m- hook id: mypy-3.11[m
[2m- exit code: 1[m
2025-04-15T09:15:26.6192565Z
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
2025-04-15T09:15:26.6231254Z
Run mypy for Python 3.12.................................................[41mFailed[m
[2m- hook id: mypy-3.12[m
[2m- exit code: 1[m
2025-04-15T09:15:44.6299270Z
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
Running mypy on
##[error]vllm/transformers_utils/processors/ovis2.py:38: error: Unexpected keyword argument "total" for "__init_subclass__" of "object"  [call-arg]
/home/runner/.cache/pre-commit/repoq9fkshj6/py_env-python3.12/lib/python3.12/site-packages/mypy/typeshed/stdlib/builtins.pyi:125: note: "__init_subclass__" of "object" defined here
##[error]vllm/transformers_utils/processors/ovis2.py:251: error: Need type annotation for "padded_placeholder_tokens" (hint: "padded_placeholder_tokens: list[<type>] = ...")  [var-annotated]
##[error]vllm/transformers_utils/processors/ovis2.py:332: error: Too many arguments for "_covering_area"  [call-arg]
##[error]vllm/transformers_utils/configs/ovis2.py:98: error: Need type annotation for "backbone_kwargs" (hint: "backbone_kwargs: dict[<type>, <type>] = ...")  [var-annotated]
Found 4 errors in 2 files (checked 170 source files)
2025-04-15T09:15:44.6367311Z
Lint shell scripts.......................................................[42mPassed[m
Lint PNG exports from excalidraw.........................................[42mPassed[m
Check SPDX headers.......................................................[42mPassed[m
Check for spaces in all filenames........................................[42mPassed[m
Update Dockerfile dependency graph.......................................[42mPassed[m
Suggestion...............................................................[42mPassed[m
[2m- hook id: suggestion[m
[2m- duration: 0s[m
2025-04-15T09:15:44.7806307Z
To bypass pre-commit hooks, add --no-verify to git commit.
2025-04-15T09:15:44.7806807Z
pre-commit hook(s) made changes.
If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
To run `pre-commit` as part of git workflow, use `pre-commit install`.
All changes made by hooks:
[1mdiff --git a/examples/offline_inference/vision_language.py b/examples/offline_inference/vision_language.py[m
[1mindex d4bb23a..5a30602 100644[m
[1m--- a/examples/offline_inference/vision_language.py[m
[1m+++ b/examples/offline_inference/vision_language.py[m
[36m@@ -724,6 +724,7 @@[m [mdef run_nvlm_d(questions: list[str], modality: str) -> ModelRequestData:[m
prompts=prompts,[m
)[m
[m
[32m+[m
# Ovis2[m
def run_ovis2(questions: list[str], modality: str) -> ModelRequestData:[m
assert modality == "image"[m
[36m@@ -743,12 +744,10 @@[m [mdef run_ovis2(questions: list[str], modality: str) -> ModelRequestData:[m
)[m
[m
placeholder = "<image>\n"[m
[31m-    prompts = [[m
[31m-        ("<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n"[m
[31m-         f"<|im_start|>user\n{placeholder}"[m
[31m-         f"{question}<|im_end|>\n"[m
[31m-         "<|im_start|>assistant\n") for question in questions[m
[31m-    ][m
[32m+[m[32m    prompts = [("<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n"[m
[32m+[m[32m                f"<|im_start|>user\n{placeholder}"[m
[32m+[m[32m                f"{question}<|im_end|>\n"[m
[32m+[m[32m                "<|im_start|>assistant\n") for question in questions][m
[m
return ModelRequestData([m
engine_args=engine_args,[m
[1mdiff --git a/examples/offline_inference/vision_language_multi_image.py b/examples/offline_inference/vision_language_multi_image.py[m
[1mindex 76f25bc..20e31cc 100644[m
[1m--- a/examples/offline_inference/vision_language_multi_image.py[m
[1m+++ b/examples/offline_inference/vision_language_multi_image.py[m
[36m@@ -453,11 +453,12 @@[m [mdef load_ovis2(question: str, image_urls: list[str]) -> ModelRequestData:[m
hf_overrides={"architectures": ["Ovis2ForConditionalGeneration"]},[m
)[m
[m
[31m-    placeholder = '\n'.join([f'Image {i+1}: <image>' for i in range(len(image_urls))]) + '\n'[m
[32m+[m[32m    placeholder = '\n'.join([m
[32m+[m[32m        [f'Image {i+1}: <image>' for i in range(len(image_urls))]) + '\n'[m
prompt = ("<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n"[m
[31m-             f"<|im_start|>user\n{placeholder}"[m
[31m-             f"{question}<|im_end|>\n"[m
[31m-             "<|im_start|>assistant\n")[m
[32m+[m[32m              f"<|im_start|>user\n{placeholder}"[m
[32m+[m[32m              f"{question}<|im_end|>\n"[m
[32m+[m[32m              "<|im_start|>assistant\n")[m
[m
return ModelRequestData([m
engine_args=engine_args,[m
[1mdiff --git a/vllm/model_executor/models/aimv2.py b/vllm/model_executor/models/aimv2.py[m
[1mindex 1da8511..07ed259 100644[m
[1m--- a/vllm/model_executor/models/aimv2.py[m
[1m+++ b/vllm/model_executor/models/aimv2.py[m
[36m@@ -5,51 +5,55 @@[m
from typing import Optional, Tuple, Union[m
[m
import torch[m
[31m-from vllm.attention import Attention, AttentionType[m
[31m-from vllm.config import VllmConfig, CacheConfig[m
[31m-from vllm.model_executor.layers.linear import QKVParallelLinear, RowParallelLinear, ColumnParallelLinear[m
[31m-from vllm.model_executor.layers.quantization.base_config import QuantizationConfig[m
[31m-[m
[31m-from torch import nn[m
[32m+[m[32mfrom torch import nn, softmax[m
from torch.nn import functional as F[m
[32m+[m[32mfrom torch.nn.functional import gumbel_softmax, pad[m
from transformers.modeling_outputs import BaseModelOutputWithNoAttention[m
[31m-from transformers.modeling_utils import PreTrainedModel[m
[m
[31m-from torch import softmax[m
[31m-from torch.nn.functional import gumbel_softmax, pad[m
[32m+[m[32mfrom vllm.model_executor.layers.linear import ColumnParallelLinear[m
[32m+[m[32mfrom vllm.model_executor.layers.quantization.base_config import ([m
[32m+[m[32m    QuantizationConfig)[m
[32m+[m[32mfrom vllm.transformers_utils.configs.ovis2 import (AIMv2Config,[m
[32m+[m[32m                                                   Aimv2VisualTokenizerConfig)[m
from vllm.transformers_utils.processor import cached_get_image_processor[m
[31m-from vllm.transformers_utils.configs.ovis2 import AIMv2Config, Aimv2VisualTokenizerConfig[m
[m
[31m-IMAGE_INDICATOR_IDS = [-301, -302, -303, -304, -305] # kept for vocab prefixed tokens[m
[32m+[m[32mIMAGE_INDICATOR_IDS = [-301, -302, -303, -304,[m
[32m+[m[32m                       -305]  # kept for vocab prefixed tokens[m
[m
[m
class Aimv2VisualTokenizer(torch.nn.Module):[m
[m
[31m-    def __init__(self, config: Aimv2VisualTokenizerConfig, quant_config: Optional[QuantizationConfig] = None, prefix: str = "", **kwargs):[m
[32m+[m[32m    def __init__(self,[m
[32m+[m[32m                 config: Aimv2VisualTokenizerConfig,[m
[32m+[m[32m                 quant_config: Optional[QuantizationConfig] = None,[m
[32m+[m[32m                 prefix: str = "",[m
[32m+[m[32m                 **kwargs):[m
super().__init__()[m
[31m-        self.image_processor = cached_get_image_processor(kwargs['image_processor_name_or_path'], trust_remote_code=True)[m
[32m+[m[32m        self.image_processor = cached_get_image_processor([m
[32m+[m[32m            kwargs['image_processor_name_or_path'], trust_remote_code=True)[m
self.config = config[m
self.image_processor.do_center_crop = False[m
self.backbone = AIMv2Model([m
[31m-            config = config.backbone_config, # noqa[m
[32m+[m[32m            config=config.backbone_config,  # noqa[m
quant_config=quant_config,[m
[31m-            prefix=f"{prefix}.visual_tokenizer"[m
[31m-        )[m
[31m-        head_dim = config.vocab_size - len(IMAGE_INDICATOR_IDS)  # reserved tokens for IMAGE_INDICATORS[m
[32m+[m[32m            prefix=f"{prefix}.visual_tokenizer")[m
[32m+[m[32m        head_dim = config.vocab_size - len([m
[32m+[m[32m            IMAGE_INDICATOR_IDS)  # reserved tokens for IMAGE_INDICATORS[m
self.head = torch.nn.Sequential([m
ColumnParallelLinear([m
[31m-                config.backbone_config.hidden_size * config.hidden_stride * config.hidden_stride, head_dim,[m
[32m+[m[32m                config.backbone_config.hidden_size * config.hidden_stride *[m
[32m+[m[32m                config.hidden_stride,[m
[32m+[m[32m                head_dim,[m
bias=False,[m
gather_output=True,[m
[31m-            ),[m
[31m-            torch.nn.LayerNorm(head_dim)[m
[31m-        )[m
[32m+[m[32m            ), torch.nn.LayerNorm(head_dim))[m
[m
[31m-        assert all((self.image_processor.do_resize,[m
[31m-                    not getattr(self.image_processor, 'do_center_crop', False),[m
[31m-                    self.image_processor.do_rescale,[m
[31m-                    self.image_processor.do_normalize[m
[31m-                    )), f"image_processor `{self.image_processor}` is not supported currently"[m
[32m+[m[32m        assert all([m
[32m+[m[32m            (self.image_processor.do_resize,[m
[32m+[m[32m             not getattr(self.image_processor, 'do_center_crop', False),[m
[32m+[m[32m             self.image_processor.do_rescale,[m
[32m+[m[32m             self.image_processor.do_normalize)[m
[32m+[m[32m        ), f"image_processor `{self.image_processor}` is not supported currently"[m
[m
@property[m
def dtype(self):[m
[36m@@ -71,11 +75,13 @@[m [mclass Aimv2VisualTokenizer(torch.nn.Module):[m
def get_image_size(self):[m
raise NotImplementedError[m
[m
[31m-[m
def tokenize(self, logits):[m
[32m+[m
def st_argmax(y_soft, dim):  # straight-through softmax[m
index = y_soft.max(dim, keepdim=True)[1][m
[31m-            y_hard = torch.zeros_like(y_soft, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)[m
[32m+[m[32m            y_hard = torch.zeros_like([m
[32m+[m[32m                y_soft, memory_format=torch.legacy_contiguous_format).scatter_([m
[32m+[m[32m                    dim, index, 1.0)[m
ret = y_hard - y_soft.detach() + y_soft[m
return ret[m
[m
[36m@@ -87,7 +93,8 @@[m [mclass Aimv2VisualTokenizer(torch.nn.Module):[m
tokens = st_argmax(logits, dim=-1)[m
else:[m
raise ValueError([m
[31m-                f'Invalid `max_type`, expected softmax or gumbel_argmax or st_argmax, but got {self.config.tokenize_function}')[m
[32m+[m[32m                f'Invalid `max_type`, expected softmax or gumbel_argmax or st_argmax, but got {self.config.tokenize_function}'[m
[32m+[m[32m            )[m
return tokens[m
[m
def encode(self, pixel_values):[m
[36m@@ -99,30 +106,41 @@[m [mclass Aimv2VisualTokenizer(torch.nn.Module):[m
# e.g., for hidden_stride=2, this leads to a token length reduction: 1024 -> 256 for aimv2[m
if self.config.hidden_stride > 1:[m
n, l, d = features.shape  # this `d` maybe different from the above `d[m
[31m-            sqrt_l = int(l ** 0.5)[m
[31m-            assert sqrt_l ** 2 == l, "The token sequence length should be a perfect square."[m
[32m+[m[32m            sqrt_l = int(l**0.5)[m
[32m+[m[32m            assert sqrt_l**2 == l, "The token sequence length should be a perfect square."[m
features = features.reshape(n, sqrt_l, sqrt_l, d)[m
[31m-            pl = (self.config.hidden_stride - (sqrt_l % self.config.hidden_stride)) % self.config.hidden_stride[m
[32m+[m[32m            pl = (self.config.hidden_stride -[m
[32m+[m[32m                  (sqrt_l %[m
[32m+[m[32m                   self.config.hidden_stride)) % self.config.hidden_stride[m
features = pad(features, (0, 0, 0, pl, 0, pl), "constant", 0)[m
sqrt_l += pl[m
[31m-            features = features.reshape(n, sqrt_l // self.config.hidden_stride, self.config.hidden_stride,[m
[31m-                                        sqrt_l // self.config.hidden_stride, self.config.hidden_stride, d)[m
[31m-            features = features.permute(0, 1, 3, 2, 4, 5)  # [n, sqrt_l/hs, sqrt_l/hs, hs, hs, d][m
[31m-            features = features.flatten(3)  # [n, sqrt_l/hs, sqrt_l/hs, hs*hs*d][m
[32m+[m[32m            features = features.reshape(n, sqrt_l // self.config.hidden_stride,[m
[32m+[m[32m                                        self.config.hidden_stride,[m
[32m+[m[32m                                        sqrt_l // self.config.hidden_stride,[m
[32m+[m[32m                                        self.config.hidden_stride, d)[m
[32m+[m[32m            features = features.permute([m
[32m+[m[32m                0, 1, 3, 2, 4, 5)  # [n, sqrt_l/hs, sqrt_l/hs, hs, hs, d][m
[32m+[m[32m            features = features.flatten([m
[32m+[m[32m                3)  # [n, sqrt_l/hs, sqrt_l/hs, hs*hs*d][m
features = features.reshape([m
[31m-                n, -1, self.config.hidden_stride * self.config.hidden_stride * d)[m
[32m+[m[32m                n, -1,[m
[32m+[m[32m                self.config.hidden_stride * self.config.hidden_stride * d)[m
[m
return features[m
[m
[31m-    def forward(self, pixel_values) -> torch.Tensor:  # [BatchSize, ImageShape] -> [BatchSize, #Token, VocabSize][m
[32m+[m[32m    def forward([m
[32m+[m[32m        self, pixel_values[m
[32m+[m[32m    ) -> torch.Tensor:  # [BatchSize, ImageShape] -> [BatchSize, #Token, VocabSize][m
features = self.encode(pixel_values)[m
[31m-        logits, _ = self.head[0](features) # we spllit the sequncial here for not throwing an error[m
[32m+[m[32m        logits, _ = self.head[0]([m
[32m+[m[32m            features)  # we spllit the sequncial here for not throwing an error[m
logits = self.head[1](logits)[m
tokens = self.tokenize(logits)[m
# tokens' shape is [BatchSize, #Token, VocabSize-5], so padding with [BatchSize, #Token, 5], after[m
# which, tokens' shape should become [BatchSize, #Token, VocabSize][m
batch_size, token_len, _ = tokens.shape[m
[31m-        padding_tensor = torch.zeros(size=(batch_size, token_len, len(IMAGE_INDICATOR_IDS)),[m
[32m+[m[32m        padding_tensor = torch.zeros(size=(batch_size, token_len,[m
[32m+[m[32m                                           len(IMAGE_INDICATOR_IDS)),[m
dtype=tokens.dtype,[m
device=tokens.device,[m
layout=tokens.layout,[m
[36m@@ -132,6 +150,7 @@[m [mclass Aimv2VisualTokenizer(torch.nn.Module):[m
[m
[m
class RMSNorm(nn.Module):[m
[32m+[m
def __init__(self, dim: int, eps: float = 1e-6):[m
super().__init__()[m
self.weight = nn.Parameter(torch.ones(dim))[m
[36m@@ -149,38 +168,43 @@[m [mclass RMSNorm(nn.Module):[m
[m
[m
class AIMv2SwiGLUFFN(nn.Module):[m
[31m-    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig, prefix: str):[m
[32m+[m
[32m+[m[32m    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig,[m
[32m+[m[32m                 prefix: str):[m
super().__init__()[m
hidden_features = config.intermediate_size[m
in_features = config.hidden_size[m
bias = config.use_bias[m
[m
[31m-        self.fc1 = nn.Linear(in_features, hidden_features, bias=bias)#ColumnParallelLinear(in_features,[m
[31m-                   #              hidden_features,[m
[31m-                   #              bias=bias,[m
[31m-                   #              quant_config=quant_config,[m
[31m-                   #              prefix=f"{prefix}.fc1")[m
[31m-        self.fc2 = nn.Linear(hidden_features, in_features, bias=bias)#ColumnParallelLinear(hidden_features,[m
[31m-                   #              in_features,[m
[31m-                   #              bias=bias,[m
[31m-                   #              quant_config=quant_config,[m
[31m-                   #              prefix=f"{prefix}.fc2")[m
[31m-        self.fc3 = nn.Linear(in_features, hidden_features, bias=bias)#RowParallelLinear(in_features,[m
[31m-                   #           hidden_features,[m
[31m-                   #           bias=bias,[m
[31m-                   #           quant_config=quant_config,[m
[31m-                   #           prefix=f"{prefix}.fc3")[m
[32m+[m[32m        self.fc1 = nn.Linear(in_features, hidden_features,[m
[32m+[m[32m                             bias=bias)  #ColumnParallelLinear(in_features,[m
[32m+[m[32m        #              hidden_features,[m
[32m+[m[32m        #              bias=bias,[m
[32m+[m[32m        #              quant_config=quant_config,[m
[32m+[m[32m        #              prefix=f"{prefix}.fc1")[m
[32m+[m[32m        self.fc2 = nn.Linear(hidden_features, in_features,[m
[32m+[m[32m                             bias=bias)  #ColumnParallelLinear(hidden_features,[m
[32m+[m[32m        #              in_features,[m
[32m+[m[32m        #              bias=bias,[m
[32m+[m[32m        #              quant_config=quant_config,[m
[32m+[m[32m        #              prefix=f"{prefix}.fc2")[m
[32m+[m[32m        self.fc3 = nn.Linear(in_features, hidden_features,[m
[32m+[m[32m                             bias=bias)  #RowParallelLinear(in_features,[m
[32m+[m[32m        #           hidden_features,[m
[32m+[m[32m        #           bias=bias,[m
[32m+[m[32m        #           quant_config=quant_config,[m
[32m+[m[32m        #           prefix=f"{prefix}.fc3")[m
[m
def forward(self, x: torch.Tensor) -> torch.Tensor:[m
[31m-        x_parallel= self.fc1(x)#, _ = self.fc1(x)[m
[31m-        gate= self.fc3(x)#, _ = self.fc3(x)[m
[32m+[m[32m        x_parallel = self.fc1(x)  #, _ = self.fc1(x)[m
[32m+[m[32m        gate = self.fc3(x)  #, _ = self.fc3(x)[m
x_parallel = F.silu(x_parallel) * gate[m
[31m-        out =self.fc2(x_parallel)#, _ = self.fc2(x_parallel)[m
[32m+[m[32m        out = self.fc2(x_parallel)  #, _ = self.fc2(x_parallel)[m
return out[m
[m
[m
[31m-[m
class AIMv2PatchEmbed(nn.Module):[m
[32m+[m
def __init__(self, config: AIMv2Config):[m
super().__init__()[m
self.proj = nn.Conv2d([m
[36m@@ -198,12 +222,14 @@[m [mclass AIMv2PatchEmbed(nn.Module):[m
[m
[m
class AIMv2ViTPreprocessor(nn.Module):[m
[32m+[m
def __init__(self, config: AIMv2Config):[m
super().__init__()[m
[31m-        num_patches = (config.image_size // config.patch_size) ** 2[m
[32m+[m[32m        num_patches = (config.image_size // config.patch_size)**2[m
[m
self.patchifier = AIMv2PatchEmbed(config)[m
[31m-        self.pos_embed = nn.Parameter(torch.zeros((1, num_patches, config.hidden_size)))[m
[32m+[m[32m        self.pos_embed = nn.Parameter([m
[32m+[m[32m            torch.zeros((1, num_patches, config.hidden_size)))[m
[m
def forward(self, x: torch.Tensor) -> torch.Tensor:[m
tokens = self.patchifier(x)[m
[36m@@ -214,68 +240,84 @@[m [mclass AIMv2ViTPreprocessor(nn.Module):[m
[m
[m
class AIMv2Attention(nn.Module):[m
[31m-    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig, prefix: str):[m
[32m+[m
[32m+[m[32m    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig,[m
[32m+[m[32m                 prefix: str):[m
super().__init__()[m
dim = config.hidden_size[m
[m
self.num_heads = config.num_attention_heads[m
[31m-        self.qkv = nn.Linear(dim, dim * 3, bias=config.qkv_bias)#QKVParallelLinear([m
[31m-                   # hidden_size=dim,[m
[31m-                   # head_size=dim // config.num_attention_heads,[m
[31m-                   # total_num_heads=config.num_attention_heads,[m
[31m-                   # bias=config.qkv_bias,[m
[31m-                   # quant_config=quant_config,[m
[31m-                   # prefix=f"{prefix}.qkv")[m
[32m+[m[32m        self.qkv = nn.Linear(dim, dim * 3,[m
[32m+[m[32m                             bias=config.qkv_bias)  #QKVParallelLinear([m
[32m+[m[32m        # hidden_size=dim,[m
[32m+[m[32m        # head_size=dim // config.num_attention_heads,[m
[32m+[m[32m        # total_num_heads=config.num_attention_heads,[m
[32m+[m[32m        # bias=config.qkv_bias,[m
[32m+[m[32m        # quant_config=quant_config,[m
[32m+[m[32m        # prefix=f"{prefix}.qkv")[m
self.attn_drop = nn.Dropout(config.attention_dropout)[m
[31m-        self.proj = nn.Linear(dim, dim, bias=config.use_bias)#RowParallelLinear(input_size=dim,[m
[31m-                    #                  output_size=dim,[m
[31m-                    #                  bias = config.use_bias,[m
[31m-                    #                  quant_config=quant_config,[m
[31m-                    #                  prefix=f"{prefix}.proj")[m
[32m+[m[32m        self.proj = nn.Linear([m
[32m+[m[32m            dim, dim, bias=config.use_bias)  #RowParallelLinear(input_size=dim,[m
[32m+[m[32m        #                  output_size=dim,[m
[32m+[m[32m        #                  bias = config.use_bias,[m
[32m+[m[32m        #                  quant_config=quant_config,[m
[32m+[m[32m        #                  prefix=f"{prefix}.proj")[m
[m
self.proj_drop = nn.Dropout(config.projection_dropout)[m
[m
[31m-    def forward( # todo might implement multiple attn implementations[m
[31m-        self, x: torch.Tensor, mask: Optional[torch.Tensor] = None[m
[31m-    ) -> torch.Tensor:[m
[32m+[m[32m    def forward(  # todo might implement multiple attn implementations[m
[32m+[m[32m            self,[m
[32m+[m[32m            x: torch.Tensor,[m
[32m+[m[32m            mask: Optional[torch.Tensor] = None) -> torch.Tensor:[m
B, N, C = x.shape[m
[31m-        qkv = self.qkv(x) #, _ = self.qkv(x)[m
[32m+[m[32m        qkv = self.qkv(x)  #, _ = self.qkv(x)[m
[m
[31m-        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[m
[32m+[m[32m        qkv = qkv.reshape(B, N, 3, self.num_heads,[m
[32m+[m[32m                          C // self.num_heads).permute(2, 0, 3, 1, 4)[m
[m
q, k, v = qkv.unbind(0)[m
[m
x = F.scaled_dot_product_attention(q, k, v, attn_mask=mask)[m
x = x.transpose(1, 2).contiguous().reshape(B, N, C)[m
[31m-        x= self.proj(x)#, _ = self.proj(x)[m
[32m+[m[32m        x = self.proj(x)  #, _ = self.proj(x)[m
x = self.proj_drop(x)[m
return x[m
[m
[m
class AIMv2Block(nn.Module):[m
[31m-    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig, prefix: str):[m
[32m+[m
[32m+[m[32m    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig,[m
[32m+[m[32m                 prefix: str):[m
super().__init__()[m
[31m-        self.attn = AIMv2Attention(config, quant_config=quant_config, prefix=f"{prefix}.attn")[m
[32m+[m[32m        self.attn = AIMv2Attention(config,[m
[32m+[m[32m                                   quant_config=quant_config,[m
[32m+[m[32m                                   prefix=f"{prefix}.attn")[m
self.norm_1 = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)[m
[31m-        self.mlp = AIMv2SwiGLUFFN(config, quant_config=quant_config, prefix=f"{prefix}.mlp")[m
[32m+[m[32m        self.mlp = AIMv2SwiGLUFFN(config,[m
[32m+[m[32m                                  quant_config=quant_config,[m
[32m+[m[32m                                  prefix=f"{prefix}.mlp")[m
self.norm_2 = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)[m
[m
[31m-    def forward([m
[31m-        self, x: torch.Tensor, mask: Optional[torch.Tensor] = None[m
[31m-    ) -> torch.Tensor:[m
[32m+[m[32m    def forward(self,[m
[32m+[m[32m                x: torch.Tensor,[m
[32m+[m[32m                mask: Optional[torch.Tensor] = None) -> torch.Tensor:[m
x = x + self.attn(self.norm_1(x), mask)[m
x = x + self.mlp(self.norm_2(x))[m
return x[m
[m
[m
class AIMv2Transformer(nn.Module):[m
[31m-    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig, prefix: str):[m
[32m+[m
[32m+[m[32m    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig,[m
[32m+[m[32m                 prefix: str):[m
super().__init__()[m
[m
[31m-        self.blocks = nn.ModuleList([m
[31m-            [AIMv2Block(config, quant_config, prefix=f"{prefix}.blocks.{i}") for i in range(config.num_hidden_layers)][m
[31m-        )[m
[31m-        self.post_trunk_norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)[m
[32m+[m[32m        self.blocks = nn.ModuleList([[m
[32m+[m[32m            AIMv2Block(config, quant_config, prefix=f"{prefix}.blocks.{i}")[m
[32m+[m[32m            for i in range(config.num_hidden_layers)[m
[32m+[m[32m        ])[m
[32m+[m[32m        self.post_trunk_norm = RMSNorm(config.hidden_size,[m
[32m+[m[32m                                       eps=config.rms_norm_eps)[m
[m
def forward([m
self,[m
[36m@@ -283,7 +325,7 @@[m [mclass AIMv2Transformer(nn.Module):[m
mask: Optional[torch.Tensor] = None,[m
) -> Tuple[torch.Tensor, Optional[Tuple[torch.Tensor, ...]]]:[m
#outputs = [][m
[31m-        for block in self.blocks: # they take the -1 as the ref embeddings, like a clip skip[m
[32m+[m[32m        for block in self.blocks:  # they take the -1 as the ref embeddings, like a clip skip[m
tokens = block(tokens, mask)[m
#outputs.append(tokens)[m
#tokens = self.post_trunk_norm(tokens) NO NORM IN THE OG IMPLEMENTATION[m
[36m@@ -291,10 +333,16 @@[m [mclass AIMv2Transformer(nn.Module):[m
[m
[m
class AIMv2Model(torch.nn.Module):[m
[31m-    def __init__(self, config: AIMv2Config, quant_config: QuantizationConfig, prefix: str = ""):[m
[32m+[m
[32m+[m[32m    def __init__(self,[m
[32m+[m[32m                 config: AIMv2Config,[m
[32m+[m[32m                 quant_config: QuantizationConfig,[m
[32m+[m[32m                 prefix: str = ""):[m
super().__init__()[m
self.preprocessor = AIMv2ViTPreprocessor(config)[m
[31m-        self.trunk = AIMv2Transformer(config, quant_config=quant_config, prefix=f"{prefix}.trunk")[m
[32m+[m[32m        self.trunk = AIMv2Transformer(config,[m
[32m+[m[32m                                      quant_config=quant_config,[m
[32m+[m[32m                                      prefix=f"{prefix}.trunk")[m
[m
@property[m
def dtype(self):[m
[36m@@ -309,14 +357,12 @@[m [mclass AIMv2Model(torch.nn.Module):[m
pixel_values: torch.Tensor,[m
mask: Optional[torch.Tensor] = None,[m
) -> Union[[m
[31m-        Tuple[torch.Tensor],[m
[31m-        Tuple[torch.Tensor, Tuple[torch.Tensor, ...]],[m
[31m-        BaseModelOutputWithNoAttention,[m
[32m+[m[32m            Tuple[torch.Tensor],[m
[32m+[m[32m            Tuple[torch.Tensor, Tuple[torch.Tensor, ...]],[m
[32m+[m[32m            BaseModelOutputWithNoAttention,[m
]:[m
[m
x = self.preprocessor(pixel_values)[m
[31m-        x = self.trunk([m
[31m-            x, mask[m
[31m-        )[m
[32m+[m[32m        x = self.trunk(x, mask)[m
[m
return x[m
[1mdiff --git a/vllm/model_executor/models/ovis2.py b/vllm/model_executor/models/ovis2.py[m
[1mindex fe85216..367dac2 100644[m
[1m--- a/vllm/model_executor/models/ovis2.py[m
[1m+++ b/vllm/model_executor/models/ovis2.py[m
[36m@@ -17,47 +17,34 @@[m
# limitations under the License.[m
""" PyTorch Ovis2 model."""[m
from typing import (Iterable, List, Literal, Mapping, Optional, Set, Tuple,[m
[31m-                    TypedDict, Dict, Union)[m
[31m-from abc import ABC, abstractmethod[m
[32m+[m[32m                    TypedDict, Union)[m
[m
import torch[m
import torch.nn as nn[m
[31m-from PIL import Image[m
from torch import Tensor[m
from torch.nn import init[m
[31m-[m
[31m-from transformers import PretrainedConfig, AutoConfig, AutoModel[m
[31m-from transformers import BatchFeature, AutoTokenizer[m
from transformers import BatchFeature[m
[31m-from transformers.image_utils import ImageInput[m
[31m-from transformers.processing_utils import ProcessingKwargs, ProcessorMixin, Unpack[m
[31m-from transformers.tokenization_utils_base import TextInput, PreTokenizedInput[m
[m
[31m-from vllm.attention import AttentionMetadata[m
from vllm.config import VllmConfig[m
[31m-from vllm.model_executor.layers.linear import ColumnParallelLinear[m
from vllm.model_executor.layers.sampler import SamplerOutput[m
[31m-from vllm.model_executor.layers.vocab_parallel_embedding import VocabParallelEmbedding[m
[31m-from vllm.model_executor.models.qwen2 import Qwen2ForCausalLM[m
from vllm.model_executor.models.aimv2 import Aimv2VisualTokenizer[m
[31m-from vllm.model_executor.models.utils import maybe_prefix, flatten_bn, AutoWeightsLoader, init_vllm_registered_model[m
[32m+[m[32mfrom vllm.model_executor.models.utils import (AutoWeightsLoader, flatten_bn,[m
[32m+[m[32m                                              init_vllm_registered_model,[m
[32m+[m[32m                                              maybe_prefix)[m
from vllm.model_executor.sampling_metadata import SamplingMetadata[m
from vllm.multimodal import MULTIMODAL_REGISTRY[m
[31m-from vllm.multimodal.inputs import (MultiModalFieldConfig, MultiModalKwargs, NestedTensors,[m
[31m-                                    )[m
[31m-from vllm.multimodal.parse import (ImageSize,[m
[31m-                                   MultiModalDataItems)[m
[32m+[m[32mfrom vllm.multimodal.inputs import MultiModalFieldConfig, MultiModalKwargs[m
[32m+[m[32mfrom vllm.multimodal.parse import ImageSize, MultiModalDataItems[m
from vllm.multimodal.processing import (BaseMultiModalProcessor,[m
BaseProcessingInfo, PromptReplacement)[m
from vllm.multimodal.profiling import BaseDummyInputsBuilder, ProcessorInputs[m
from vllm.sequence import IntermediateTensors[m
from vllm.transformers_utils.configs.ovis2 import OvisConfig[m
[31m-from vllm.transformers_utils.tokenizer import cached_tokenizer_from_config[m
from vllm.transformers_utils.processors.ovis2 import OvisProcessor[m
[31m-from collections import defaultdict[m
[32m+[m[32mfrom vllm.transformers_utils.tokenizer import cached_tokenizer_from_config[m
[m
[31m-from .utils import merge_multimodal_embeddings[m
from .interfaces import MultiModalEmbeddings, SupportsMultiModal, SupportsPP[m
[32m+[m[32mfrom .utils import merge_multimodal_embeddings[m
[m
# Cannot find the following number from hf config.[m
IGNORE_ID = -100[m
[36m@@ -86,11 +73,14 @@[m [mclass Ovis2ImagePatchInputs(TypedDict):[m
[m
[m
class VisualEmbedding(torch.nn.Embedding):[m
[32m+[m
def __init__(self, *args, **kwargs):[m
super().__init__(*args, **kwargs)[m
[m
def forward(self, visual_tokens: Tensor) -> Tensor:[m
[31m-        if visual_tokens.dtype in [torch.int8, torch.int16, torch.int32, torch.int64, torch.long]:[m
[32m+[m[32m        if visual_tokens.dtype in [[m
[32m+[m[32m                torch.int8, torch.int16, torch.int32, torch.int64, torch.long[m
[32m+[m[32m        ]:[m
return super().forward(visual_tokens)[m
return torch.matmul(visual_tokens, self.weight)[m
[m
[36m@@ -112,22 +102,23 @@[m [mclass Ovis2ProcessingInfo(BaseProcessingInfo):[m
def get_hf_config(self):[m
return self.ctx.get_hf_config(OvisConfig)[m
[m
[31m-    def get_hf_processor(self,[m
[31m-                         **kwargs):[m
[32m+[m[32m    def get_hf_processor(self, **kwargs):[m
return self.ctx.get_hf_processor(OvisProcessor)[m
[m
def get_image_processor(self) -> OvisProcessor:[m
return self.get_hf_processor().image_processor  # type: ignore[m
[m
def get_supported_mm_limits(self) -> Mapping[str, Optional[int]]:[m
[31m-        return {# 32k is model token limit at the moment[m
[31m-            "image": self.get_hf_config().multimodal_max_length // ((9 + 1) *[m
[31m-                                                                    NUMBER_OF_TOKEN_TO_RESERVE_FOR_SEGMENT)}[m
[32m+[m[32m        return {  # 32k is model token limit at the moment[m
[32m+[m[32m            "image":[m
[32m+[m[32m            self.get_hf_config().multimodal_max_length //[m
[32m+[m[32m            ((9 + 1) * NUMBER_OF_TOKEN_TO_RESERVE_FOR_SEGMENT)[m
[32m+[m[32m        }[m
[m
def get_mm_max_tokens_per_item([m
[31m-            self,[m
[31m-            seq_len: int,[m
[31m-            mm_counts: Mapping[str, int],[m
[32m+[m[32m        self,[m
[32m+[m[32m        seq_len: int,[m
[32m+[m[32m        mm_counts: Mapping[str, int],[m
) -> Mapping[str, int]:[m
return {[m
"image": (9 + 1) * NUMBER_OF_TOKEN_TO_RESERVE_FOR_SEGMENT + 11[m
[36m@@ -142,35 +133,32 @@[m [mclass Ovis2ProcessingInfo(BaseProcessingInfo):[m
class Ovis2DummyInputsBuilder(BaseDummyInputsBuilder[Ovis2ProcessingInfo]):[m
[m
def get_dummy_processor_inputs([m
[31m-            self,[m
[31m-            seq_len: int,[m
[31m-            mm_counts: Mapping[str, int][m
[31m-    ) -> ProcessorInputs:[m
[32m+[m[32m            self, seq_len: int, mm_counts: Mapping[str,[m
[32m+[m[32m                                                   int]) -> ProcessorInputs:[m
target_width, target_height = \[m
self.info.get_image_size()[m
num_images = mm_counts.get("image", 0)[m
[m
mm_data = {[m
"image":[m
[31m-                self._get_dummy_images(width=target_width,[m
[31m-                                       height=target_height,[m
[31m-                                       num_images=num_images),[m
[32m+[m[32m            self._get_dummy_images(width=target_width,[m
[32m+[m[32m                                   height=target_height,[m
[32m+[m[32m                                   num_images=num_images),[m
}[m
[m
return ProcessorInputs([m
prompt_text=IMAGE_TOKEN * num_images,[m
mm_data=mm_data,[m
[31m-[m
)[m
[m
[m
class Ovis2MultiModalProcessor(BaseMultiModalProcessor[Ovis2ProcessingInfo]):[m
[m
def _call_hf_processor([m
[31m-            self,[m
[31m-            prompt: str,[m
[31m-            mm_data: Mapping[str, object],[m
[31m-            mm_kwargs: Mapping[str, object],[m
[32m+[m[32m        self,[m
[32m+[m[32m        prompt: str,[m
[32m+[m[32m        mm_data: Mapping[str, object],[m
[32m+[m[32m        mm_kwargs: Mapping[str, object],[m
) -> BatchFeature:[m
if not mm_data:[m
#    # Avoid warning from HF logger for text-only input[m
[36m@@ -187,27 +175,25 @@[m [mclass Ovis2MultiModalProcessor(BaseMultiModalProcessor[Ovis2ProcessingInfo]):[m
return processed_outputs[m
[m
def _apply_hf_processor_tokens_only([m
[31m-            self,[m
[31m-            prompt_tokens: list[int],[m
[32m+[m[32m        self,[m
[32m+[m[32m        prompt_tokens: list[int],[m
) -> list[int]:[m
[m
return prompt_tokens[m
[m
def _get_mm_fields_config([m
[31m-            self,[m
[31m-            hf_inputs: BatchFeature,[m
[31m-            hf_processor_mm_kwargs: Mapping[str, object],[m
[32m+[m[32m        self,[m
[32m+[m[32m        hf_inputs: BatchFeature,[m
[32m+[m[32m        hf_processor_mm_kwargs: Mapping[str, object],[m
) -> Mapping[str, MultiModalFieldConfig]:[m
[31m-        return dict([m
[31m-            pixel_values=MultiModalFieldConfig.batched("image"),[m
[31m-            grids=MultiModalFieldConfig.batched("image")[m
[31m-        )[m
[32m+[m[32m        return dict(pixel_values=MultiModalFieldConfig.batched("image"),[m
[32m+[m[32m                    grids=MultiModalFieldConfig.batched("image"))[m
[m
def _get_prompt_updates([m
[31m-            self,[m
[31m-            mm_items: MultiModalDataItems,[m
[31m-            hf_processor_mm_kwargs: Mapping[str, object],[m
[31m-            out_mm_kwargs: MultiModalKwargs,[m
[32m+[m[32m        self,[m
[32m+[m[32m        mm_items: MultiModalDataItems,[m
[32m+[m[32m        hf_processor_mm_kwargs: Mapping[str, object],[m
[32m+[m[32m        out_mm_kwargs: MultiModalKwargs,[m
) -> list[PromptReplacement]:[m
[m
def get_replacement_ovis(item_idx):[m
[36m@@ -248,14 +234,14 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
config=config.visual_tokenizer_config,[m
quant_config=quant_config,[m
prefix=f"{prefix}.visual_tokenizer",[m
[31m-            image_processor_name_or_path=config.visual_tokenizer_config.backbone_config.name_or_path,[m
[32m+[m[32m            image_processor_name_or_path=config.visual_tokenizer_config.[m
[32m+[m[32m            backbone_config.name_or_path,[m
)[m
[m
self.vte = VisualEmbedding([m
self.config.visual_tokenizer_config.vocab_size,[m
self.config.hidden_size,[m
[31m-            dtype=self.visual_tokenizer.dtype[m
[31m-        )[m
[32m+[m[32m            dtype=self.visual_tokenizer.dtype)[m
[m
# we'll instantiate a tokenizer and keep just the external mapping[m
# tokenizer = AutoTokenizer.from_pretrained(config.name_or_path)[m
[36m@@ -273,13 +259,14 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
}[m
[m
self.extra_token_mapping = {[m
[31m-            k: tokenizer(v)['input_ids'][0] for k, v in self.extra_special_tokens.items()[m
[32m+[m[32m            k: tokenizer(v)['input_ids'][0][m
[32m+[m[32m            for k, v in self.extra_special_tokens.items()[m
}[m
[m
self.extra_token_mapping_for_substitution = {[m
[31m-            k: tokenizer(v)['input_ids'][0] for k, v in self.extra_special_tokens.items() if k in[m
[31m-                                                                                                  {'image_atom',[m
[31m-                                                                                                   'image_pad'}[m
[32m+[m[32m            k: tokenizer(v)['input_ids'][0][m
[32m+[m[32m            for k, v in self.extra_special_tokens.items()[m
[32m+[m[32m            if k in {'image_atom', 'image_pad'}[m
}[m
[m
self.visual_indicators_embeds_dict = None[m
[36m@@ -293,12 +280,10 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
# we precalcualte the embeddings for the image tokens[m
visual_vocab_size = self.visual_tokenizer.config.vocab_size[m
visual_indicator_embeds = self.vte([m
[31m-                torch.tensor([m
[31m-                    list(range(visual_vocab_size - 5, visual_vocab_size)),[m
[31m-                    dtype=torch.long,[m
[31m-                    device=self.vte.device[m
[31m-                )[m
[31m-            )[m
[32m+[m[32m                torch.tensor(list([m
[32m+[m[32m                    range(visual_vocab_size - 5, visual_vocab_size)),[m
[32m+[m[32m                             dtype=torch.long,[m
[32m+[m[32m                             device=self.vte.device))[m
[m
self.visual_indicators_embeds_dict = {[m
'image_start': visual_indicator_embeds[0],[m
[36m@@ -317,7 +302,7 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
pixel_values = kwargs.pop("pixel_values", None)[m
if pixel_values is None:[m
return None[m
[31m-        [m
[32m+[m
if pixel_values is not None:[m
if not isinstance(pixel_values, (torch.Tensor, list)):[m
raise ValueError("Incorrect type of pixel values. "[m
[36m@@ -326,7 +311,9 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
return Ovis2ImagePatchInputs([m
type="image_patches",[m
flat_data=flatten_bn(flatten_bn(pixel_values), concat=True),[m
[31m-                patches_per_image=[x.shape[0] for x in flatten_bn(pixel_values)],[m
[32m+[m[32m                patches_per_image=[[m
[32m+[m[32m                    x.shape[0] for x in flatten_bn(pixel_values)[m
[32m+[m[32m                ],[m
)[m
[m
raise AssertionError("This line should be unreachable.")[m
[36m@@ -338,10 +325,13 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
patches_per_image = image_input["patches_per_image"][m
[m
target_dtype = self.visual_tokenizer.dtype[m
[31m-        visual_tokens = self.visual_tokenizer(image_patches_flat.to(target_dtype))[m
[32m+[m[32m        visual_tokens = self.visual_tokenizer([m
[32m+[m[32m            image_patches_flat.to(target_dtype))[m
visual_embeds = self.vte(visual_tokens)  # 1:1 numeric eq.[m
[m
[31m-        return tuple(x.flatten(0, 1) for x in visual_embeds.split(patches_per_image, dim=0))[m
[32m+[m[32m        return tuple([m
[32m+[m[32m            x.flatten(0, 1)[m
[32m+[m[32m            for x in visual_embeds.split(patches_per_image, dim=0))[m
[m
def get_multimodal_embeddings([m
self, **kwargs: object) -> Optional[MultiModalEmbeddings]:[m
[36m@@ -352,7 +342,7 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
image_features = self._process_image_input(image_input)[m
[m
return image_features[m
[31m-    [m
[32m+[m
def get_input_embeddings([m
self,[m
input_ids: torch.Tensor,[m
[36m@@ -361,17 +351,17 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
inputs_embeds = self.llm.get_input_embeddings(input_ids)[m
if multimodal_embeddings is not None:[m
inputs_embeds = merge_multimodal_embeddings([m
[31m-                input_ids, inputs_embeds,[m
[31m-                multimodal_embeddings, [151672, 151666])[m
[32m+[m[32m                input_ids, inputs_embeds, multimodal_embeddings,[m
[32m+[m[32m                [151672, 151666])[m
return inputs_embeds[m
[m
def forward([m
[31m-            self,[m
[31m-            input_ids: torch.Tensor,[m
[31m-            positions: torch.Tensor,[m
[31m-            intermediate_tensors: Optional[IntermediateTensors] = None,[m
[31m-            inputs_embeds: Optional[torch.Tensor] = None,[m
[31m-            **kwargs: object,[m
[32m+[m[32m        self,[m
[32m+[m[32m        input_ids: torch.Tensor,[m
[32m+[m[32m        positions: torch.Tensor,[m
[32m+[m[32m        intermediate_tensors: Optional[IntermediateTensors] = None,[m
[32m+[m[32m        inputs_embeds: Optional[torch.Tensor] = None,[m
[32m+[m[32m        **kwargs: object,[m
) -> Union[torch.Tensor, IntermediateTensors]:[m
if intermediate_tensors is not None:[m
inputs_embeds = None[m
[36m@@ -394,23 +384,23 @@[m [mclass Ovis2ForConditionalGeneration(nn.Module, SupportsMultiModal, SupportsPP):[m
return hidden_states[m
[m
def compute_logits([m
[31m-            self,[m
[31m-            hidden_states: torch.Tensor,[m
[31m-            sampling_metadata: SamplingMetadata,[m
[32m+[m[32m        self,[m
[32m+[m[32m        hidden_states: torch.Tensor,[m
[32m+[m[32m        sampling_metadata: SamplingMetadata,[m
) -> Optional[torch.Tensor]:[m
[31m-        logits = self.llm.logits_processor([m
[31m-            self.llm.lm_head, hidden_states, sampling_metadata)[m
[32m+[m[32m        logits = self.llm.logits_processor(self.llm.lm_head, hidden_states,[m
[32m+[m[32m                                           sampling_metadata)[m
return logits[m
[m
def sample([m
[31m-            self,[m
[31m-            logits: torch.Tensor,[m
[31m-            sampling_metadata: SamplingMetadata,[m
[32m+[m[32m        self,[m
[32m+[m[32m        logits: torch.Tensor,[m
[32m+[m[32m        sampling_metadata: SamplingMetadata,[m
) -> Optional[SamplerOutput]:[m
next_tokens = self.llm.sampler(logits, sampling_metadata)[m
return next_tokens[m
[m
def load_weights(self, weights: Iterable[Tuple[str,[m
[31m-    torch.Tensor]]) -> Set[str]:[m
[32m+[m[32m                                                   torch.Tensor]]) -> Set[str]:[m
loader = AutoWeightsLoader(self)[m
[31m-        return loader.load_weights(weights)[m
\ No newline at end of file[m
[32m+[m[32m        return loader.load_weights(weights)[m
[1mdiff --git a/vllm/transformers_utils/config.py b/vllm/transformers_utils/config.py[m
[1mindex 1b18e49..13ba370 100644[m
[1m--- a/vllm/transformers_utils/config.py[m
[1m+++ b/vllm/transformers_utils/config.py[m
[36m@@ -36,10 +36,10 @@[m [mfrom vllm.transformers_utils.configs import (ChatGLMConfig, Cohere2Config,[m
KimiVLConfig, MedusaConfig,[m
MllamaConfig, MLPSpeculatorConfig,[m
MPTConfig, NemotronConfig,[m
[31m-                                             NVLM_D_Config, OvisConfig, Olmo2Config,[m
[31m-                                             RWConfig, SkyworkR1VChatConfig,[m
[31m-                                             SolarConfig, Telechat2Config,[m
[31m-                                             UltravoxConfig)[m
[32m+[m[32m                                             NVLM_D_Config, Olmo2Config,[m
[32m+[m[32m                                             OvisConfig, RWConfig,[m
[32m+[m[32m                                             SkyworkR1VChatConfig, SolarConfig,[m
[32m+[m[32m                                             Telechat2Config, UltravoxConfig)[m
# yapf: enable[m
from vllm.transformers_utils.utils import check_gguf_file[m
from vllm.utils import resolve_obj_by_qualname[m
[1mdiff --git a/vllm/transformers_utils/configs/ovis2.py b/vllm/transformers_utils/configs/ovis2.py[m
[1mindex a055b76..c258282 100644[m
[1m--- a/vllm/transformers_utils/configs/ovis2.py[m
[1m+++ b/vllm/transformers_utils/configs/ovis2.py[m
[36m@@ -2,9 +2,9 @@[m
[m
# copied from https://huggingface.co/AIDC-AI/Ovis2-1B/blob/main/configuration_aimv2.py[m
# and https://huggingface.co/AIDC-AI/Ovis2-1B/blob/main/configuration_ovis.py[m
[31m-from typing import Any, Union, Optional[m
[32m+[m[32mfrom typing import Any, Optional, Union[m
[m
[31m-from transformers import PretrainedConfig, AutoConfig[m
[32m+[m[32mfrom transformers import AutoConfig, PretrainedConfig[m
[m
[m
class AIMv2Config(PretrainedConfig):[m
[36m@@ -63,6 +63,7 @@[m [mclass AIMv2Config(PretrainedConfig):[m
self.qkv_bias = qkv_bias[m
self.use_bias = use_bias[m
[m
[32m+[m
IGNORE_ID = -100[m
IMAGE_TOKEN_ID = -200[m
IMAGE_TOKEN = "<image>"[m
[36m@@ -71,21 +72,22 @@[m [mIMAGE_INDICATOR_IDS = [-301, -302, -303, -304, -305][m
[m
AutoConfig.register("aimv2", AIMv2Config)[m
[m
[32m+[m
# ----------------------------------------------------------------------[m
#                     Visual Tokenizer Configuration[m
# ----------------------------------------------------------------------[m
class BaseVisualTokenizerConfig(PretrainedConfig):[m
[31m-    def __init__([m
[31m-        self,[m
[31m-        vocab_size=16384,[m
[31m-        tokenize_function="softmax",[m
[31m-        tau=1.0,[m
[31m-        depths=None,[m
[31m-        drop_cls_token=False,[m
[31m-        backbone_config: Optional[Union[PretrainedConfig, dict]] = None,[m
[31m-        hidden_stride: int = 1,[m
[31m-        **kwargs[m
[31m-    ):[m
[32m+[m
[32m+[m[32m    def __init__(self,[m
[32m+[m[32m                 vocab_size=16384,[m
[32m+[m[32m                 tokenize_function="softmax",[m
[32m+[m[32m                 tau=1.0,[m
[32m+[m[32m                 depths=None,[m
[32m+[m[32m                 drop_cls_token=False,[m
[32m+[m[32m                 backbone_config: Optional[Union[PretrainedConfig,[m
[32m+[m[32m                                                 dict]] = None,[m
[32m+[m[32m                 hidden_stride: int = 1,[m
[32m+[m[32m                 **kwargs):[m
super().__init__(**kwargs)[m
self.vocab_size = vocab_size[m
self.tokenize_function = tokenize_function[m
[36m@@ -101,7 +103,8 @@[m [mclass BaseVisualTokenizerConfig(PretrainedConfig):[m
if not isinstance(backbone_config, PretrainedConfig):[m
model_type = backbone_config['model_type'][m
backbone_config.pop('model_type')[m
[31m-                backbone_config = AutoConfig.for_model(model_type, **backbone_config)[m
[32m+[m[32m                backbone_config = AutoConfig.for_model(model_type,[m
[32m+[m[32m                                                       **backbone_config)[m
self.backbone_config = backbone_config[m
self.hidden_stride = hidden_stride[m
[m
[36m@@ -127,17 +130,16 @@[m [mAutoConfig.register("aimv2_visual_tokenizer", Aimv2VisualTokenizerConfig)[m
class OvisConfig(PretrainedConfig):[m
model_type = "ovis"[m
[m
[31m-    def __init__([m
[31m-        self,[m
[31m-        llm_config: Optional[Union[PretrainedConfig, dict]] = None,[m
[31m-        visual_tokenizer_config: Optional[Union[PretrainedConfig, dict]] = None,[m
[31m-        multimodal_max_length=8192,[m
[31m-        hidden_size=None,[m
[31m-        conversation_formatter_class=None,[m
[31m-        llm_attn_implementation=None,[m
[31m-        disable_tie_weight=False,[m
[31m-        **kwargs[m
[31m-    ):[m
[32m+[m[32m    def __init__(self,[m
[32m+[m[32m                 llm_config: Optional[Union[PretrainedConfig, dict]] = None,[m
[32m+[m[32m                 visual_tokenizer_config: Optional[Union[PretrainedConfig,[m
[32m+[m[32m                                                         dict]] = None,[m
[32m+[m[32m                 multimodal_max_length=8192,[m
[32m+[m[32m                 hidden_size=None,[m
[32m+[m[32m                 conversation_formatter_class=None,[m
[32m+[m[32m                 llm_attn_implementation=None,[m
[32m+[m[32m                 disable_tie_weight=False,[m
[32m+[m[32m                 **kwargs):[m
super().__init__(**kwargs)[m
if llm_config is not None:[m
assert isinstance(llm_config, (PretrainedConfig, dict)), \[m
[36m@@ -155,7 +157,8 @@[m [mclass OvisConfig(PretrainedConfig):[m
if not isinstance(visual_tokenizer_config, PretrainedConfig):[m
model_type = visual_tokenizer_config['model_type'][m
visual_tokenizer_config.pop('model_type')[m
[31m-                visual_tokenizer_config = AutoConfig.for_model(model_type, **visual_tokenizer_config)[m
[32m+[m[32m                visual_tokenizer_config = AutoConfig.for_model([m
[32m+[m[32m                    model_type, **visual_tokenizer_config)[m
[m
self.visual_tokenizer_config = visual_tokenizer_config[m
self.multimodal_max_length = multimodal_max_length[m
[1mdiff --git a/vllm/transformers_utils/processors/ovis2.py b/vllm/transformers_utils/processors/ovis2.py[m
[1mindex 60da0f7..0da57e2 100644[m
[1m--- a/vllm/transformers_utils/processors/ovis2.py[m
[1m+++ b/vllm/transformers_utils/processors/ovis2.py[m
[36m@@ -28,8 +28,9 @@[m [mimport PIL[m
import torch[m
from transformers import AutoProcessor, BatchFeature[m
from transformers.image_utils import ImageInput[m
[31m-from transformers.processing_utils import ProcessingKwargs, ProcessorMixin, Unpack[m
[31m-from transformers.tokenization_utils_base import TextInput, PreTokenizedInput[m
[32m+[m[32mfrom transformers.processing_utils import (ProcessingKwargs, ProcessorMixin,[m
[32m+[m[32m                                           Unpack)[m
[32m+[m[32mfrom transformers.tokenization_utils_base import PreTokenizedInput, TextInput[m
[m
__all__ = [ 'OvisProcessor'][m
IGNORE_ID = -100[m
##[error]Process completed with exit code 1.



2 49 0
Temporarily overriding HOME='/home/runner/work/_temp/250e8ce7-e944-47f4-ac1c-f0636fb60756' before making global git config changes

[command]/usr/bin/git config --global --add safe.directory /home/runner/work/vllm/vllm
core\.sshCommand
'core\.sshCommand' 'core.sshCommand'
http\.https\:\/\/github\.com\/\.extraheader


'http\.https\:\/\/github\.com\/\.extraheader' 'http.https://github.com/.extraheader'

